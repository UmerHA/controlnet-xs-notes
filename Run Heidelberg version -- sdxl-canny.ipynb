{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda36831-a1e7-4c2f-b3ab-5f45dfaac14e",
   "metadata": {},
   "source": [
    "In this notebook, I run one step for TwoStreamControlModel to get intermediate outputs which I can then compare to my local run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b74b9e-7bbc-41ff-bc01-3d3055570a57",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a43bd7c1-8c6b-4f3c-bf65-5398fdbbdc51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # needed to make torch deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1c7d13-020e-4053-9754-7f2bf5b4829f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name vit_base_resnet50_384 to current vit_base_r50_s16_384.orig_in21k_ft_in1k.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "import scripts.control_utils as cu\n",
    "import torch\n",
    "torch.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad3a198-093b-46fa-9cda-a13750fc9aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be14a47f-ac71-4e60-a52f-4befa3fb0b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_config = 'cnxs_config/sdxl/sdxl_encD_canny_48m.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6552dd-0ad5-4db2-b1a6-3c9b8ca55f4f",
   "metadata": {},
   "source": [
    "If this results in the kernel crashing, I'm using too much GPU memory elsewhere. Shut down every other kernel and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70915bf0-38be-40e8-a791-23a6ded976ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a Downsample layer with 2 dims.\n",
      "  --> settings are: \n",
      " in-chn: 320, out-chn: 320, kernel-size: 3, stride: 2, padding: 1\n",
      "constructing SpatialTransformer of depth 2 w/ 640 channels and 10 heads\n",
      "constructing SpatialTransformer of depth 2 w/ 640 channels and 10 heads\n",
      "Building a Downsample layer with 2 dims.\n",
      "  --> settings are: \n",
      " in-chn: 640, out-chn: 640, kernel-size: 3, stride: 2, padding: 1\n",
      "constructing SpatialTransformer of depth 10 w/ 1280 channels and 20 heads\n",
      "constructing SpatialTransformer of depth 10 w/ 1280 channels and 20 heads\n",
      "constructing SpatialTransformer of depth 10 w/ 1280 channels and 20 heads\n",
      "constructing SpatialTransformer of depth 10 w/ 1280 channels and 20 heads\n",
      "constructing SpatialTransformer of depth 10 w/ 1280 channels and 20 heads\n",
      "constructing SpatialTransformer of depth 10 w/ 1280 channels and 20 heads\n",
      "constructing SpatialTransformer of depth 2 w/ 640 channels and 10 heads\n",
      "constructing SpatialTransformer of depth 2 w/ 640 channels and 10 heads\n",
      "constructing SpatialTransformer of depth 2 w/ 640 channels and 10 heads\n",
      "Building a Downsample layer with 2 dims.\n",
      "  --> settings are: \n",
      " in-chn: 352, out-chn: 32, kernel-size: 3, stride: 2, padding: 1\n",
      "constructing SpatialTransformer of depth 2 w/ 64 channels and 1 heads\n",
      "constructing SpatialTransformer of depth 2 w/ 64 channels and 1 heads\n",
      "Building a Downsample layer with 2 dims.\n",
      "  --> settings are: \n",
      " in-chn: 704, out-chn: 64, kernel-size: 3, stride: 2, padding: 1\n",
      "constructing SpatialTransformer of depth 10 w/ 128 channels and 2 heads\n",
      "constructing SpatialTransformer of depth 10 w/ 128 channels and 2 heads\n",
      "constructing SpatialTransformer of depth 10 w/ 128 channels and 2 heads\n",
      "Initialized embedder #0: FrozenCLIPEmbedder with 123060480 params. Trainable: False\n",
      "Initialized embedder #1: FrozenOpenCLIPEmbedder2 with 694659841 params. Trainable: False\n",
      "Initialized embedder #2: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Initialized embedder #3: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Initialized embedder #4: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "making attention of type 'vanilla-xformers' with 512 in_channels\n",
      "building MemoryEfficientAttnBlock with 512 in_channels...\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla-xformers' with 512 in_channels\n",
      "building MemoryEfficientAttnBlock with 512 in_channels...\n",
      "Loaded model config from [cnxs_config/sdxl/sdxl_encD_canny_48m.yaml]\n"
     ]
    }
   ],
   "source": [
    "model = cu.create_model(path_to_config).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340af143-5579-4785-b103-b796011abf6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722ce2e4-2e2b-4f4c-bc1e-8818a7ae7c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size = 768\n",
    "num_samples=1\n",
    "prompt='cinematic, shoe in the streets, made from meat, photorealistic shoe, highly detailed'\n",
    "n_prompt='lowres, bad anatomy, worst quality, low quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05676d1d-23c9-4982-98e9-6142b876d136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_canny_edges():\n",
    "    image_path = 'input_images/shoe.png' # chosen to fit size above\n",
    "    image = cu.get_image(image_path, size=size)\n",
    "    edges = cu.get_canny_edges(image, low_th=100, high_th=250)\n",
    "    return edges\n",
    "edges = get_canny_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e372b6-ecd3-4f26-a0dc-809795f24dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a19f10d5-90d8-4481-a9c9-780349d87543",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sgm.umer_debug_logger import udl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fdaf55a-d896-49c2-ae49-c276afd08604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "udl.set_dir('logs/cloud/', clear=True)\n",
    "udl.set_condition('SUBBLOCK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f45e59cd-3ecb-419d-ab69-ee3e488e640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1999158951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONTROL CORRECTION OF ControlledDiffusionEngine SCALED WITH 0.95]\n",
      "crop_coords_top_left = tensor([[0, 0]], device='cuda:0')\n",
      "original_size_as_tuple = tensor([[768, 768]], device='cuda:0')\n",
      "target_size_as_tuple = tensor([[768, 768]], device='cuda:0')\n",
      "These are the timesteps: (0: 14.614641189575195)\t(1: 12.966320991516113)\t(2: 11.542771339416504)\t(3: 10.309401512145996)\t(4: 9.237422943115234)\t(5: 8.302803039550781)\t(6: 7.485421180725098)\t(7: 6.768382549285889)\t(8: 6.137460708618164)\t(9: 5.580644607543945)\t(10: 5.08776330947876)\t(11: 4.650183200836182)\t(12: 4.260556697845459)\t(13: 3.9126131534576416)\t(14: 3.6009886264801025)\t(15: 3.3210830688476562)\t(16: 3.0689430236816406)\t(17: 2.8411612510681152)\t(18: 2.634795665740967)\t(19: 2.4472994804382324)\t(20: 2.276463031768799)\t(21: 2.1203653812408447)\t(22: 1.977332353591919)\t(23: 1.8459018468856812)\t(24: 1.7247940301895142)\t(25: 1.6128861904144287)\t(26: 1.5091912746429443)\t(27: 1.4128390550613403)\t(28: 1.3230608701705933)\t(29: 1.2391756772994995)\t(30: 1.1605783700942993)\t(31: 1.0867294073104858)\t(32: 1.0171462297439575)\t(33: 0.9513954520225525)\t(34: 0.8890852332115173)\t(35: 0.8298594951629639)\t(36: 0.773391842842102)\t(37: 0.7193796038627625)\t(38: 0.6675384640693665)\t(39: 0.6175960898399353)\t(40: 0.5692849159240723)\t(41: 0.5223334431648254)\t(42: 0.47645437717437744)\t(43: 0.4313262701034546)\t(44: 0.3865651786327362)\t(45: 0.3416738212108612)\t(46: 0.29594171047210693)\t(47: 0.24822042882442474)\t(48: 0.19630272686481476)\t(49: 0.13445067405700684)\t(50: 0.0)\n",
      "control scale:  tensor([0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500], device='cuda:0')\n",
      "Timestep embedding params: timesteps = tensor([999, 999], device='cuda:0') | model channels = 320\n",
      "Of course I've not learned a time embedding. I'm smart! Let me collaborate with the base model by {self.control_scale:.2f}**3.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TimestepEmbedSequential.forward() missing 1 required positional argument: 'emb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m samples, controls, latents \u001b[38;5;241m=\u001b[39m \u001b[43mcu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sdxl_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mguidance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mddim_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrol_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_latents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ControlNet-XS/scripts/control_utils.py:221\u001b[0m, in \u001b[0;36mget_sdxl_sample\u001b[0;34m(guidance, model, num_samples, seed, scale, eta, ddim_steps, prompt, idx, control_scale, shape, n_prompt, return_latents)\u001b[0m\n\u001b[1;32m    218\u001b[0m         c[k], uc[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m y: y[k]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m), (c, uc))\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mema_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlotting\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 221\u001b[0m     samples, latents \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msampling_kwargs\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m x_samples \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecode_first_stage(samples)\n\u001b[1;32m    226\u001b[0m x_samples \u001b[38;5;241m=\u001b[39m (einops\u001b[38;5;241m.\u001b[39mrearrange(\n\u001b[1;32m    227\u001b[0m     x_samples, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb c h w -> b h w c\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    228\u001b[0m ) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m127.5\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m127.5\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/models/diffusion.py:248\u001b[0m, in \u001b[0;36mDiffusionEngine.sample\u001b[0;34m(self, cond, uc, batch_size, shape, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m randn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, \u001b[38;5;241m*\u001b[39mshape)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    245\u001b[0m denoiser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28minput\u001b[39m, sigma, c: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdenoiser(\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28minput\u001b[39m, sigma, c, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    247\u001b[0m )\n\u001b[0;32m--> 248\u001b[0m samples, latents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdenoiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m latents \u001b[38;5;241m=\u001b[39m [randn] \u001b[38;5;241m+\u001b[39m latents \u001b[38;5;66;03m# Debug Umer\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples, latents\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/modules/diffusionmodules/sampling.py:128\u001b[0m, in \u001b[0;36mEDMSampler.__call__\u001b[0;34m(self, denoiser, x, cond, uc, num_steps)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sigma_gen(num_sigmas):\n\u001b[1;32m    123\u001b[0m     gamma \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms_churn \u001b[38;5;241m/\u001b[39m (num_sigmas \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms_tmin \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sigmas[i] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms_tmax\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[0;32m--> 128\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms_in\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msigmas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms_in\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msigmas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdenoiser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43muc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m     latents\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, latents\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/modules/diffusionmodules/sampling.py:105\u001b[0m, in \u001b[0;36mEDMSampler.sampler_step\u001b[0;34m(self, sigma, next_sigma, denoiser, x, cond, uc, gamma)\u001b[0m\n\u001b[1;32m    102\u001b[0m     eps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms_noise\n\u001b[1;32m    103\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m eps \u001b[38;5;241m*\u001b[39m append_dims(sigma_hat\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m sigma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, x\u001b[38;5;241m.\u001b[39mndim) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m--> 105\u001b[0m denoised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenoiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m d \u001b[38;5;241m=\u001b[39m to_d(x, sigma_hat, denoised)\n\u001b[1;32m    107\u001b[0m dt \u001b[38;5;241m=\u001b[39m append_dims(next_sigma \u001b[38;5;241m-\u001b[39m sigma_hat, x\u001b[38;5;241m.\u001b[39mndim)\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/modules/diffusionmodules/sampling.py:61\u001b[0m, in \u001b[0;36mBaseDiffusionSampler.denoise\u001b[0;34m(self, x, denoiser, sigma, cond, uc)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdenoise\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, denoiser, sigma, cond, uc):\n\u001b[0;32m---> 61\u001b[0m     denoised \u001b[38;5;241m=\u001b[39m \u001b[43mdenoiser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     denoised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mguider(denoised, sigma)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m denoised\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/models/diffusion.py:245\u001b[0m, in \u001b[0;36mDiffusionEngine.sample.<locals>.<lambda>\u001b[0;34m(input, sigma, c)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    242\u001b[0m ):\n\u001b[1;32m    243\u001b[0m     randn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, \u001b[38;5;241m*\u001b[39mshape)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 245\u001b[0m     denoiser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28minput\u001b[39m, sigma, c: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoiser\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     samples, latents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler(denoiser, randn, cond, uc\u001b[38;5;241m=\u001b[39muc)\n\u001b[1;32m    250\u001b[0m     latents \u001b[38;5;241m=\u001b[39m [randn] \u001b[38;5;241m+\u001b[39m latents \u001b[38;5;66;03m# Debug Umer\u001b[39;00m\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/modules/diffusionmodules/denoiser.py:93\u001b[0m, in \u001b[0;36mControlledDiscreteDenoiser.__call__\u001b[0;34m(self, network, input, sigma, cond, hint)\u001b[0m\n\u001b[1;32m     91\u001b[0m c_skip, c_out, c_in, c_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling(sigma)\n\u001b[1;32m     92\u001b[0m c_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpossibly_quantize_c_noise(c_noise\u001b[38;5;241m.\u001b[39mreshape(sigma_shape))\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m c_out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m c_skip\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/modules/diffusionmodules/twoStreamControl.py:305\u001b[0m, in \u001b[0;36mTwoStreamControlNet.forward\u001b[0;34m(self, x, t, c, hint, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m hint\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    304\u001b[0m     hint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([hint, hint], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcrossattn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# True if self.control_mode == 'midas' else False,\u001b[39;49;00m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/modules/diffusionmodules/twoStreamControl.py:381\u001b[0m, in \u001b[0;36mTwoStreamControlNet.forward_\u001b[0;34m(self, x, hint, timesteps, context, base_model, y, precomputed_hint, no_control, compute_hint, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m     guided_hint \u001b[38;5;241m=\u001b[39m hint\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     guided_hint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_hint_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, emb, context)\u001b[39;00m\n\u001b[1;32m    383\u001b[0m h_ctr \u001b[38;5;241m=\u001b[39m h_base \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    384\u001b[0m hs_base \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: TimestepEmbedSequential.forward() missing 1 required positional argument: 'emb'"
     ]
    }
   ],
   "source": [
    "samples, controls, latents = cu.get_sdxl_sample(\n",
    "    guidance=edges,\n",
    "    ddim_steps=50,\n",
    "    num_samples=num_samples,\n",
    "    model=model,\n",
    "    shape=[4, size // 8, size // 8],\n",
    "    control_scale=0.95,\n",
    "    prompt=prompt,\n",
    "    n_prompt=n_prompt,\n",
    "    return_latents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4e3f08-ba93-411f-a6d6-baca8ab80f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas_str = '\\t'.join([f'({i}: {t})' for i,t in enumerate([1,2,3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3d5f3-99db-428d-9da6-5409cc4410fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f2bfc-cb28-4dc6-b4d8-e7c1383eba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model.model.diffusion_model.input_blocks[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1937e742-41a2-4277-ac47-a2a43d4d2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model.model.control_model.input_blocks[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ca1238-4d47-40fb-95de-bf652b653dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de72f5-d9de-4114-960c-821c0dd99b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad32bc4-43d3-4ef8-aaae-a592a367f93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e3dba-96fe-44cb-b70e-f181a787bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def show_image(im_tensor): return Image.fromarray(cu.create_image_grid(im_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f3e5d5-1d77-4e87-bbcd-b95dc0cdcc9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_image(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7d2a68-1f1f-4d90-b0f8-50b162c038d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d238e0-c4e8-4680-9f98-8de4a832498b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7098c-0cba-4c99-a5a9-328f61c6e59c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import einops\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def lat2img(lat, resize_to=None, output_type='pil'):\n",
    "    assert lat.dim() == 4, \"Expected a batch of images, not a single batch\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ims = model.decode_first_stage(lat)\n",
    "        ims = (einops.rearrange(\n",
    "            ims, 'b c h w -> b h w c'\n",
    "        ) * 127.5 + 127.5).cpu().numpy().clip(0, 255).astype(np.uint8)\n",
    "        \n",
    "        if output_type == 'pil': ims = [Image.fromarray(im) for im in ims]\n",
    "        \n",
    "        if resize_to is not None:\n",
    "            if output_type=='pil': ims = [im.resize(resize_to) for im in ims]\n",
    "            else: print(f'Not resizing as output_type = {output_type} requested')\n",
    "    return ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dee8055-3d0f-4f54-bc93-09284b2926cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps, ImageDraw\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import partial\n",
    "\n",
    "def plot_latents_to_pil_grid(lats, every=1, cols=10, im_size=200, pbar=True, border=2, return_ims=True, output_type='pil'):\n",
    "    if not isinstance(im_size, (list, tuple)): im_size = (im_size, im_size)\n",
    "    \n",
    "    lats = [lat for i, lat in enumerate(lats) if i % every == 0 or i == len(lats)-1]\n",
    "    if pbar: lats = tqdm(lats)\n",
    "    \n",
    "    # decoce latents -> images\n",
    "    ims = [lat2img(lat, resize_to=im_size, output_type=output_type)[0] for lat in lats] # removed pipe argument\n",
    "    \n",
    "    # add border\n",
    "    ims_bordered = [ImageOps.expand(im, border=2, fill='black') for im in ims]\n",
    "    im_size = (im_size[0]+border, im_size[1]+border)\n",
    "\n",
    "    rows = len(ims) // cols\n",
    "    if rows * cols < len(ims): rows += 1\n",
    "\n",
    "    # draw background\n",
    "    grid_image = Image.new('RGB', (cols * im_size[0], rows * im_size[1]), color='grey')\n",
    "    draw = ImageDraw.Draw(grid_image)\n",
    "    for xy in range(0,2*max(cols * im_size[0], rows * im_size[1])+1,100):\n",
    "        draw.line([(xy, 0), (0, xy)], fill=\"white\", width=1)\n",
    "    \n",
    "    # draw images\n",
    "    for i, img in enumerate(ims_bordered):\n",
    "        x_offset = (i % cols) * im_size[0]\n",
    "        y_offset = (i // cols) * im_size[1]\n",
    "        grid_image.paste(img, (x_offset, y_offset))\n",
    "\n",
    "    if return_ims: return grid_image, ims\n",
    "    else: return grid_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076182e2-1372-4f11-9c16-c120e98f4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, ims = plot_latents_to_pil_grid(latents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28190dcd-9a17-491e-86bb-8aa151a32b91",
   "metadata": {},
   "source": [
    "Cuda Heidelberg, control scale = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a04ad9-1f4e-45d0-a2fe-e30205c8a088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff5718b-1db0-4620-b084-ec490dc71286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc0f9d6-f231-4a00-bfdf-76701a3ecb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ee3a6-9a2a-477e-a4c4-d8bf20b3808d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc71b66-91f4-4ee3-a23f-54151ad34c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c294c2-24c9-4dea-9775-ed7f7ac5238e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbebb69-1770-4559-8f60-e77b9ffc30c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602acaba-3cdf-4818-9467-5fa7045d30dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cae264-d9be-4c2d-aee5-161415a9cbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
