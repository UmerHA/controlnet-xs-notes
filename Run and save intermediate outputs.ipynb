{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda36831-a1e7-4c2f-b3ab-5f45dfaac14e",
   "metadata": {},
   "source": [
    "In this notebook, I run one step for TwoStreamControlModel to get intermediate outputs which I can then compare to my local run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54dbfc0d-9426-4833-848f-be9ee8b3e1a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libelf1:amd64.\n",
      "(Reading database ... 30662 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libelf1_0.176-1.1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libelf1:amd64 (0.176-1.1ubuntu0.1) ...\n",
      "Selecting previously unselected package libdrm-common.\n",
      "Preparing to unpack .../01-libdrm-common_2.4.107-8ubuntu1~20.04.2_all.deb ...\n",
      "Unpacking libdrm-common (2.4.107-8ubuntu1~20.04.2) ...\n",
      "Selecting previously unselected package libdrm2:amd64.\n",
      "Preparing to unpack .../02-libdrm2_2.4.107-8ubuntu1~20.04.2_amd64.deb ...\n",
      "Unpacking libdrm2:amd64 (2.4.107-8ubuntu1~20.04.2) ...\n",
      "Selecting previously unselected package libdrm-amdgpu1:amd64.\n",
      "Preparing to unpack .../03-libdrm-amdgpu1_2.4.107-8ubuntu1~20.04.2_amd64.deb ...\n",
      "Unpacking libdrm-amdgpu1:amd64 (2.4.107-8ubuntu1~20.04.2) ...\n",
      "Selecting previously unselected package libpciaccess0:amd64.\n",
      "Preparing to unpack .../04-libpciaccess0_0.16-0ubuntu1_amd64.deb ...\n",
      "Unpacking libpciaccess0:amd64 (0.16-0ubuntu1) ...\n",
      "Selecting previously unselected package libdrm-intel1:amd64.\n",
      "Preparing to unpack .../05-libdrm-intel1_2.4.107-8ubuntu1~20.04.2_amd64.deb ...\n",
      "Unpacking libdrm-intel1:amd64 (2.4.107-8ubuntu1~20.04.2) ...\n",
      "Selecting previously unselected package libdrm-nouveau2:amd64.\n",
      "Preparing to unpack .../06-libdrm-nouveau2_2.4.107-8ubuntu1~20.04.2_amd64.deb ...\n",
      "Unpacking libdrm-nouveau2:amd64 (2.4.107-8ubuntu1~20.04.2) ...\n",
      "Selecting previously unselected package libdrm-radeon1:amd64.\n",
      "Preparing to unpack .../07-libdrm-radeon1_2.4.107-8ubuntu1~20.04.2_amd64.deb ...\n",
      "Unpacking libdrm-radeon1:amd64 (2.4.107-8ubuntu1~20.04.2) ...\n",
      "Selecting previously unselected package libglapi-mesa:amd64.\n",
      "Preparing to unpack .../08-libglapi-mesa_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
      "Unpacking libglapi-mesa:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
      "Selecting previously unselected package libllvm12:amd64.\n",
      "Preparing to unpack .../09-libllvm12_1%3a12.0.0-3ubuntu1~20.04.5_amd64.deb ...\n",
      "Unpacking libllvm12:amd64 (1:12.0.0-3ubuntu1~20.04.5) ...\n",
      "Selecting previously unselected package libsensors-config.\n",
      "Preparing to unpack .../10-libsensors-config_1%3a3.6.0-2ubuntu1.1_all.deb ...\n",
      "Unpacking libsensors-config (1:3.6.0-2ubuntu1.1) ...\n",
      "Selecting previously unselected package libsensors5:amd64.\n",
      "Preparing to unpack .../11-libsensors5_1%3a3.6.0-2ubuntu1.1_amd64.deb ...\n",
      "Unpacking libsensors5:amd64 (1:3.6.0-2ubuntu1.1) ...\n",
      "Selecting previously unselected package libvulkan1:amd64.\n",
      "Preparing to unpack .../12-libvulkan1_1.2.131.2-1_amd64.deb ...\n",
      "Unpacking libvulkan1:amd64 (1.2.131.2-1) ...\n",
      "Selecting previously unselected package libgl1-mesa-dri:amd64.\n",
      "Preparing to unpack .../13-libgl1-mesa-dri_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
      "Unpacking libgl1-mesa-dri:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
      "Selecting previously unselected package libglvnd0:amd64.\n",
      "Preparing to unpack .../14-libglvnd0_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\n",
      "Unpacking libglvnd0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
      "Selecting previously unselected package libx11-xcb1:amd64.\n",
      "Preparing to unpack .../15-libx11-xcb1_2%3a1.6.9-2ubuntu1.6_amd64.deb ...\n",
      "Unpacking libx11-xcb1:amd64 (2:1.6.9-2ubuntu1.6) ...\n",
      "Selecting previously unselected package libxcb-dri2-0:amd64.\n",
      "Preparing to unpack .../16-libxcb-dri2-0_1.14-2_amd64.deb ...\n",
      "Unpacking libxcb-dri2-0:amd64 (1.14-2) ...\n",
      "Selecting previously unselected package libxcb-dri3-0:amd64.\n",
      "Preparing to unpack .../17-libxcb-dri3-0_1.14-2_amd64.deb ...\n",
      "Unpacking libxcb-dri3-0:amd64 (1.14-2) ...\n",
      "Selecting previously unselected package libxcb-glx0:amd64.\n",
      "Preparing to unpack .../18-libxcb-glx0_1.14-2_amd64.deb ...\n",
      "Unpacking libxcb-glx0:amd64 (1.14-2) ...\n",
      "Selecting previously unselected package libxcb-present0:amd64.\n",
      "Preparing to unpack .../19-libxcb-present0_1.14-2_amd64.deb ...\n",
      "Unpacking libxcb-present0:amd64 (1.14-2) ...\n",
      "Selecting previously unselected package libxcb-shm0:amd64.\n",
      "Preparing to unpack .../20-libxcb-shm0_1.14-2_amd64.deb ...\n",
      "Unpacking libxcb-shm0:amd64 (1.14-2) ...\n",
      "Selecting previously unselected package libxcb-sync1:amd64.\n",
      "Preparing to unpack .../21-libxcb-sync1_1.14-2_amd64.deb ...\n",
      "Unpacking libxcb-sync1:amd64 (1.14-2) ...\n",
      "Selecting previously unselected package libxcb-xfixes0:amd64.\n",
      "Preparing to unpack .../22-libxcb-xfixes0_1.14-2_amd64.deb ...\n",
      "Unpacking libxcb-xfixes0:amd64 (1.14-2) ...\n",
      "Selecting previously unselected package libxfixes3:amd64.\n",
      "Preparing to unpack .../23-libxfixes3_1%3a5.0.3-2_amd64.deb ...\n",
      "Unpacking libxfixes3:amd64 (1:5.0.3-2) ...\n",
      "Selecting previously unselected package libxshmfence1:amd64.\n",
      "Preparing to unpack .../24-libxshmfence1_1.3-1_amd64.deb ...\n",
      "Unpacking libxshmfence1:amd64 (1.3-1) ...\n",
      "Selecting previously unselected package libxxf86vm1:amd64.\n",
      "Preparing to unpack .../25-libxxf86vm1_1%3a1.1.4-1build1_amd64.deb ...\n",
      "Unpacking libxxf86vm1:amd64 (1:1.1.4-1build1) ...\n",
      "Selecting previously unselected package libglx-mesa0:amd64.\n",
      "Preparing to unpack .../26-libglx-mesa0_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
      "Unpacking libglx-mesa0:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
      "Selecting previously unselected package libglx0:amd64.\n",
      "Preparing to unpack .../27-libglx0_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\n",
      "Unpacking libglx0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
      "Selecting previously unselected package libgl1:amd64.\n",
      "Preparing to unpack .../28-libgl1_1.3.2-1~ubuntu0.20.04.2_amd64.deb ...\n",
      "Unpacking libgl1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
      "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
      "Preparing to unpack .../29-libgl1-mesa-glx_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
      "Unpacking libgl1-mesa-glx:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
      "Selecting previously unselected package libwayland-client0:amd64.\n",
      "Preparing to unpack .../30-libwayland-client0_1.18.0-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libwayland-client0:amd64 (1.18.0-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libxcb-randr0:amd64.\n",
      "Preparing to unpack .../31-libxcb-randr0_1.14-2_amd64.deb ...\n",
      "Unpacking libxcb-randr0:amd64 (1.14-2) ...\n",
      "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
      "Preparing to unpack .../32-mesa-vulkan-drivers_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
      "Unpacking mesa-vulkan-drivers:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
      "Setting up libxcb-dri3-0:amd64 (1.14-2) ...\n",
      "Setting up libx11-xcb1:amd64 (2:1.6.9-2ubuntu1.6) ...\n",
      "Setting up libpciaccess0:amd64 (0.16-0ubuntu1) ...\n",
      "Setting up libxcb-xfixes0:amd64 (1.14-2) ...\n",
      "Setting up libglvnd0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
      "Setting up libxcb-glx0:amd64 (1.14-2) ...\n",
      "Setting up libsensors-config (1:3.6.0-2ubuntu1.1) ...\n",
      "Setting up libxcb-shm0:amd64 (1.14-2) ...\n",
      "Setting up libxxf86vm1:amd64 (1:1.1.4-1build1) ...\n",
      "Setting up libxcb-present0:amd64 (1.14-2) ...\n",
      "Setting up libxfixes3:amd64 (1:5.0.3-2) ...\n",
      "Setting up libxcb-sync1:amd64 (1.14-2) ...\n",
      "Setting up libllvm12:amd64 (1:12.0.0-3ubuntu1~20.04.5) ...\n",
      "Setting up libsensors5:amd64 (1:3.6.0-2ubuntu1.1) ...\n",
      "Setting up libglapi-mesa:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
      "Setting up libvulkan1:amd64 (1.2.131.2-1) ...\n",
      "Setting up libxcb-dri2-0:amd64 (1.14-2) ...\n",
      "Setting up libxshmfence1:amd64 (1.3-1) ...\n",
      "Setting up libxcb-randr0:amd64 (1.14-2) ...\n",
      "Setting up libdrm-common (2.4.107-8ubuntu1~20.04.2) ...\n",
      "Setting up libelf1:amd64 (0.176-1.1ubuntu0.1) ...\n",
      "Setting up libwayland-client0:amd64 (1.18.0-1ubuntu0.1) ...\n",
      "Setting up libdrm2:amd64 (2.4.107-8ubuntu1~20.04.2) ...\n",
      "Setting up libdrm-amdgpu1:amd64 (2.4.107-8ubuntu1~20.04.2) ...\n",
      "Setting up mesa-vulkan-drivers:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
      "Setting up libdrm-nouveau2:amd64 (2.4.107-8ubuntu1~20.04.2) ...\n",
      "Setting up libdrm-radeon1:amd64 (2.4.107-8ubuntu1~20.04.2) ...\n",
      "Setting up libdrm-intel1:amd64 (2.4.107-8ubuntu1~20.04.2) ...\n",
      "Setting up libgl1-mesa-dri:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
      "Setting up libglx-mesa0:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
      "Setting up libglx0:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
      "Setting up libgl1:amd64 (1.3.2-1~ubuntu0.20.04.2) ...\n",
      "Setting up libgl1-mesa-glx:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get update -qq\n",
    "!apt-get install -y libgl1-mesa-glx -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5df29a-5aca-4184-9804-07d8549d873b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ControlNet-XS' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/vislearn/ControlNet-XS -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f529887-84c9-4e94-9eff-da6db4421fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf diffusers\n",
    "!git clone https://github.com/UmerHA/diffusers.git --branch controlnet-xs -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65ed5de-0c21-4916-b808-5d344e208c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r ControlNet-XS/requirements/pt2.txt -qq\n",
    "!pip install -e ControlNet-XS -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb87187d-4c6f-427b-9399-ca88d46fabb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -Uqq transformers\n",
    "!pip install diffusers -e diffusers -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f25800-ed8d-4090-b01a-bf18fcbe4944",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb4d4bb-a139-4270-bf10-796e2b304fed",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1231abe-d52d-410f-a289-61ec5b3b9b9a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "Restart kernel here, so newly installed packages are available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b74b9e-7bbc-41ff-bc01-3d3055570a57",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a43bd7c1-8c6b-4f3c-bf65-5398fdbbdc51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # needed to make torch deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c1c7d13-020e-4053-9754-7f2bf5b4829f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name vit_base_resnet50_384 to current vit_base_r50_s16_384.orig_in21k_ft_in1k.\n",
      "  model = create_fn(\n"
     ]
    }
   ],
   "source": [
    "import scripts.control_utils as cu\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aad3a198-093b-46fa-9cda-a13750fc9aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be14a47f-ac71-4e60-a52f-4befa3fb0b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_config = 'ControlNet-XS/configs/inference/sdxl/sdxl_encD_canny_48m.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6552dd-0ad5-4db2-b1a6-3c9b8ca55f4f",
   "metadata": {},
   "source": [
    "If this results in the kernel crashing, I'm using too much GPU memory elsewhere. Shut down every other kernel and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70915bf0-38be-40e8-a791-23a6ded976ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a Downsample layer with 2 dims.\n",
      "  --> settings are: \n",
      " in-chn: 320, out-chn: 320, kernel-size: 3, stride: 2, padding: 1\n",
      "constructing SpatialTransformer of depth 2 w/ 640 channels and 10 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 2. Setting context_dim to [2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "constructing SpatialTransformer of depth 2 w/ 640 channels and 10 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 2. Setting context_dim to [2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "Building a Downsample layer with 2 dims.\n",
      "  --> settings are: \n",
      " in-chn: 640, out-chn: 640, kernel-size: 3, stride: 2, padding: 1\n",
      "constructing SpatialTransformer of depth 10 w/ 1280 channels and 20 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "constructing SpatialTransformer of depth 10 w/ 1280 channels and 20 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "constructing SpatialTransformer of depth 10 w/ 1280 channels and 20 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "constructing SpatialTransformer of depth 10 w/ 1280 channels and 20 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "constructing SpatialTransformer of depth 10 w/ 1280 channels and 20 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "constructing SpatialTransformer of depth 10 w/ 1280 channels and 20 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "constructing SpatialTransformer of depth 2 w/ 640 channels and 10 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 2. Setting context_dim to [2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "constructing SpatialTransformer of depth 2 w/ 640 channels and 10 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 2. Setting context_dim to [2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "constructing SpatialTransformer of depth 2 w/ 640 channels and 10 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 2. Setting context_dim to [2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "Building a Downsample layer with 2 dims.\n",
      "  --> settings are: \n",
      " in-chn: 352, out-chn: 32, kernel-size: 3, stride: 2, padding: 1\n",
      "constructing SpatialTransformer of depth 2 w/ 64 channels and 1 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 2. Setting context_dim to [2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "constructing SpatialTransformer of depth 2 w/ 64 channels and 1 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 2. Setting context_dim to [2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "Building a Downsample layer with 2 dims.\n",
      "  --> settings are: \n",
      " in-chn: 704, out-chn: 64, kernel-size: 3, stride: 2, padding: 1\n",
      "constructing SpatialTransformer of depth 10 w/ 128 channels and 2 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "constructing SpatialTransformer of depth 10 w/ 128 channels and 2 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "constructing SpatialTransformer of depth 10 w/ 128 channels and 2 heads\n",
      "WARNING: SpatialTransformer: Found context dims [2048] of depth 1, which does not match the specified 'depth' of 10. Setting context_dim to [2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048, 2048] now.\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "BasicTransformerBlock is using checkpointing\n",
      "Initialized embedder #0: FrozenCLIPEmbedder with 123060480 params. Trainable: False\n",
      "Initialized embedder #1: FrozenOpenCLIPEmbedder2 with 694659841 params. Trainable: False\n",
      "Initialized embedder #2: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Initialized embedder #3: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "Initialized embedder #4: ConcatTimestepEmbedderND with 0 params. Trainable: False\n",
      "making attention of type 'vanilla-xformers' with 512 in_channels\n",
      "building MemoryEfficientAttnBlock with 512 in_channels...\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla-xformers' with 512 in_channels\n",
      "building MemoryEfficientAttnBlock with 512 in_channels...\n",
      "Loaded model config from [ControlNet-XS/configs/inference/sdxl/sdxl_encD_canny_48m.yaml]\n"
     ]
    }
   ],
   "source": [
    "model = cu.create_model(path_to_config).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "722ce2e4-2e2b-4f4c-bc1e-8818a7ae7c4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size = 768\n",
    "num_samples=1\n",
    "prompt='cinematic, shoe in the streets, made from meat, photorealistic shoe, highly detailed'\n",
    "n_prompt='lowres, bad anatomy, worst quality, low quality'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05676d1d-23c9-4982-98e9-6142b876d136",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_canny_edges():\n",
    "    image_path = 'input_images/shoe.png' # chosen to fit size above\n",
    "    image = cu.get_image(image_path, size=size)\n",
    "    edges = cu.get_canny_edges(image, low_th=100, high_th=250)\n",
    "    return edges\n",
    "edges = get_canny_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "233ab7f5-b836-4bcf-a413-80f642cd63e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.model.DEBUG_LOG_by_Umer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d8acd0-c2a2-4171-a53c-cc49f5842750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb106f6a-933b-49d3-b85d-642e01e814c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1999158951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CONTROL CORRECTION OF ControlledDiffusionEngine SCALED WITH 0.95]\n",
      ">>> These are the embedders that are hard at working:\n",
      "Embedder FrozenCLIPEmbedder       , output 0: Initialized  crossattn. It has now shape [1, 77, 768]\n",
      "--\n",
      "Embedder FrozenOpenCLIPEmbedder2  , output 0: Concatted to crossattn. It has now shape [1, 77, 2048]\n",
      "Embedder FrozenOpenCLIPEmbedder2  , output 1: Initialized  vector   . It has now shape [1, 1280]\n",
      "--\n",
      "Where are inside ConcatTimestepEmbedderND, lets forward\n",
      "- x.shape before rearrage = [1, 2]\n",
      "- x.shape after rearrange = [2]\n",
      "- emb.shape before rearrange = [2, 256]\n",
      "- emb.shape after rearrange = [1, 512]\n",
      "Embedder ConcatTimestepEmbedderND , output 0: Concatted to vector   . It has now shape [1, 1792]\n",
      "--\n",
      "Where are inside ConcatTimestepEmbedderND, lets forward\n",
      "- x.shape before rearrage = [1, 2]\n",
      "- x.shape after rearrange = [2]\n",
      "- emb.shape before rearrange = [2, 256]\n",
      "- emb.shape after rearrange = [1, 512]\n",
      "Embedder ConcatTimestepEmbedderND , output 0: Concatted to vector   . It has now shape [1, 2304]\n",
      "--\n",
      "Where are inside ConcatTimestepEmbedderND, lets forward\n",
      "- x.shape before rearrage = [1, 2]\n",
      "- x.shape after rearrange = [2]\n",
      "- emb.shape before rearrange = [2, 256]\n",
      "- emb.shape after rearrange = [1, 512]\n",
      "Embedder ConcatTimestepEmbedderND , output 0: Concatted to vector   . It has now shape [1, 2816]\n",
      "--\n",
      "<<<\n",
      "\n",
      "\n",
      ">>> These are the embedders that are hard at working:\n",
      "Embedder FrozenCLIPEmbedder       , output 0: Initialized  crossattn. It has now shape [1, 77, 768]\n",
      "--\n",
      "Embedder FrozenOpenCLIPEmbedder2  , output 0: Concatted to crossattn. It has now shape [1, 77, 2048]\n",
      "Embedder FrozenOpenCLIPEmbedder2  , output 1: Initialized  vector   . It has now shape [1, 1280]\n",
      "--\n",
      "Where are inside ConcatTimestepEmbedderND, lets forward\n",
      "- x.shape before rearrage = [1, 2]\n",
      "- x.shape after rearrange = [2]\n",
      "- emb.shape before rearrange = [2, 256]\n",
      "- emb.shape after rearrange = [1, 512]\n",
      "Embedder ConcatTimestepEmbedderND , output 0: Concatted to vector   . It has now shape [1, 1792]\n",
      "--\n",
      "Where are inside ConcatTimestepEmbedderND, lets forward\n",
      "- x.shape before rearrage = [1, 2]\n",
      "- x.shape after rearrange = [2]\n",
      "- emb.shape before rearrange = [2, 256]\n",
      "- emb.shape after rearrange = [1, 512]\n",
      "Embedder ConcatTimestepEmbedderND , output 0: Concatted to vector   . It has now shape [1, 2304]\n",
      "--\n",
      "Where are inside ConcatTimestepEmbedderND, lets forward\n",
      "- x.shape before rearrage = [1, 2]\n",
      "- x.shape after rearrange = [2]\n",
      "- emb.shape before rearrange = [2, 256]\n",
      "- emb.shape after rearrange = [1, 512]\n",
      "Embedder ConcatTimestepEmbedderND , output 0: Concatted to vector   . It has now shape [1, 2816]\n",
      "--\n",
      "<<<\n",
      "\n",
      "\n",
      "Type of sampler:  <class 'sgm.modules.diffusionmodules.sampling.EulerEDMSampler'>\n",
      "timesteps = tensor([999, 999], device='cuda:0')\n",
      "t_emb = [2, 320]\n",
      "t_emb: dim 0 = dim 1?  tensor(True, device='cuda:0')\n",
      "emb = [2, 1280]\n",
      "emb: dim 0 = dim 1?  tensor(True, device='cuda:0')\n",
      "added label emb\n",
      "emb = [2, 1280]\n",
      "emb: dim 0 = dim 1?  tensor(False, device='cuda:0')\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n",
      "btw: use_scale_shift_norm = False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Debug Log saved successfully",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m samples, controls, latents \u001b[38;5;241m=\u001b[39m \u001b[43mcu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sdxl_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mguidance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mddim_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontrol_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_latents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ControlNet-XS/scripts/control_utils.py:221\u001b[0m, in \u001b[0;36mget_sdxl_sample\u001b[0;34m(guidance, model, num_samples, seed, scale, eta, ddim_steps, prompt, idx, control_scale, shape, n_prompt, return_latents)\u001b[0m\n\u001b[1;32m    218\u001b[0m         c[k], uc[k] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m y: y[k]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m), (c, uc))\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m model\u001b[38;5;241m.\u001b[39mema_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlotting\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 221\u001b[0m     samples, latents \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msampling_kwargs\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m x_samples \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecode_first_stage(samples)\n\u001b[1;32m    226\u001b[0m x_samples \u001b[38;5;241m=\u001b[39m (einops\u001b[38;5;241m.\u001b[39mrearrange(\n\u001b[1;32m    227\u001b[0m     x_samples, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb c h w -> b h w c\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    228\u001b[0m ) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m127.5\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m127.5\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mclip(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/models/diffusion.py:249\u001b[0m, in \u001b[0;36mDiffusionEngine.sample\u001b[0;34m(self, cond, uc, batch_size, shape, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m denoiser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28minput\u001b[39m, sigma, c: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdenoiser(\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28minput\u001b[39m, sigma, c, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    247\u001b[0m )\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType of sampler: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler))\n\u001b[0;32m--> 249\u001b[0m samples, latents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdenoiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m latents \u001b[38;5;241m=\u001b[39m [randn] \u001b[38;5;241m+\u001b[39m latents \u001b[38;5;66;03m# Debug Umer\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m samples, latents\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/modules/diffusionmodules/sampling.py:125\u001b[0m, in \u001b[0;36mEDMSampler.__call__\u001b[0;34m(self, denoiser, x, cond, uc, num_steps)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sigma_gen(num_sigmas):\n\u001b[1;32m    120\u001b[0m     gamma \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    121\u001b[0m         \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms_churn \u001b[38;5;241m/\u001b[39m (num_sigmas \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms_tmin \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m sigmas[i] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms_tmax\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms_in\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msigmas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms_in\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msigmas\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdenoiser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43muc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     latents\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, latents\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/modules/diffusionmodules/sampling.py:102\u001b[0m, in \u001b[0;36mEDMSampler.sampler_step\u001b[0;34m(self, sigma, next_sigma, denoiser, x, cond, uc, gamma)\u001b[0m\n\u001b[1;32m     99\u001b[0m     eps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms_noise\n\u001b[1;32m    100\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m eps \u001b[38;5;241m*\u001b[39m append_dims(sigma_hat\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m sigma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, x\u001b[38;5;241m.\u001b[39mndim) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m--> 102\u001b[0m denoised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenoiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m d \u001b[38;5;241m=\u001b[39m to_d(x, sigma_hat, denoised)\n\u001b[1;32m    104\u001b[0m dt \u001b[38;5;241m=\u001b[39m append_dims(next_sigma \u001b[38;5;241m-\u001b[39m sigma_hat, x\u001b[38;5;241m.\u001b[39mndim)\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/modules/diffusionmodules/sampling.py:58\u001b[0m, in \u001b[0;36mBaseDiffusionSampler.denoise\u001b[0;34m(self, x, denoiser, sigma, cond, uc)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdenoise\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, denoiser, sigma, cond, uc):\n\u001b[0;32m---> 58\u001b[0m     denoised \u001b[38;5;241m=\u001b[39m \u001b[43mdenoiser\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m     denoised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mguider(denoised, sigma)\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m denoised\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/models/diffusion.py:245\u001b[0m, in \u001b[0;36mDiffusionEngine.sample.<locals>.<lambda>\u001b[0;34m(input, sigma, c)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    242\u001b[0m ):\n\u001b[1;32m    243\u001b[0m     randn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch_size, \u001b[38;5;241m*\u001b[39mshape)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 245\u001b[0m     denoiser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28minput\u001b[39m, sigma, c: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdenoiser\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType of sampler: \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler))\n\u001b[1;32m    249\u001b[0m     samples, latents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler(denoiser, randn, cond, uc\u001b[38;5;241m=\u001b[39muc)\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/modules/diffusionmodules/denoiser.py:93\u001b[0m, in \u001b[0;36mControlledDiscreteDenoiser.__call__\u001b[0;34m(self, network, input, sigma, cond, hint)\u001b[0m\n\u001b[1;32m     91\u001b[0m c_skip, c_out, c_in, c_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling(sigma)\n\u001b[1;32m     92\u001b[0m c_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpossibly_quantize_c_noise(c_noise\u001b[38;5;241m.\u001b[39mreshape(sigma_shape))\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhint\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m c_out \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m c_skip\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/modules/diffusionmodules/twoStreamControl.py:287\u001b[0m, in \u001b[0;36mTwoStreamControlNet.forward\u001b[0;34m(self, x, t, c, hint, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m hint\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    286\u001b[0m     hint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([hint, hint], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcrossattn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiffusion_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# True if self.control_mode == 'midas' else False,\u001b[39;49;00m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/modules/diffusionmodules/twoStreamControl.py:457\u001b[0m, in \u001b[0;36mTwoStreamControlNet.forward_\u001b[0;34m(self, x, hint, timesteps, context, base_model, y, precomputed_hint, no_control, compute_hint, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n\u001b[0;32m--> 457\u001b[0m \u001b[43mdebug_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m h_base \u001b[38;5;241m=\u001b[39m h_base\u001b[38;5;241m.\u001b[39mtype(x\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m base_model\u001b[38;5;241m.\u001b[39mout(h_base)\n",
      "File \u001b[0;32m~/ControlNet-XS/sgm/modules/diffusionmodules/twoStreamControl.py:365\u001b[0m, in \u001b[0;36mTwoStreamControlNet.forward_.<locals>.debug_save\u001b[0;34m()\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m    364\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(debug_log, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdebug_log.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 365\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebug Log saved successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Debug Log saved successfully"
     ]
    }
   ],
   "source": [
    "samples, controls, latents = cu.get_sdxl_sample(\n",
    "    guidance=edges,\n",
    "    ddim_steps=10,\n",
    "    num_samples=num_samples,\n",
    "    model=model,\n",
    "    shape=[4, size // 8, size // 8],\n",
    "    control_scale=0.95,\n",
    "    prompt=prompt,\n",
    "    n_prompt=n_prompt,\n",
    "    return_latents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4a991c-7dc9-4536-b1ca-927e531ceded",
   "metadata": {
    "tags": []
   },
   "source": [
    "Cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6410ce7c-5bba-4b85-8e62-440e6efe23d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0] FrozenCLIPEmbedder            - input key(s) = caption\n",
      "1] FrozenOpenCLIPEmbedder2       - input key(s) = caption\n",
      "2] ConcatTimestepEmbedderND      - input key(s) = original_size_as_tuple\n",
      "3] ConcatTimestepEmbedderND      - input key(s) = crop_coords_top_left\n",
      "4] ConcatTimestepEmbedderND      - input key(s) = target_size_as_tuple\n"
     ]
    }
   ],
   "source": [
    "def cls_name(o): return str(type(o)).replace(\"< class'\",\"\").replace(\"'>\",\"\").split('.')[-1]\n",
    "\n",
    "for i,m in enumerate(model.conditioner.embedders):\n",
    "    k = m.input_key if hasattr(m,'input_key') else m.input_keys\n",
    "    print(f\"{i}] {cls_name(m):<25}     - input key(s) = {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a70c303-4057-45f0-87fd-cea4e238effa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConcatTimestepEmbedderND(\n",
       "  (timestep): Timestep()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conditioner.embedders[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26151e6b-8583-4daa-b93c-846af8995a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConcatTimestepEmbedderND(\n",
       "  (timestep): Timestep()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conditioner.embedders[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "458495ca-4a6c-4b79-a6f7-ef2a95ee6ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConcatTimestepEmbedderND(\n",
       "  (timestep): Timestep()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conditioner.embedders[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "372210ca-d40c-461a-9bc5-6569896ad0e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dim of ConcatTimestepEmbedderND at 2: 512\n",
      "Dim of ConcatTimestepEmbedderND at 3: 512\n",
      "Dim of ConcatTimestepEmbedderND at 4: 512\n"
     ]
    }
   ],
   "source": [
    "conditional_vector_szs = (1280,1792,2304,2816)\n",
    "for i in range(3):\n",
    "    print(f'Dim of ConcatTimestepEmbedderND at {2+i}: ',end='')\n",
    "    print(conditional_vector_szs[i+1]-conditional_vector_szs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4e910-6361-4e86-aa37-b10a337cc448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd04ae12-c1cc-498b-b086-cfd5027ab669",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "1.0\n",
      "Sequential(\n",
      "  (0): Linear(in_features=320, out_features=1280, bias=True)\n",
      "  (1): SiLU()\n",
      "  (2): Linear(in_features=1280, out_features=1280, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.model.diffusion_model.input_blocks[1][0].use_scale_shift_norm)\n",
    "print(model.model.learn_embedding)\n",
    "print(model.model.control_scale)\n",
    "print(model.model.control_model.time_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb095451-3b3d-4335-9a93-b24cdf27defd",
   "metadata": {},
   "source": [
    "Create guidance info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d14ac44-e1fc-4885-8476-827ccea361f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hint -> [768, 768]\n",
      "crop_coords_top_left -> [2]\n",
      "original_size_as_tuple -> [2]\n",
      "target_size_as_tuple -> [2]\n"
     ]
    }
   ],
   "source": [
    "my_guidance = edges\n",
    "\n",
    "my_ds = {\n",
    "    'hint': my_guidance,\n",
    "    'crop_coords_top_left': torch.tensor([0, 0]),\n",
    "    'original_size_as_tuple': torch.tensor(my_guidance.shape[-2:]),\n",
    "    'target_size_as_tuple': torch.tensor(my_guidance.shape[-2:]),\n",
    "}\n",
    "\n",
    "for k,v in my_ds.items(): print(k,'->',list(v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db59e11-b264-49fd-8282-929117f419dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "In addition to the `hint` image, SDXL was also conditionned on `crop_coords_top_left`, `original_size_as_tuple`, `target_size_as_tuple`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2502625a-e642-472f-b97a-0170a2341f0d",
   "metadata": {},
   "source": [
    "Make them batch-ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09376de6-87b1-48ee-a3f2-64b038e69e8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_batch = cu.get_batch(ds_instance=my_ds, num_samples=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f747a649-768f-4bed-b306-35310242ad7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hint -> [1, 768, 768]\n",
      "crop_coords_top_left -> [1, 2]\n",
      "original_size_as_tuple -> [1, 2]\n",
      "target_size_as_tuple -> [1, 2]\n"
     ]
    }
   ],
   "source": [
    "for k,v in my_batch.items(): print(k,'->',list(v.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd561dc-b54d-4a97-a637-bd6db4e11ac7",
   "metadata": {},
   "source": [
    "Add prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1b7a146-d9ea-4c4c-8f64-d795c620f1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_batch['caption'] = [prompt or my_ds['caption']] * num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe8ea2df-1395-4195-a2b5-bebd6ea0e513",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hint -> [1, 768, 768]\n",
      "crop_coords_top_left -> [1, 2]\n",
      "original_size_as_tuple -> [1, 2]\n",
      "target_size_as_tuple -> [1, 2]\n",
      "caption -> 1\n"
     ]
    }
   ],
   "source": [
    "for k,v in my_batch.items(): print(k,'->',(list(v.shape) if hasattr(v,'shape') else len(v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7533086a-7f58-471b-b11f-0cc79402531c",
   "metadata": {},
   "source": [
    "To cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f034f108-8e7f-49b9-aa36-c3fdbe507eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k in my_batch:\n",
    "    if isinstance(my_batch[k], torch.Tensor):\n",
    "        my_batch[k] = my_batch[k].to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c022c3-eada-4f16-812a-2c1af0f2be5a",
   "metadata": {},
   "source": [
    "Same for negative prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "179ae867-35ce-4a4e-b3d9-015524fdf77d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d60ed933-f89f-4355-b652-f40eaed5f4ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_batch_uc = copy.deepcopy(my_batch)\n",
    "my_batch_uc['caption'] = [n_prompt] * num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34434ca7-d7e0-4fe5-970c-089edfeea364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_c, my_uc = model.conditioner.get_unconditional_conditioning(\n",
    "    my_batch,\n",
    "    batch_uc=my_batch_uc,\n",
    "    force_uc_zero_embeddings=None if len(model.conditioner.embedders) > 0 else [],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d51896f-22af-4091-93cd-5698dd0cb86d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['crossattn', 'vector'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_c.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41495bc-4cd7-4d1a-ac19-e4e706e0b3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "480240a2-2575-4534-a5a1-276227621bf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fac275-a6c4-4c4f-aa4b-6f8a6969c27d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d4b41-e0ac-4ea9-9683-7608c50a5322",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9051cd-9c93-4476-bdb8-59572181c8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
    "device_dtype = torch.float16 if device == 'cuda' else torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89426d73-4a03-4bd1-b2b1-8f6d7b97347d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "from diffusers.models.controlnetxs import ControlNetXSModel\n",
    "from diffusers.pipelines.controlnet_xs.pipeline_controlnet_xs_sd_xl import StableDiffusionXLControlNetXSPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f66143-1980-4a55-a5e3-74262061a613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdxl_pipe = StableDiffusionXLPipeline.from_single_file('weights/sd_xl_base_1.0_0.9vae.safetensors').to(device)\n",
    "cnxs = ControlNetXSModel.from_pretrained('weights/cnxs').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7009f9cd-925a-4f25-8446-ccf0b48999d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxs.scale_list = cnxs.scale_list * 0. + 0.95\n",
    "cnxs.base_model = sdxl_pipe.unet\n",
    "sdxl_pipe.scheduler.config.timestep_spacing = 'linspace'\n",
    "sdxl_pipe.scheduler = EulerDiscreteScheduler.from_config(sdxl_pipe.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b123f-9528-4686-aa25-4b48960ae5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxs_pipe = StableDiffusionXLControlNetXSPipeline(\n",
    "    vae=sdxl_pipe.vae,\n",
    "    text_encoder=sdxl_pipe.text_encoder,\n",
    "    text_encoder_2=sdxl_pipe.text_encoder_2,\n",
    "    tokenizer=sdxl_pipe.tokenizer,\n",
    "    tokenizer_2=sdxl_pipe.tokenizer_2,\n",
    "    unet=sdxl_pipe.unet,\n",
    "    controlnet=cnxs,\n",
    "    scheduler=sdxl_pipe.scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbdaaac-995e-4075-bc60-84772b89d964",
   "metadata": {},
   "source": [
    "### Load intermediate outputs of whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f44404-190f-4e57-9461-27fa29b0a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_inspect import load_intermediate_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed206ee7-c62c-4cf4-98d8-0415709a214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outp_local = load_intermediate_outputs('intermediate_output/local_debug_log.pkl')\n",
    "model_outp_cloud = load_intermediate_outputs('intermediate_output/cloud_debug_log.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0800026f-cc5b-463f-ac23-2dfdd93b7efd",
   "metadata": {},
   "source": [
    "### Load intermediate outputs of 1st resnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602acaba-3cdf-4818-9467-5fa7045d30dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
