{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a718e1-28e9-4766-9973-9207da3f986a",
   "metadata": {},
   "source": [
    "In this notebook, I want to map the modules of cnxs' unet and diffusers' onto each other. When done, I should be able to load diffuser weights into cnxs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0efad4-daef-4c45-b6b6-276d1de06161",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "680cf02d-fcaa-4d11-8925-cb973e7b6039",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -Uqq transformers diffusers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab1ff2fc-41ba-4b77-82de-d76165e1f377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a08b518-d2d6-4251-b65f-fdb1aba792be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers.models import AutoencoderKL\n",
    "from diffusers import StableDiffusionXLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70686595-366a-4c49-91f5-7b044fc72fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "vae = AutoencoderKL.from_pretrained(\"stabilityai/sdxl-vae\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e0ec2d2-18c7-4504-af54-3ab4696be612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c156e103cc0842a6bd59d332d0fba198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = StableDiffusionXLPipeline.from_pretrained(model, vae=vae, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcce888-df2c-4cf5-b036-413d31664712",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc05ad01-2844-4ae9-a07f-8f88e90c6fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict(d, ignore_bias=True):\n",
    "    root = {}\n",
    "    for k,v in d.items():\n",
    "        if 'bias' in k: continue\n",
    "        parts = k.replace('.weight','').split(\".\")\n",
    "        d = root\n",
    "        for part in parts[:-1]:\n",
    "            d = d.setdefault(part, {})\n",
    "        d[parts[-1]] = v \n",
    "    return root\n",
    "\n",
    "def pretty_print_dict(d,lv=2,indent=0,depth=1):\n",
    "    if lv is not None and depth > lv: return\n",
    "    if not isinstance(d,dict):\n",
    "        print(d)\n",
    "        return\n",
    "    for k,v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            print('  ' * indent + str(k))\n",
    "            pretty_print_dict(v,lv,indent+2,depth+1)\n",
    "        else: \n",
    "            print('  ' * indent + str(k) + ' -> ' + str(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b110f-4ff9-47a6-adaf-a38d84f7cace",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c850341-8974-49c2-986a-6c2c2c2e8bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_shape(o):\n",
    "    if isinstance(o,dict): return {k:to_shape(v) for k,v in o.items()}\n",
    "    elif isinstance(o,list): return o\n",
    "    else: return list(o.shape)\n",
    "\n",
    "def remove_bias(o):\n",
    "    if isinstance(o,dict): return {k.replace('.weight',''):remove_bias(v) for k,v in o.items() if not 'bias' in k}\n",
    "    else: return o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab290585-c9eb-4b3c-8e6f-4b66a3a74ae3",
   "metadata": {},
   "source": [
    "Load unet from CNXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18fbc6e8-a9fc-43be-ac55-7594f97a6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05043d7d-50e9-47e2-b76c-6ca8b55d7ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cnsx_base_state_dict_with_shapes.json', 'r') as infile:\n",
    "    cn_sdict = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d186b3c0-1fd1-4186-9fe6-7239929472b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_sdict = remove_bias(to_shape(cn_sdict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f1919e-fcab-4a25-a3f1-bc8103a8324b",
   "metadata": {},
   "source": [
    "Load unet from diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76e7816d-c4d8-452a-aa43-fa60a635222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sdict = remove_bias(to_shape(pipe.unet.state_dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d38d7fb-cde0-4f48-9a1d-cc584fb4be1a",
   "metadata": {},
   "source": [
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f62d4a0f-d901-47c5-8738-1282e185a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_bak = cn_sdict.copy()\n",
    "df_bak = df_sdict.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2244043-fdd2-4c37-98bd-855b24ffa072",
   "metadata": {},
   "source": [
    "### First goal: Map one resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "c27daf3c-272a-4e8c-9de8-965cee58bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MappedModule:\n",
    "    cn: str\n",
    "    df: str\n",
    "    shape: list\n",
    "    def __repr__(self): return f'{self.df} {self.shape}'\n",
    "\n",
    "\n",
    "class UnmappedModel:\n",
    "    # contains dict of style {'down_blocks.0.resnets.0': [4, 64, 64]}\n",
    "    def __init__(self, modules): self.modules = modules\n",
    "    def print(self, contains='', lv=None): pretty_print_dict(nested_dict(filter_dict(self.modules,by=contains)), lv=lv)\n",
    "    def remove(self,k): del self.modules[k]\n",
    "    def __getitem__(self,k): return self.modules[k]\n",
    "    def __len__(self): return len(self.modules)\n",
    "    def has(self,k): return any(k==k_ for k_ in self.modules.keys())\n",
    "\n",
    "def filter_dict(d,by): return {k:v for k,v in d.items() if by in k}\n",
    "\n",
    "class MappedModel:\n",
    "    modules = []\n",
    "\n",
    "    def __init__(self, unmapped_cn, unmapped_df):\n",
    "        self.unmapped_cn=UnmappedModel(unmapped_cn)\n",
    "        self.unmapped_df=UnmappedModel(unmapped_df)\n",
    "    \n",
    "    def add(self, cn_module, df_module):\n",
    "        # check shapes\n",
    "        cn_shape = self.unmapped_cn[cn_module]\n",
    "        df_shape = self.unmapped_df[df_module]\n",
    "        assert cn_shape==df_shape, f'Mapping don\\'t fit: {cn_shape} != {df_shape}'\n",
    "        # add to mapped\n",
    "        self.modules = sorted(self.modules + [MappedModule(cn=cn_module,df=df_module,shape=cn_shape)], key=lambda o:o.df)\n",
    "        # remove from unmapped\n",
    "        self.unmapped_cn.remove(cn_module)\n",
    "        self.unmapped_df.remove(df_module)\n",
    "        #print(f'Added {df_module} âœ…')\n",
    "        \n",
    "    def __repr__(self): return '\\n'.join(str(m) for m in self.modules)\n",
    "    def __len__(self): return len(self.modules)\n",
    "\n",
    "    def __getitem__(self,k):\n",
    "        for m in self.modules:\n",
    "            if m.df==k: return m.cn\n",
    "        raise ValueError(f\"Didn't find  module with name {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c05ed78-5af2-4006-8278-35d74a15197e",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "abbfa527-eb22-4b05-91ff-f2e4a86bb2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = cn_bak.copy()\n",
    "df = df_bak.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "58b4cb68-c408-4909-8e38-d9a0fb1cf56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped = MappedModel(cn,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "f000c370-6f0f-4655-bbba-4717cdab9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_unmapped = UnmappedModel(cn)\n",
    "df_unmapped = UnmappedModel(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "550ec0d1-aa39-41e3-8641-7035ae079055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1050, 1050)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped), len(cn_unmapped), len(df_unmapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e0ea4-869a-474f-b124-ed754a24e8d9",
   "metadata": {},
   "source": [
    "#### Let's map the downblocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e31f6-e2d5-4923-b83c-0568305a5237",
   "metadata": {},
   "source": [
    "**Note:** The number of tranformer blocks varies between attentions. In downlock 1, there are 2, in downblock 2 each, there are 10 each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "3500e242-9eae-40d3-bf41-7ee96c7a856a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(pipe.unet.down_blocks[1].attentions[0].transformer_blocks))\n",
    "print(len(pipe.unet.down_blocks[1].attentions[1].transformer_blocks))\n",
    "print(len(pipe.unet.down_blocks[2].attentions[0].transformer_blocks))\n",
    "print(len(pipe.unet.down_blocks[2].attentions[1].transformer_blocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "d8207950-985f-4eb7-a5f5-68b028c6df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_resnet(idx):\n",
    "    d1,d2,c=idx\n",
    "    cn_path = f'input_blocks.{c}.0.'\n",
    "    df_path = f'down_blocks.{d1}.resnets.{d2}.'\n",
    "    mapped.add(cn_module=cn_path+'in_layers.0',df_module=df_path+'norm1')\n",
    "    mapped.add(cn_module=cn_path+'in_layers.2',df_module=df_path+'conv1')\n",
    "    mapped.add(cn_module=cn_path+'emb_layers.1',df_module=df_path+'time_emb_proj')\n",
    "    mapped.add(cn_module=cn_path+'out_layers.0',df_module=df_path+'norm2')\n",
    "    mapped.add(cn_module=cn_path+'out_layers.3',df_module=df_path+'conv2')\n",
    "    if mapped.unmapped_df.has(df_path+'conv_shortcut'): mapped.add(cn_module=cn_path+'skip_connection',df_module=df_path+'conv_shortcut')\n",
    "\n",
    "def map_attn(idx):\n",
    "    d1,d2,c=idx\n",
    "    cn_path = f'input_blocks.{c}.1.'\n",
    "    df_path = f'down_blocks.{d1}.attentions.{d2}.'\n",
    "    mapped.add(cn_module=cn_path+'norm',df_module=df_path+'norm')\n",
    "    mapped.add(cn_module=cn_path+'proj_in',df_module=df_path+'proj_in')\n",
    "    num_tfs = 10 if d1==2 else 2 # attns in down block 2 have 10 tranformers each\n",
    "    for i in range(num_tfs): map_tfmr(f'{cn_path}transformer_blocks.{i}.',f'{df_path}transformer_blocks.{i}.')        \n",
    "    mapped.add(cn_module=cn_path+'proj_out',df_module=df_path+'proj_out')\n",
    "\n",
    "def map_tfmr(cn_path,df_path):\n",
    "    # nomenclature of tranformers is equal in cnxs and diffuers\n",
    "    modules = [\n",
    "        'norm1',\n",
    "        'attn1.to_q','attn1.to_k','attn1.to_v','attn1.to_out.0',\n",
    "        'norm2',\n",
    "        'attn2.to_q','attn2.to_k','attn2.to_v','attn2.to_out.0',\n",
    "        'norm3',\n",
    "        'ff.net.0.proj','ff.net.2'\n",
    "    ]\n",
    "    for m in modules: mapped.add(cn_path+m,df_path+m)\n",
    "\n",
    "def map_downsample(idx):\n",
    "    d,c=idx\n",
    "    cn_path = f'input_blocks.{c}.0.'\n",
    "    df_path = f'down_blocks.{d}.downsamplers.0.'\n",
    "    mapped.add(cn_module=cn_path+'op',df_module=df_path+'conv')\n",
    "    \n",
    "def map_down_block():\n",
    "    # # resnets\n",
    "    idx = (\n",
    "        (0,0,1),(0,1,2), # down block 0\n",
    "        (1,0,4),(1,1,5), # down block 1\n",
    "        (2,0,7),(2,1,8), # down block 2\n",
    "    )\n",
    "    for i in idx: map_resnet(i)\n",
    "    print(f'Mapped {len(idx)} Resnet blocks')\n",
    "    # # attentions\n",
    "    idx = (\n",
    "        (1,0,4),(1,1,5), # down block 1\n",
    "        (2,0,7),(2,1,8), # down block 2\n",
    "    )\n",
    "    for i in idx: map_attn(i)\n",
    "    print(f'Mapped {len(idx)} Attention blocks')\n",
    "    # # downsamplers\n",
    "    idx = (\n",
    "        (0,3), # down block 0\n",
    "        (1,6), # down block 1\n",
    "    )\n",
    "    for i in idx: map_downsample(i)\n",
    "    print(f'Mapped {len(idx)} Downsamplers blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "46e1eff5-3264-4697-8e3d-c027054bc4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped 6 Resnet blocks\n",
      "Mapped 4 Attention blocks\n",
      "Mapped 2 Downsamplers blocks\n"
     ]
    }
   ],
   "source": [
    "map_down_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "ab9a441e-c5fe-49fa-8059-22c7f9732eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(358, 692, 692)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped), len(cn_unmapped), len(df_unmapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b833c517-5220-45c1-abe6-3f9494c5694d",
   "metadata": {},
   "source": [
    "#### Let's map the embeds, and in/outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "33dafd08-c1d2-4d8b-9675-d8cca59fd1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_conv_in():\n",
    "    mapped.add(cn_module='input_blocks.0.0',df_module='conv_in')\n",
    "\n",
    "def map_conv_out():\n",
    "    mapped.add(cn_module='out.0',df_module='conv_norm_out')\n",
    "    mapped.add(cn_module='out.2',df_module='conv_out')    \n",
    "\n",
    "def map_embedds():\n",
    "    mapped.add(cn_module='time_embed.0',df_module='time_embedding.linear_1')\n",
    "    mapped.add(cn_module='time_embed.2',df_module='time_embedding.linear_2')\n",
    "    mapped.add(cn_module='label_emb.0.0',df_module='add_embedding.linear_1')\n",
    "    mapped.add(cn_module='label_emb.0.2',df_module='add_embedding.linear_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "d4f9c799-967e-461c-b142-938fce0cd8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_conv_in()\n",
    "map_conv_out()\n",
    "map_embedds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "ef6d42c4-cec2-4ace-9f52-69d215911b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 685, 685)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped), len(cn_unmapped), len(df_unmapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06618283-e3c4-4547-bce6-c3bc2cd72cf4",
   "metadata": {},
   "source": [
    "#### Let's map the middle block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "f5b8f082-9d5f-44ae-8e2d-59a836d96907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_resnet(d,c):\n",
    "    cn_path = f'middle_block.{c}.'\n",
    "    df_path = f'mid_block.resnets.{d}.'\n",
    "    mapped.add(cn_module=cn_path+'in_layers.0',df_module=df_path+'norm1')\n",
    "    mapped.add(cn_module=cn_path+'in_layers.2',df_module=df_path+'conv1')\n",
    "    mapped.add(cn_module=cn_path+'emb_layers.1',df_module=df_path+'time_emb_proj')\n",
    "    mapped.add(cn_module=cn_path+'out_layers.0',df_module=df_path+'norm2')\n",
    "    mapped.add(cn_module=cn_path+'out_layers.3',df_module=df_path+'conv2')\n",
    "    if mapped.unmapped_df.has(df_path+'conv_shortcut'): mapped.add(cn_module=cn_path+'skip_connection',df_module=df_path+'conv_shortcut')\n",
    "\n",
    "def map_attn(d,c):\n",
    "    cn_path = f'middle_block.{c}.'\n",
    "    df_path = f'mid_block.attentions.{d}.'\n",
    "    mapped.add(cn_module=cn_path+'norm',df_module=df_path+'norm')\n",
    "    mapped.add(cn_module=cn_path+'proj_in',df_module=df_path+'proj_in')\n",
    "    num_tfs = 10 # the attn has 10 tranformers each\n",
    "    for i in range(num_tfs): map_tfmr(f'{cn_path}transformer_blocks.{i}.',f'{df_path}transformer_blocks.{i}.')        \n",
    "    mapped.add(cn_module=cn_path+'proj_out',df_module=df_path+'proj_out')\n",
    "\n",
    "def map_tfmr(cn_path,df_path):\n",
    "    # nomenclature of tranformers is equal in cnxs and diffuers\n",
    "    modules = [\n",
    "        'norm1',\n",
    "        'attn1.to_q','attn1.to_k','attn1.to_v','attn1.to_out.0',\n",
    "        'norm2',\n",
    "        'attn2.to_q','attn2.to_k','attn2.to_v','attn2.to_out.0',\n",
    "        'norm3',\n",
    "        'ff.net.0.proj','ff.net.2'\n",
    "    ]\n",
    "    for m in modules: mapped.add(cn_path+m,df_path+m)\n",
    "\n",
    "def map_mid_block():\n",
    "    map_resnet(0,0)\n",
    "    map_attn(0,1)\n",
    "    map_resnet(1,2)\n",
    "    print(f'Mapped 2 Restnets and 1 Attention blocks (R/A/R)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "4932c3dd-709c-4a53-8a5a-ad175053c46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped 2 Restnets and 1 Attention blocks (R/A/R)\n"
     ]
    }
   ],
   "source": [
    "map_mid_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "be1b02b3-d883-420f-b49c-1bdccad0a507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(508, 542, 542)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped), len(cn_unmapped), len(df_unmapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138fd398-6565-49eb-82f1-5a0291aeb128",
   "metadata": {},
   "source": [
    "#### Let's map the up blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "e30387f8-339a-4eae-be93-5fc512aed388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2] | [3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "n_res_in_down = [len(pipe.unet.down_blocks[i].resnets) for i in (0,1,2)]\n",
    "n_res_in_up   = [len(pipe.unet.up_blocks  [i].resnets) for i in (0,1,2)]\n",
    "print(n_res_in_down, '|', n_res_in_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09b6ebb-4534-4b1b-bd01-5b61837237c6",
   "metadata": {},
   "source": [
    "In the up part, we have **3** resnets per block instead of 2 as in the down part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "46521a1b-24f4-4a7f-848b-15ad81d5e196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2] | [3, 3]\n"
     ]
    }
   ],
   "source": [
    "n_attn_in_down = [len(pipe.unet.down_blocks[i].attentions) for i in (1,2)]\n",
    "n_attn_in_up   = [len(pipe.unet.up_blocks  [i].attentions) for i in (0,1)]\n",
    "print(n_attn_in_down, '|', n_attn_in_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4edce3c-506d-4ecd-b19b-cdf843951220",
   "metadata": {},
   "source": [
    "Similarly, the number of attns is 3 instead of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "f0b00656-7f61-4073-85ec-60363391703e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10] | [2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "n_tf_in_up0 = [len(pipe.unet.up_blocks[0].attentions[a].transformer_blocks) for i in (0,1,2)]\n",
    "n_tf_in_up1 = [len(pipe.unet.up_blocks[1].attentions[a].transformer_blocks) for i in (0,1,2)]\n",
    "print(n_tf_in_up0, '|', n_tf_in_up1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072da8d2-24a4-43d3-8bc2-281ca1973f4e",
   "metadata": {},
   "source": [
    "As in the down part, the lowest block (here: bock 0) has 10 tranformers per attention, while the other block has 2 transformers per attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "a1ca3ace-b17b-445a-8115-53b5f9da1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_resnet(idx):\n",
    "    d1,d2,c=idx\n",
    "    cn_path = f'output_blocks.{c}.0.'\n",
    "    df_path = f'up_blocks.{d1}.resnets.{d2}.'\n",
    "    mapped.add(cn_module=cn_path+'in_layers.0',df_module=df_path+'norm1')\n",
    "    mapped.add(cn_module=cn_path+'in_layers.2',df_module=df_path+'conv1')\n",
    "    mapped.add(cn_module=cn_path+'emb_layers.1',df_module=df_path+'time_emb_proj')\n",
    "    mapped.add(cn_module=cn_path+'out_layers.0',df_module=df_path+'norm2')\n",
    "    mapped.add(cn_module=cn_path+'out_layers.3',df_module=df_path+'conv2')\n",
    "    if mapped.unmapped_df.has(df_path+'conv_shortcut'): mapped.add(cn_module=cn_path+'skip_connection',df_module=df_path+'conv_shortcut')\n",
    "\n",
    "def map_attn(idx):\n",
    "    d1,d2,c=idx\n",
    "    cn_path = f'output_blocks.{c}.1.'\n",
    "    df_path = f'up_blocks.{d1}.attentions.{d2}.'\n",
    "    mapped.add(cn_module=cn_path+'norm',df_module=df_path+'norm')\n",
    "    mapped.add(cn_module=cn_path+'proj_in',df_module=df_path+'proj_in')\n",
    "    num_tfs = 10 if d1==0 else 2 # attns in up block 0 have 10 tranformers each\n",
    "    for i in range(num_tfs): map_tfmr(f'{cn_path}transformer_blocks.{i}.',f'{df_path}transformer_blocks.{i}.')        \n",
    "    mapped.add(cn_module=cn_path+'proj_out',df_module=df_path+'proj_out')\n",
    "\n",
    "def map_tfmr(cn_path,df_path):\n",
    "    # nomenclature of tranformers is equal in cnxs and diffuers\n",
    "    modules = [\n",
    "        'norm1',\n",
    "        'attn1.to_q','attn1.to_k','attn1.to_v','attn1.to_out.0',\n",
    "        'norm2',\n",
    "        'attn2.to_q','attn2.to_k','attn2.to_v','attn2.to_out.0',\n",
    "        'norm3',\n",
    "        'ff.net.0.proj','ff.net.2'\n",
    "    ]\n",
    "    for m in modules: mapped.add(cn_path+m,df_path+m)\n",
    "\n",
    "def map_upsample(idx):\n",
    "    d,c=idx\n",
    "    cn_path = f'output_blocks.{c}.2.'\n",
    "    df_path = f'up_blocks.{d}.upsamplers.0.'\n",
    "    mapped.add(cn_module=cn_path+'conv',df_module=df_path+'conv')\n",
    "\n",
    "def map_up_block():\n",
    "    # # resnets\n",
    "    idx = (\n",
    "        (0,0,0),(0,1,1),(0,2,2), # up block 0\n",
    "        (1,0,3),(1,1,4),(1,2,5), # up block 1\n",
    "        (2,0,6),(2,1,7),(2,2,8), # up block 2\n",
    "    )\n",
    "    for i in idx: map_resnet(i)\n",
    "    print(f'Mapped {len(idx)} Resnet blocks')\n",
    "    # # attentions\n",
    "    idx = (\n",
    "        (0,0,0),(0,1,1),(0,2,2), # up block 0\n",
    "        (1,0,3),(1,1,4),(1,2,5), # up block 1\n",
    "    )\n",
    "    for i in idx: map_attn(i)\n",
    "    print(f'Mapped {len(idx)} Attention blocks')\n",
    "    # # downsamplers\n",
    "    idx = (\n",
    "        (0,2), # up block 0\n",
    "        (1,5), # up block 1\n",
    "    )\n",
    "    for i in idx: map_upsample(i)\n",
    "    print(f'Mapped {len(idx)} Upsamplers blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "a92aebdc-38e1-438f-8ffd-525e1ab5cead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped 9 Resnet blocks\n",
      "Mapped 6 Attention blocks\n",
      "Mapped 2 Upsamplers blocks\n"
     ]
    }
   ],
   "source": [
    "map_up_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "4d461102-1b1c-4d34-9039-8daa1d149d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 0, 0)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped), len(cn_unmapped), len(df_unmapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa6a861-5608-437c-9664-67a156653fac",
   "metadata": {},
   "source": [
    "**We are done!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "3cfad78d-0c6a-4a43-8a39-c242c2fef000",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_unmapped)==0\n",
    "assert len(cn_unmapped)==0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e54e78-fbc6-4b5d-af84-bd8533ae3451",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a9cf0d-4442-44bf-822a-4b9515af9903",
   "metadata": {},
   "source": [
    "Now, let's create the final mapping dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607702f8-b362-4c71-ab27-4bbaecbe38ec",
   "metadata": {},
   "source": [
    "Let's quickly check that all weights are actually mapped (if not, the below line will throw a ValueError)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "202da85b-2e35-4597-b3f0-0f8ae1f400f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in pipe.unet.state_dict().keys(): mapped[k.replace('.weight','').replace('.bias','')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa69392-a2fb-428d-aeea-da83a9378e1d",
   "metadata": {},
   "source": [
    "Works, cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "541ee1cf-1e53-4c8b-8939-812a86e426ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_mapping = {}\n",
    "for k in pipe.unet.state_dict().keys():\n",
    "    k_df = k.replace('.weight','').replace('.bias','')\n",
    "    k_cn = mapped[k_df]\n",
    "    state_dict_mapping[k_df+'.weight'] = k_cn+'.weight'\n",
    "    state_dict_mapping[k_df+'.bias'] = k_cn+'.bias'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "105345a2-3415-4b10-b5f0-890c6344181d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_in.weight': 'input_blocks.0.0.weight',\n",
       " 'conv_in.bias': 'input_blocks.0.0.bias',\n",
       " 'time_embedding.linear_1.weight': 'time_embed.0.weight',\n",
       " 'time_embedding.linear_1.bias': 'time_embed.0.bias',\n",
       " 'time_embedding.linear_2.weight': 'time_embed.2.weight',\n",
       " 'time_embedding.linear_2.bias': 'time_embed.2.bias',\n",
       " 'add_embedding.linear_1.weight': 'label_emb.0.0.weight',\n",
       " 'add_embedding.linear_1.bias': 'label_emb.0.0.bias',\n",
       " 'add_embedding.linear_2.weight': 'label_emb.0.2.weight',\n",
       " 'add_embedding.linear_2.bias': 'label_emb.0.2.bias',\n",
       " 'down_blocks.0.resnets.0.norm1.weight': 'input_blocks.1.0.in_layers.0.weight',\n",
       " 'down_blocks.0.resnets.0.norm1.bias': 'input_blocks.1.0.in_layers.0.bias',\n",
       " 'down_blocks.0.resnets.0.conv1.weight': 'input_blocks.1.0.in_layers.2.weight',\n",
       " 'down_blocks.0.resnets.0.conv1.bias': 'input_blocks.1.0.in_layers.2.bias',\n",
       " 'down_blocks.0.resnets.0.time_emb_proj.weight': 'input_blocks.1.0.emb_layers.1.weight',\n",
       " 'down_blocks.0.resnets.0.time_emb_proj.bias': 'input_blocks.1.0.emb_layers.1.bias',\n",
       " 'down_blocks.0.resnets.0.norm2.weight': 'input_blocks.1.0.out_layers.0.weight',\n",
       " 'down_blocks.0.resnets.0.norm2.bias': 'input_blocks.1.0.out_layers.0.bias',\n",
       " 'down_blocks.0.resnets.0.conv2.weight': 'input_blocks.1.0.out_layers.3.weight',\n",
       " 'down_blocks.0.resnets.0.conv2.bias': 'input_blocks.1.0.out_layers.3.bias',\n",
       " 'down_blocks.0.resnets.1.norm1.weight': 'input_blocks.2.0.in_layers.0.weight',\n",
       " 'down_blocks.0.resnets.1.norm1.bias': 'input_blocks.2.0.in_layers.0.bias',\n",
       " 'down_blocks.0.resnets.1.conv1.weight': 'input_blocks.2.0.in_layers.2.weight',\n",
       " 'down_blocks.0.resnets.1.conv1.bias': 'input_blocks.2.0.in_layers.2.bias',\n",
       " 'down_blocks.0.resnets.1.time_emb_proj.weight': 'input_blocks.2.0.emb_layers.1.weight',\n",
       " 'down_blocks.0.resnets.1.time_emb_proj.bias': 'input_blocks.2.0.emb_layers.1.bias',\n",
       " 'down_blocks.0.resnets.1.norm2.weight': 'input_blocks.2.0.out_layers.0.weight',\n",
       " 'down_blocks.0.resnets.1.norm2.bias': 'input_blocks.2.0.out_layers.0.bias',\n",
       " 'down_blocks.0.resnets.1.conv2.weight': 'input_blocks.2.0.out_layers.3.weight',\n",
       " 'down_blocks.0.resnets.1.conv2.bias': 'input_blocks.2.0.out_layers.3.bias',\n",
       " 'down_blocks.0.downsamplers.0.conv.weight': 'input_blocks.3.0.op.weight',\n",
       " 'down_blocks.0.downsamplers.0.conv.bias': 'input_blocks.3.0.op.bias',\n",
       " 'down_blocks.1.attentions.0.norm.weight': 'input_blocks.4.1.norm.weight',\n",
       " 'down_blocks.1.attentions.0.norm.bias': 'input_blocks.4.1.norm.bias',\n",
       " 'down_blocks.1.attentions.0.proj_in.weight': 'input_blocks.4.1.proj_in.weight',\n",
       " 'down_blocks.1.attentions.0.proj_in.bias': 'input_blocks.4.1.proj_in.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight': 'input_blocks.4.1.transformer_blocks.0.norm1.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias': 'input_blocks.4.1.transformer_blocks.0.norm1.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.bias': 'input_blocks.4.1.transformer_blocks.0.attn1.to_q.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.bias': 'input_blocks.4.1.transformer_blocks.0.attn1.to_k.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.bias': 'input_blocks.4.1.transformer_blocks.0.attn1.to_v.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight': 'input_blocks.4.1.transformer_blocks.0.norm2.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias': 'input_blocks.4.1.transformer_blocks.0.norm2.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.bias': 'input_blocks.4.1.transformer_blocks.0.attn2.to_q.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.bias': 'input_blocks.4.1.transformer_blocks.0.attn2.to_k.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.bias': 'input_blocks.4.1.transformer_blocks.0.attn2.to_v.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight': 'input_blocks.4.1.transformer_blocks.0.norm3.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias': 'input_blocks.4.1.transformer_blocks.0.norm3.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight': 'input_blocks.4.1.transformer_blocks.0.ff.net.2.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias': 'input_blocks.4.1.transformer_blocks.0.ff.net.2.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.norm1.weight': 'input_blocks.4.1.transformer_blocks.1.norm1.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.norm1.bias': 'input_blocks.4.1.transformer_blocks.1.norm1.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q.weight': 'input_blocks.4.1.transformer_blocks.1.attn1.to_q.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_q.bias': 'input_blocks.4.1.transformer_blocks.1.attn1.to_q.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k.weight': 'input_blocks.4.1.transformer_blocks.1.attn1.to_k.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_k.bias': 'input_blocks.4.1.transformer_blocks.1.attn1.to_k.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v.weight': 'input_blocks.4.1.transformer_blocks.1.attn1.to_v.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_v.bias': 'input_blocks.4.1.transformer_blocks.1.attn1.to_v.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.weight': 'input_blocks.4.1.transformer_blocks.1.attn1.to_out.0.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn1.to_out.0.bias': 'input_blocks.4.1.transformer_blocks.1.attn1.to_out.0.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.norm2.weight': 'input_blocks.4.1.transformer_blocks.1.norm2.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.norm2.bias': 'input_blocks.4.1.transformer_blocks.1.norm2.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q.weight': 'input_blocks.4.1.transformer_blocks.1.attn2.to_q.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_q.bias': 'input_blocks.4.1.transformer_blocks.1.attn2.to_q.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k.weight': 'input_blocks.4.1.transformer_blocks.1.attn2.to_k.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_k.bias': 'input_blocks.4.1.transformer_blocks.1.attn2.to_k.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v.weight': 'input_blocks.4.1.transformer_blocks.1.attn2.to_v.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_v.bias': 'input_blocks.4.1.transformer_blocks.1.attn2.to_v.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.weight': 'input_blocks.4.1.transformer_blocks.1.attn2.to_out.0.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.attn2.to_out.0.bias': 'input_blocks.4.1.transformer_blocks.1.attn2.to_out.0.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.norm3.weight': 'input_blocks.4.1.transformer_blocks.1.norm3.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.norm3.bias': 'input_blocks.4.1.transformer_blocks.1.norm3.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.weight': 'input_blocks.4.1.transformer_blocks.1.ff.net.0.proj.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.ff.net.0.proj.bias': 'input_blocks.4.1.transformer_blocks.1.ff.net.0.proj.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.weight': 'input_blocks.4.1.transformer_blocks.1.ff.net.2.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.1.ff.net.2.bias': 'input_blocks.4.1.transformer_blocks.1.ff.net.2.bias',\n",
       " 'down_blocks.1.attentions.0.proj_out.weight': 'input_blocks.4.1.proj_out.weight',\n",
       " 'down_blocks.1.attentions.0.proj_out.bias': 'input_blocks.4.1.proj_out.bias',\n",
       " 'down_blocks.1.attentions.1.norm.weight': 'input_blocks.5.1.norm.weight',\n",
       " 'down_blocks.1.attentions.1.norm.bias': 'input_blocks.5.1.norm.bias',\n",
       " 'down_blocks.1.attentions.1.proj_in.weight': 'input_blocks.5.1.proj_in.weight',\n",
       " 'down_blocks.1.attentions.1.proj_in.bias': 'input_blocks.5.1.proj_in.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight': 'input_blocks.5.1.transformer_blocks.0.norm1.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias': 'input_blocks.5.1.transformer_blocks.0.norm1.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.bias': 'input_blocks.5.1.transformer_blocks.0.attn1.to_q.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.bias': 'input_blocks.5.1.transformer_blocks.0.attn1.to_k.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.bias': 'input_blocks.5.1.transformer_blocks.0.attn1.to_v.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight': 'input_blocks.5.1.transformer_blocks.0.norm2.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias': 'input_blocks.5.1.transformer_blocks.0.norm2.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.bias': 'input_blocks.5.1.transformer_blocks.0.attn2.to_q.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.bias': 'input_blocks.5.1.transformer_blocks.0.attn2.to_k.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.bias': 'input_blocks.5.1.transformer_blocks.0.attn2.to_v.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight': 'input_blocks.5.1.transformer_blocks.0.norm3.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias': 'input_blocks.5.1.transformer_blocks.0.norm3.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight': 'input_blocks.5.1.transformer_blocks.0.ff.net.2.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias': 'input_blocks.5.1.transformer_blocks.0.ff.net.2.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.norm1.weight': 'input_blocks.5.1.transformer_blocks.1.norm1.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.norm1.bias': 'input_blocks.5.1.transformer_blocks.1.norm1.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q.weight': 'input_blocks.5.1.transformer_blocks.1.attn1.to_q.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_q.bias': 'input_blocks.5.1.transformer_blocks.1.attn1.to_q.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k.weight': 'input_blocks.5.1.transformer_blocks.1.attn1.to_k.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_k.bias': 'input_blocks.5.1.transformer_blocks.1.attn1.to_k.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v.weight': 'input_blocks.5.1.transformer_blocks.1.attn1.to_v.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_v.bias': 'input_blocks.5.1.transformer_blocks.1.attn1.to_v.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.weight': 'input_blocks.5.1.transformer_blocks.1.attn1.to_out.0.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn1.to_out.0.bias': 'input_blocks.5.1.transformer_blocks.1.attn1.to_out.0.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.norm2.weight': 'input_blocks.5.1.transformer_blocks.1.norm2.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.norm2.bias': 'input_blocks.5.1.transformer_blocks.1.norm2.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q.weight': 'input_blocks.5.1.transformer_blocks.1.attn2.to_q.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_q.bias': 'input_blocks.5.1.transformer_blocks.1.attn2.to_q.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k.weight': 'input_blocks.5.1.transformer_blocks.1.attn2.to_k.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_k.bias': 'input_blocks.5.1.transformer_blocks.1.attn2.to_k.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v.weight': 'input_blocks.5.1.transformer_blocks.1.attn2.to_v.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_v.bias': 'input_blocks.5.1.transformer_blocks.1.attn2.to_v.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.weight': 'input_blocks.5.1.transformer_blocks.1.attn2.to_out.0.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.attn2.to_out.0.bias': 'input_blocks.5.1.transformer_blocks.1.attn2.to_out.0.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.norm3.weight': 'input_blocks.5.1.transformer_blocks.1.norm3.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.norm3.bias': 'input_blocks.5.1.transformer_blocks.1.norm3.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.weight': 'input_blocks.5.1.transformer_blocks.1.ff.net.0.proj.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.ff.net.0.proj.bias': 'input_blocks.5.1.transformer_blocks.1.ff.net.0.proj.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.weight': 'input_blocks.5.1.transformer_blocks.1.ff.net.2.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.1.ff.net.2.bias': 'input_blocks.5.1.transformer_blocks.1.ff.net.2.bias',\n",
       " 'down_blocks.1.attentions.1.proj_out.weight': 'input_blocks.5.1.proj_out.weight',\n",
       " 'down_blocks.1.attentions.1.proj_out.bias': 'input_blocks.5.1.proj_out.bias',\n",
       " 'down_blocks.1.resnets.0.norm1.weight': 'input_blocks.4.0.in_layers.0.weight',\n",
       " 'down_blocks.1.resnets.0.norm1.bias': 'input_blocks.4.0.in_layers.0.bias',\n",
       " 'down_blocks.1.resnets.0.conv1.weight': 'input_blocks.4.0.in_layers.2.weight',\n",
       " 'down_blocks.1.resnets.0.conv1.bias': 'input_blocks.4.0.in_layers.2.bias',\n",
       " 'down_blocks.1.resnets.0.time_emb_proj.weight': 'input_blocks.4.0.emb_layers.1.weight',\n",
       " 'down_blocks.1.resnets.0.time_emb_proj.bias': 'input_blocks.4.0.emb_layers.1.bias',\n",
       " 'down_blocks.1.resnets.0.norm2.weight': 'input_blocks.4.0.out_layers.0.weight',\n",
       " 'down_blocks.1.resnets.0.norm2.bias': 'input_blocks.4.0.out_layers.0.bias',\n",
       " 'down_blocks.1.resnets.0.conv2.weight': 'input_blocks.4.0.out_layers.3.weight',\n",
       " 'down_blocks.1.resnets.0.conv2.bias': 'input_blocks.4.0.out_layers.3.bias',\n",
       " 'down_blocks.1.resnets.0.conv_shortcut.weight': 'input_blocks.4.0.skip_connection.weight',\n",
       " 'down_blocks.1.resnets.0.conv_shortcut.bias': 'input_blocks.4.0.skip_connection.bias',\n",
       " 'down_blocks.1.resnets.1.norm1.weight': 'input_blocks.5.0.in_layers.0.weight',\n",
       " 'down_blocks.1.resnets.1.norm1.bias': 'input_blocks.5.0.in_layers.0.bias',\n",
       " 'down_blocks.1.resnets.1.conv1.weight': 'input_blocks.5.0.in_layers.2.weight',\n",
       " 'down_blocks.1.resnets.1.conv1.bias': 'input_blocks.5.0.in_layers.2.bias',\n",
       " 'down_blocks.1.resnets.1.time_emb_proj.weight': 'input_blocks.5.0.emb_layers.1.weight',\n",
       " 'down_blocks.1.resnets.1.time_emb_proj.bias': 'input_blocks.5.0.emb_layers.1.bias',\n",
       " 'down_blocks.1.resnets.1.norm2.weight': 'input_blocks.5.0.out_layers.0.weight',\n",
       " 'down_blocks.1.resnets.1.norm2.bias': 'input_blocks.5.0.out_layers.0.bias',\n",
       " 'down_blocks.1.resnets.1.conv2.weight': 'input_blocks.5.0.out_layers.3.weight',\n",
       " 'down_blocks.1.resnets.1.conv2.bias': 'input_blocks.5.0.out_layers.3.bias',\n",
       " 'down_blocks.1.downsamplers.0.conv.weight': 'input_blocks.6.0.op.weight',\n",
       " 'down_blocks.1.downsamplers.0.conv.bias': 'input_blocks.6.0.op.bias',\n",
       " 'down_blocks.2.attentions.0.norm.weight': 'input_blocks.7.1.norm.weight',\n",
       " 'down_blocks.2.attentions.0.norm.bias': 'input_blocks.7.1.norm.bias',\n",
       " 'down_blocks.2.attentions.0.proj_in.weight': 'input_blocks.7.1.proj_in.weight',\n",
       " 'down_blocks.2.attentions.0.proj_in.bias': 'input_blocks.7.1.proj_in.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight': 'input_blocks.7.1.transformer_blocks.0.norm1.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias': 'input_blocks.7.1.transformer_blocks.0.norm1.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.bias': 'input_blocks.7.1.transformer_blocks.0.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.bias': 'input_blocks.7.1.transformer_blocks.0.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.bias': 'input_blocks.7.1.transformer_blocks.0.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight': 'input_blocks.7.1.transformer_blocks.0.norm2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias': 'input_blocks.7.1.transformer_blocks.0.norm2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.bias': 'input_blocks.7.1.transformer_blocks.0.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.bias': 'input_blocks.7.1.transformer_blocks.0.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.bias': 'input_blocks.7.1.transformer_blocks.0.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight': 'input_blocks.7.1.transformer_blocks.0.norm3.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias': 'input_blocks.7.1.transformer_blocks.0.norm3.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.0.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.0.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.norm1.weight': 'input_blocks.7.1.transformer_blocks.1.norm1.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.norm1.bias': 'input_blocks.7.1.transformer_blocks.1.norm1.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.1.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_q.bias': 'input_blocks.7.1.transformer_blocks.1.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.1.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_k.bias': 'input_blocks.7.1.transformer_blocks.1.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.1.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_v.bias': 'input_blocks.7.1.transformer_blocks.1.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.1.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.1.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.norm2.weight': 'input_blocks.7.1.transformer_blocks.1.norm2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.norm2.bias': 'input_blocks.7.1.transformer_blocks.1.norm2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.1.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_q.bias': 'input_blocks.7.1.transformer_blocks.1.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.1.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_k.bias': 'input_blocks.7.1.transformer_blocks.1.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.1.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_v.bias': 'input_blocks.7.1.transformer_blocks.1.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.1.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.1.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.norm3.weight': 'input_blocks.7.1.transformer_blocks.1.norm3.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.norm3.bias': 'input_blocks.7.1.transformer_blocks.1.norm3.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.1.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.1.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.1.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.1.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.1.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.norm1.weight': 'input_blocks.7.1.transformer_blocks.2.norm1.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.norm1.bias': 'input_blocks.7.1.transformer_blocks.2.norm1.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.2.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_q.bias': 'input_blocks.7.1.transformer_blocks.2.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.2.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_k.bias': 'input_blocks.7.1.transformer_blocks.2.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.2.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_v.bias': 'input_blocks.7.1.transformer_blocks.2.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.2.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.2.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.norm2.weight': 'input_blocks.7.1.transformer_blocks.2.norm2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.norm2.bias': 'input_blocks.7.1.transformer_blocks.2.norm2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.2.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_q.bias': 'input_blocks.7.1.transformer_blocks.2.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.2.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_k.bias': 'input_blocks.7.1.transformer_blocks.2.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.2.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_v.bias': 'input_blocks.7.1.transformer_blocks.2.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.2.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.2.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.norm3.weight': 'input_blocks.7.1.transformer_blocks.2.norm3.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.norm3.bias': 'input_blocks.7.1.transformer_blocks.2.norm3.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.2.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.2.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.2.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.2.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.2.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.norm1.weight': 'input_blocks.7.1.transformer_blocks.3.norm1.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.norm1.bias': 'input_blocks.7.1.transformer_blocks.3.norm1.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.3.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_q.bias': 'input_blocks.7.1.transformer_blocks.3.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.3.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_k.bias': 'input_blocks.7.1.transformer_blocks.3.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.3.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_v.bias': 'input_blocks.7.1.transformer_blocks.3.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.3.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.3.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.norm2.weight': 'input_blocks.7.1.transformer_blocks.3.norm2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.norm2.bias': 'input_blocks.7.1.transformer_blocks.3.norm2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.3.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_q.bias': 'input_blocks.7.1.transformer_blocks.3.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.3.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_k.bias': 'input_blocks.7.1.transformer_blocks.3.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.3.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_v.bias': 'input_blocks.7.1.transformer_blocks.3.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.3.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.3.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.norm3.weight': 'input_blocks.7.1.transformer_blocks.3.norm3.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.norm3.bias': 'input_blocks.7.1.transformer_blocks.3.norm3.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.3.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.3.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.3.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.3.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.3.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.norm1.weight': 'input_blocks.7.1.transformer_blocks.4.norm1.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.norm1.bias': 'input_blocks.7.1.transformer_blocks.4.norm1.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.4.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_q.bias': 'input_blocks.7.1.transformer_blocks.4.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.4.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_k.bias': 'input_blocks.7.1.transformer_blocks.4.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.4.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_v.bias': 'input_blocks.7.1.transformer_blocks.4.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.4.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.4.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.norm2.weight': 'input_blocks.7.1.transformer_blocks.4.norm2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.norm2.bias': 'input_blocks.7.1.transformer_blocks.4.norm2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.4.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_q.bias': 'input_blocks.7.1.transformer_blocks.4.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.4.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_k.bias': 'input_blocks.7.1.transformer_blocks.4.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.4.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_v.bias': 'input_blocks.7.1.transformer_blocks.4.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.4.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.4.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.norm3.weight': 'input_blocks.7.1.transformer_blocks.4.norm3.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.norm3.bias': 'input_blocks.7.1.transformer_blocks.4.norm3.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.4.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.4.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.4.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.4.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.4.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.norm1.weight': 'input_blocks.7.1.transformer_blocks.5.norm1.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.norm1.bias': 'input_blocks.7.1.transformer_blocks.5.norm1.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.5.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_q.bias': 'input_blocks.7.1.transformer_blocks.5.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.5.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_k.bias': 'input_blocks.7.1.transformer_blocks.5.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.5.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_v.bias': 'input_blocks.7.1.transformer_blocks.5.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.5.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.5.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.norm2.weight': 'input_blocks.7.1.transformer_blocks.5.norm2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.norm2.bias': 'input_blocks.7.1.transformer_blocks.5.norm2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.5.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_q.bias': 'input_blocks.7.1.transformer_blocks.5.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.5.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_k.bias': 'input_blocks.7.1.transformer_blocks.5.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.5.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_v.bias': 'input_blocks.7.1.transformer_blocks.5.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.5.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.5.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.norm3.weight': 'input_blocks.7.1.transformer_blocks.5.norm3.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.norm3.bias': 'input_blocks.7.1.transformer_blocks.5.norm3.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.5.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.5.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.5.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.5.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.5.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.norm1.weight': 'input_blocks.7.1.transformer_blocks.6.norm1.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.norm1.bias': 'input_blocks.7.1.transformer_blocks.6.norm1.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.6.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_q.bias': 'input_blocks.7.1.transformer_blocks.6.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.6.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_k.bias': 'input_blocks.7.1.transformer_blocks.6.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.6.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_v.bias': 'input_blocks.7.1.transformer_blocks.6.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.6.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.6.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.norm2.weight': 'input_blocks.7.1.transformer_blocks.6.norm2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.norm2.bias': 'input_blocks.7.1.transformer_blocks.6.norm2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.6.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_q.bias': 'input_blocks.7.1.transformer_blocks.6.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.6.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_k.bias': 'input_blocks.7.1.transformer_blocks.6.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.6.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_v.bias': 'input_blocks.7.1.transformer_blocks.6.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.6.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.6.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.norm3.weight': 'input_blocks.7.1.transformer_blocks.6.norm3.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.norm3.bias': 'input_blocks.7.1.transformer_blocks.6.norm3.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.6.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.6.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.6.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.6.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.6.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.norm1.weight': 'input_blocks.7.1.transformer_blocks.7.norm1.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.norm1.bias': 'input_blocks.7.1.transformer_blocks.7.norm1.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.7.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_q.bias': 'input_blocks.7.1.transformer_blocks.7.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.7.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_k.bias': 'input_blocks.7.1.transformer_blocks.7.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.7.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_v.bias': 'input_blocks.7.1.transformer_blocks.7.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.7.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.7.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.norm2.weight': 'input_blocks.7.1.transformer_blocks.7.norm2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.norm2.bias': 'input_blocks.7.1.transformer_blocks.7.norm2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.7.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_q.bias': 'input_blocks.7.1.transformer_blocks.7.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.7.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_k.bias': 'input_blocks.7.1.transformer_blocks.7.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.7.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_v.bias': 'input_blocks.7.1.transformer_blocks.7.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.7.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.7.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.norm3.weight': 'input_blocks.7.1.transformer_blocks.7.norm3.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.norm3.bias': 'input_blocks.7.1.transformer_blocks.7.norm3.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.7.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.7.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.7.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.7.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.7.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.norm1.weight': 'input_blocks.7.1.transformer_blocks.8.norm1.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.norm1.bias': 'input_blocks.7.1.transformer_blocks.8.norm1.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.8.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_q.bias': 'input_blocks.7.1.transformer_blocks.8.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.8.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_k.bias': 'input_blocks.7.1.transformer_blocks.8.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.8.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_v.bias': 'input_blocks.7.1.transformer_blocks.8.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.8.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.8.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.norm2.weight': 'input_blocks.7.1.transformer_blocks.8.norm2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.norm2.bias': 'input_blocks.7.1.transformer_blocks.8.norm2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.8.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_q.bias': 'input_blocks.7.1.transformer_blocks.8.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.8.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_k.bias': 'input_blocks.7.1.transformer_blocks.8.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.8.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_v.bias': 'input_blocks.7.1.transformer_blocks.8.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.8.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.8.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.norm3.weight': 'input_blocks.7.1.transformer_blocks.8.norm3.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.norm3.bias': 'input_blocks.7.1.transformer_blocks.8.norm3.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.8.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.8.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.8.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.8.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.8.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.norm1.weight': 'input_blocks.7.1.transformer_blocks.9.norm1.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.norm1.bias': 'input_blocks.7.1.transformer_blocks.9.norm1.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.9.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_q.bias': 'input_blocks.7.1.transformer_blocks.9.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.9.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_k.bias': 'input_blocks.7.1.transformer_blocks.9.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.9.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_v.bias': 'input_blocks.7.1.transformer_blocks.9.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.9.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.9.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.norm2.weight': 'input_blocks.7.1.transformer_blocks.9.norm2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.norm2.bias': 'input_blocks.7.1.transformer_blocks.9.norm2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.9.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_q.bias': 'input_blocks.7.1.transformer_blocks.9.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.9.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_k.bias': 'input_blocks.7.1.transformer_blocks.9.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.9.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_v.bias': 'input_blocks.7.1.transformer_blocks.9.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.9.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.9.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.norm3.weight': 'input_blocks.7.1.transformer_blocks.9.norm3.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.norm3.bias': 'input_blocks.7.1.transformer_blocks.9.norm3.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.9.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.9.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.9.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.9.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.9.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.0.proj_out.weight': 'input_blocks.7.1.proj_out.weight',\n",
       " 'down_blocks.2.attentions.0.proj_out.bias': 'input_blocks.7.1.proj_out.bias',\n",
       " 'down_blocks.2.attentions.1.norm.weight': 'input_blocks.8.1.norm.weight',\n",
       " 'down_blocks.2.attentions.1.norm.bias': 'input_blocks.8.1.norm.bias',\n",
       " 'down_blocks.2.attentions.1.proj_in.weight': 'input_blocks.8.1.proj_in.weight',\n",
       " 'down_blocks.2.attentions.1.proj_in.bias': 'input_blocks.8.1.proj_in.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight': 'input_blocks.8.1.transformer_blocks.0.norm1.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias': 'input_blocks.8.1.transformer_blocks.0.norm1.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.bias': 'input_blocks.8.1.transformer_blocks.0.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.bias': 'input_blocks.8.1.transformer_blocks.0.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.bias': 'input_blocks.8.1.transformer_blocks.0.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight': 'input_blocks.8.1.transformer_blocks.0.norm2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias': 'input_blocks.8.1.transformer_blocks.0.norm2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.bias': 'input_blocks.8.1.transformer_blocks.0.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.bias': 'input_blocks.8.1.transformer_blocks.0.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.bias': 'input_blocks.8.1.transformer_blocks.0.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight': 'input_blocks.8.1.transformer_blocks.0.norm3.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias': 'input_blocks.8.1.transformer_blocks.0.norm3.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.0.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.0.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.norm1.weight': 'input_blocks.8.1.transformer_blocks.1.norm1.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.norm1.bias': 'input_blocks.8.1.transformer_blocks.1.norm1.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.1.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_q.bias': 'input_blocks.8.1.transformer_blocks.1.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.1.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_k.bias': 'input_blocks.8.1.transformer_blocks.1.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.1.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_v.bias': 'input_blocks.8.1.transformer_blocks.1.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.1.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.1.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.norm2.weight': 'input_blocks.8.1.transformer_blocks.1.norm2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.norm2.bias': 'input_blocks.8.1.transformer_blocks.1.norm2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.1.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_q.bias': 'input_blocks.8.1.transformer_blocks.1.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.1.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_k.bias': 'input_blocks.8.1.transformer_blocks.1.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.1.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_v.bias': 'input_blocks.8.1.transformer_blocks.1.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.1.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.1.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.norm3.weight': 'input_blocks.8.1.transformer_blocks.1.norm3.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.norm3.bias': 'input_blocks.8.1.transformer_blocks.1.norm3.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.1.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.1.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.1.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.1.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.1.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.norm1.weight': 'input_blocks.8.1.transformer_blocks.2.norm1.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.norm1.bias': 'input_blocks.8.1.transformer_blocks.2.norm1.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.2.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_q.bias': 'input_blocks.8.1.transformer_blocks.2.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.2.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_k.bias': 'input_blocks.8.1.transformer_blocks.2.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.2.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_v.bias': 'input_blocks.8.1.transformer_blocks.2.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.2.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.2.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.norm2.weight': 'input_blocks.8.1.transformer_blocks.2.norm2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.norm2.bias': 'input_blocks.8.1.transformer_blocks.2.norm2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.2.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_q.bias': 'input_blocks.8.1.transformer_blocks.2.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.2.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_k.bias': 'input_blocks.8.1.transformer_blocks.2.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.2.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_v.bias': 'input_blocks.8.1.transformer_blocks.2.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.2.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.2.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.norm3.weight': 'input_blocks.8.1.transformer_blocks.2.norm3.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.norm3.bias': 'input_blocks.8.1.transformer_blocks.2.norm3.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.2.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.2.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.2.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.2.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.2.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.norm1.weight': 'input_blocks.8.1.transformer_blocks.3.norm1.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.norm1.bias': 'input_blocks.8.1.transformer_blocks.3.norm1.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.3.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_q.bias': 'input_blocks.8.1.transformer_blocks.3.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.3.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_k.bias': 'input_blocks.8.1.transformer_blocks.3.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.3.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_v.bias': 'input_blocks.8.1.transformer_blocks.3.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.3.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.3.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.norm2.weight': 'input_blocks.8.1.transformer_blocks.3.norm2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.norm2.bias': 'input_blocks.8.1.transformer_blocks.3.norm2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.3.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_q.bias': 'input_blocks.8.1.transformer_blocks.3.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.3.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_k.bias': 'input_blocks.8.1.transformer_blocks.3.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.3.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_v.bias': 'input_blocks.8.1.transformer_blocks.3.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.3.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.3.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.norm3.weight': 'input_blocks.8.1.transformer_blocks.3.norm3.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.norm3.bias': 'input_blocks.8.1.transformer_blocks.3.norm3.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.3.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.3.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.3.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.3.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.3.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.norm1.weight': 'input_blocks.8.1.transformer_blocks.4.norm1.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.norm1.bias': 'input_blocks.8.1.transformer_blocks.4.norm1.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.4.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_q.bias': 'input_blocks.8.1.transformer_blocks.4.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.4.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_k.bias': 'input_blocks.8.1.transformer_blocks.4.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.4.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_v.bias': 'input_blocks.8.1.transformer_blocks.4.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.4.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.4.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.norm2.weight': 'input_blocks.8.1.transformer_blocks.4.norm2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.norm2.bias': 'input_blocks.8.1.transformer_blocks.4.norm2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.4.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_q.bias': 'input_blocks.8.1.transformer_blocks.4.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.4.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_k.bias': 'input_blocks.8.1.transformer_blocks.4.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.4.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_v.bias': 'input_blocks.8.1.transformer_blocks.4.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.4.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.4.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.norm3.weight': 'input_blocks.8.1.transformer_blocks.4.norm3.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.norm3.bias': 'input_blocks.8.1.transformer_blocks.4.norm3.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.4.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.4.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.4.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.4.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.4.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.norm1.weight': 'input_blocks.8.1.transformer_blocks.5.norm1.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.norm1.bias': 'input_blocks.8.1.transformer_blocks.5.norm1.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.5.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_q.bias': 'input_blocks.8.1.transformer_blocks.5.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.5.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_k.bias': 'input_blocks.8.1.transformer_blocks.5.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.5.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_v.bias': 'input_blocks.8.1.transformer_blocks.5.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.5.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.5.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.norm2.weight': 'input_blocks.8.1.transformer_blocks.5.norm2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.norm2.bias': 'input_blocks.8.1.transformer_blocks.5.norm2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.5.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_q.bias': 'input_blocks.8.1.transformer_blocks.5.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.5.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_k.bias': 'input_blocks.8.1.transformer_blocks.5.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.5.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_v.bias': 'input_blocks.8.1.transformer_blocks.5.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.5.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.5.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.norm3.weight': 'input_blocks.8.1.transformer_blocks.5.norm3.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.norm3.bias': 'input_blocks.8.1.transformer_blocks.5.norm3.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.5.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.5.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.5.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.5.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.5.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.norm1.weight': 'input_blocks.8.1.transformer_blocks.6.norm1.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.norm1.bias': 'input_blocks.8.1.transformer_blocks.6.norm1.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.6.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_q.bias': 'input_blocks.8.1.transformer_blocks.6.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.6.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_k.bias': 'input_blocks.8.1.transformer_blocks.6.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.6.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_v.bias': 'input_blocks.8.1.transformer_blocks.6.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.6.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.6.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.norm2.weight': 'input_blocks.8.1.transformer_blocks.6.norm2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.norm2.bias': 'input_blocks.8.1.transformer_blocks.6.norm2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.6.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_q.bias': 'input_blocks.8.1.transformer_blocks.6.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.6.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_k.bias': 'input_blocks.8.1.transformer_blocks.6.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.6.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_v.bias': 'input_blocks.8.1.transformer_blocks.6.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.6.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.6.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.norm3.weight': 'input_blocks.8.1.transformer_blocks.6.norm3.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.norm3.bias': 'input_blocks.8.1.transformer_blocks.6.norm3.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.6.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.6.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.6.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.6.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.6.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.norm1.weight': 'input_blocks.8.1.transformer_blocks.7.norm1.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.norm1.bias': 'input_blocks.8.1.transformer_blocks.7.norm1.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.7.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_q.bias': 'input_blocks.8.1.transformer_blocks.7.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.7.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_k.bias': 'input_blocks.8.1.transformer_blocks.7.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.7.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_v.bias': 'input_blocks.8.1.transformer_blocks.7.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.7.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.7.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.norm2.weight': 'input_blocks.8.1.transformer_blocks.7.norm2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.norm2.bias': 'input_blocks.8.1.transformer_blocks.7.norm2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.7.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_q.bias': 'input_blocks.8.1.transformer_blocks.7.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.7.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_k.bias': 'input_blocks.8.1.transformer_blocks.7.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.7.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_v.bias': 'input_blocks.8.1.transformer_blocks.7.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.7.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.7.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.norm3.weight': 'input_blocks.8.1.transformer_blocks.7.norm3.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.norm3.bias': 'input_blocks.8.1.transformer_blocks.7.norm3.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.7.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.7.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.7.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.7.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.7.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.norm1.weight': 'input_blocks.8.1.transformer_blocks.8.norm1.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.norm1.bias': 'input_blocks.8.1.transformer_blocks.8.norm1.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.8.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_q.bias': 'input_blocks.8.1.transformer_blocks.8.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.8.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_k.bias': 'input_blocks.8.1.transformer_blocks.8.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.8.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_v.bias': 'input_blocks.8.1.transformer_blocks.8.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.8.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.8.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.norm2.weight': 'input_blocks.8.1.transformer_blocks.8.norm2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.norm2.bias': 'input_blocks.8.1.transformer_blocks.8.norm2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.8.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_q.bias': 'input_blocks.8.1.transformer_blocks.8.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.8.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_k.bias': 'input_blocks.8.1.transformer_blocks.8.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.8.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_v.bias': 'input_blocks.8.1.transformer_blocks.8.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.8.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.8.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.norm3.weight': 'input_blocks.8.1.transformer_blocks.8.norm3.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.norm3.bias': 'input_blocks.8.1.transformer_blocks.8.norm3.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.8.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.8.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.8.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.8.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.8.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.norm1.weight': 'input_blocks.8.1.transformer_blocks.9.norm1.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.norm1.bias': 'input_blocks.8.1.transformer_blocks.9.norm1.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.9.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_q.bias': 'input_blocks.8.1.transformer_blocks.9.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.9.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_k.bias': 'input_blocks.8.1.transformer_blocks.9.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.9.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_v.bias': 'input_blocks.8.1.transformer_blocks.9.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.9.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.9.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.norm2.weight': 'input_blocks.8.1.transformer_blocks.9.norm2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.norm2.bias': 'input_blocks.8.1.transformer_blocks.9.norm2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.9.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_q.bias': 'input_blocks.8.1.transformer_blocks.9.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.9.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_k.bias': 'input_blocks.8.1.transformer_blocks.9.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.9.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_v.bias': 'input_blocks.8.1.transformer_blocks.9.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.9.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.9.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.norm3.weight': 'input_blocks.8.1.transformer_blocks.9.norm3.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.norm3.bias': 'input_blocks.8.1.transformer_blocks.9.norm3.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.9.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.9.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.9.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.9.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.9.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.1.proj_out.weight': 'input_blocks.8.1.proj_out.weight',\n",
       " 'down_blocks.2.attentions.1.proj_out.bias': 'input_blocks.8.1.proj_out.bias',\n",
       " 'down_blocks.2.resnets.0.norm1.weight': 'input_blocks.7.0.in_layers.0.weight',\n",
       " 'down_blocks.2.resnets.0.norm1.bias': 'input_blocks.7.0.in_layers.0.bias',\n",
       " 'down_blocks.2.resnets.0.conv1.weight': 'input_blocks.7.0.in_layers.2.weight',\n",
       " 'down_blocks.2.resnets.0.conv1.bias': 'input_blocks.7.0.in_layers.2.bias',\n",
       " 'down_blocks.2.resnets.0.time_emb_proj.weight': 'input_blocks.7.0.emb_layers.1.weight',\n",
       " 'down_blocks.2.resnets.0.time_emb_proj.bias': 'input_blocks.7.0.emb_layers.1.bias',\n",
       " 'down_blocks.2.resnets.0.norm2.weight': 'input_blocks.7.0.out_layers.0.weight',\n",
       " 'down_blocks.2.resnets.0.norm2.bias': 'input_blocks.7.0.out_layers.0.bias',\n",
       " 'down_blocks.2.resnets.0.conv2.weight': 'input_blocks.7.0.out_layers.3.weight',\n",
       " 'down_blocks.2.resnets.0.conv2.bias': 'input_blocks.7.0.out_layers.3.bias',\n",
       " 'down_blocks.2.resnets.0.conv_shortcut.weight': 'input_blocks.7.0.skip_connection.weight',\n",
       " 'down_blocks.2.resnets.0.conv_shortcut.bias': 'input_blocks.7.0.skip_connection.bias',\n",
       " 'down_blocks.2.resnets.1.norm1.weight': 'input_blocks.8.0.in_layers.0.weight',\n",
       " 'down_blocks.2.resnets.1.norm1.bias': 'input_blocks.8.0.in_layers.0.bias',\n",
       " 'down_blocks.2.resnets.1.conv1.weight': 'input_blocks.8.0.in_layers.2.weight',\n",
       " 'down_blocks.2.resnets.1.conv1.bias': 'input_blocks.8.0.in_layers.2.bias',\n",
       " 'down_blocks.2.resnets.1.time_emb_proj.weight': 'input_blocks.8.0.emb_layers.1.weight',\n",
       " 'down_blocks.2.resnets.1.time_emb_proj.bias': 'input_blocks.8.0.emb_layers.1.bias',\n",
       " 'down_blocks.2.resnets.1.norm2.weight': 'input_blocks.8.0.out_layers.0.weight',\n",
       " 'down_blocks.2.resnets.1.norm2.bias': 'input_blocks.8.0.out_layers.0.bias',\n",
       " 'down_blocks.2.resnets.1.conv2.weight': 'input_blocks.8.0.out_layers.3.weight',\n",
       " 'down_blocks.2.resnets.1.conv2.bias': 'input_blocks.8.0.out_layers.3.bias',\n",
       " 'up_blocks.0.attentions.0.norm.weight': 'output_blocks.0.1.norm.weight',\n",
       " 'up_blocks.0.attentions.0.norm.bias': 'output_blocks.0.1.norm.bias',\n",
       " 'up_blocks.0.attentions.0.proj_in.weight': 'output_blocks.0.1.proj_in.weight',\n",
       " 'up_blocks.0.attentions.0.proj_in.bias': 'output_blocks.0.1.proj_in.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.norm1.weight': 'output_blocks.0.1.transformer_blocks.0.norm1.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.norm1.bias': 'output_blocks.0.1.transformer_blocks.0.norm1.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.0.attn1.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.bias': 'output_blocks.0.1.transformer_blocks.0.attn1.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.0.attn1.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.bias': 'output_blocks.0.1.transformer_blocks.0.attn1.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.0.attn1.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.bias': 'output_blocks.0.1.transformer_blocks.0.attn1.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.0.attn1.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.norm2.weight': 'output_blocks.0.1.transformer_blocks.0.norm2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.norm2.bias': 'output_blocks.0.1.transformer_blocks.0.norm2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.0.attn2.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.bias': 'output_blocks.0.1.transformer_blocks.0.attn2.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.0.attn2.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.bias': 'output_blocks.0.1.transformer_blocks.0.attn2.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.0.attn2.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.bias': 'output_blocks.0.1.transformer_blocks.0.attn2.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.0.attn2.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.norm3.weight': 'output_blocks.0.1.transformer_blocks.0.norm3.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.norm3.bias': 'output_blocks.0.1.transformer_blocks.0.norm3.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.0.ff.net.0.proj.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.0.ff.net.2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.0.ff.net.2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.norm1.weight': 'output_blocks.0.1.transformer_blocks.1.norm1.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.norm1.bias': 'output_blocks.0.1.transformer_blocks.1.norm1.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.1.attn1.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_q.bias': 'output_blocks.0.1.transformer_blocks.1.attn1.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.1.attn1.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_k.bias': 'output_blocks.0.1.transformer_blocks.1.attn1.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.1.attn1.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_v.bias': 'output_blocks.0.1.transformer_blocks.1.attn1.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.1.attn1.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.1.attn1.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.norm2.weight': 'output_blocks.0.1.transformer_blocks.1.norm2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.norm2.bias': 'output_blocks.0.1.transformer_blocks.1.norm2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.1.attn2.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_q.bias': 'output_blocks.0.1.transformer_blocks.1.attn2.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.1.attn2.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_k.bias': 'output_blocks.0.1.transformer_blocks.1.attn2.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.1.attn2.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_v.bias': 'output_blocks.0.1.transformer_blocks.1.attn2.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.1.attn2.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.1.attn2.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.norm3.weight': 'output_blocks.0.1.transformer_blocks.1.norm3.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.norm3.bias': 'output_blocks.0.1.transformer_blocks.1.norm3.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.1.ff.net.0.proj.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.1.ff.net.0.proj.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.1.ff.net.2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.1.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.1.ff.net.2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.norm1.weight': 'output_blocks.0.1.transformer_blocks.2.norm1.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.norm1.bias': 'output_blocks.0.1.transformer_blocks.2.norm1.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.2.attn1.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_q.bias': 'output_blocks.0.1.transformer_blocks.2.attn1.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.2.attn1.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_k.bias': 'output_blocks.0.1.transformer_blocks.2.attn1.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.2.attn1.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_v.bias': 'output_blocks.0.1.transformer_blocks.2.attn1.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.2.attn1.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.2.attn1.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.norm2.weight': 'output_blocks.0.1.transformer_blocks.2.norm2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.norm2.bias': 'output_blocks.0.1.transformer_blocks.2.norm2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.2.attn2.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_q.bias': 'output_blocks.0.1.transformer_blocks.2.attn2.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.2.attn2.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_k.bias': 'output_blocks.0.1.transformer_blocks.2.attn2.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.2.attn2.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_v.bias': 'output_blocks.0.1.transformer_blocks.2.attn2.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.2.attn2.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.2.attn2.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.norm3.weight': 'output_blocks.0.1.transformer_blocks.2.norm3.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.norm3.bias': 'output_blocks.0.1.transformer_blocks.2.norm3.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.2.ff.net.0.proj.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.2.ff.net.0.proj.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.2.ff.net.2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.2.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.2.ff.net.2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.norm1.weight': 'output_blocks.0.1.transformer_blocks.3.norm1.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.norm1.bias': 'output_blocks.0.1.transformer_blocks.3.norm1.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.3.attn1.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_q.bias': 'output_blocks.0.1.transformer_blocks.3.attn1.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.3.attn1.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_k.bias': 'output_blocks.0.1.transformer_blocks.3.attn1.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.3.attn1.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_v.bias': 'output_blocks.0.1.transformer_blocks.3.attn1.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.3.attn1.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.3.attn1.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.norm2.weight': 'output_blocks.0.1.transformer_blocks.3.norm2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.norm2.bias': 'output_blocks.0.1.transformer_blocks.3.norm2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.3.attn2.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_q.bias': 'output_blocks.0.1.transformer_blocks.3.attn2.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.3.attn2.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_k.bias': 'output_blocks.0.1.transformer_blocks.3.attn2.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.3.attn2.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_v.bias': 'output_blocks.0.1.transformer_blocks.3.attn2.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.3.attn2.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.3.attn2.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.norm3.weight': 'output_blocks.0.1.transformer_blocks.3.norm3.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.norm3.bias': 'output_blocks.0.1.transformer_blocks.3.norm3.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.3.ff.net.0.proj.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.3.ff.net.0.proj.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.3.ff.net.2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.3.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.3.ff.net.2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.norm1.weight': 'output_blocks.0.1.transformer_blocks.4.norm1.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.norm1.bias': 'output_blocks.0.1.transformer_blocks.4.norm1.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.4.attn1.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_q.bias': 'output_blocks.0.1.transformer_blocks.4.attn1.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.4.attn1.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_k.bias': 'output_blocks.0.1.transformer_blocks.4.attn1.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.4.attn1.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_v.bias': 'output_blocks.0.1.transformer_blocks.4.attn1.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.4.attn1.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.4.attn1.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.norm2.weight': 'output_blocks.0.1.transformer_blocks.4.norm2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.norm2.bias': 'output_blocks.0.1.transformer_blocks.4.norm2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.4.attn2.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_q.bias': 'output_blocks.0.1.transformer_blocks.4.attn2.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.4.attn2.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_k.bias': 'output_blocks.0.1.transformer_blocks.4.attn2.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.4.attn2.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_v.bias': 'output_blocks.0.1.transformer_blocks.4.attn2.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.4.attn2.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.4.attn2.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.norm3.weight': 'output_blocks.0.1.transformer_blocks.4.norm3.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.norm3.bias': 'output_blocks.0.1.transformer_blocks.4.norm3.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.4.ff.net.0.proj.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.4.ff.net.0.proj.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.4.ff.net.2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.4.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.4.ff.net.2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.norm1.weight': 'output_blocks.0.1.transformer_blocks.5.norm1.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.norm1.bias': 'output_blocks.0.1.transformer_blocks.5.norm1.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.5.attn1.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_q.bias': 'output_blocks.0.1.transformer_blocks.5.attn1.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.5.attn1.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_k.bias': 'output_blocks.0.1.transformer_blocks.5.attn1.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.5.attn1.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_v.bias': 'output_blocks.0.1.transformer_blocks.5.attn1.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.5.attn1.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.5.attn1.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.norm2.weight': 'output_blocks.0.1.transformer_blocks.5.norm2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.norm2.bias': 'output_blocks.0.1.transformer_blocks.5.norm2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.5.attn2.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_q.bias': 'output_blocks.0.1.transformer_blocks.5.attn2.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.5.attn2.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_k.bias': 'output_blocks.0.1.transformer_blocks.5.attn2.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.5.attn2.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_v.bias': 'output_blocks.0.1.transformer_blocks.5.attn2.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.5.attn2.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.5.attn2.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.norm3.weight': 'output_blocks.0.1.transformer_blocks.5.norm3.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.norm3.bias': 'output_blocks.0.1.transformer_blocks.5.norm3.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.5.ff.net.0.proj.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.5.ff.net.0.proj.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.5.ff.net.2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.5.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.5.ff.net.2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.norm1.weight': 'output_blocks.0.1.transformer_blocks.6.norm1.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.norm1.bias': 'output_blocks.0.1.transformer_blocks.6.norm1.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.6.attn1.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_q.bias': 'output_blocks.0.1.transformer_blocks.6.attn1.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.6.attn1.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_k.bias': 'output_blocks.0.1.transformer_blocks.6.attn1.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.6.attn1.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_v.bias': 'output_blocks.0.1.transformer_blocks.6.attn1.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.6.attn1.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.6.attn1.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.norm2.weight': 'output_blocks.0.1.transformer_blocks.6.norm2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.norm2.bias': 'output_blocks.0.1.transformer_blocks.6.norm2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.6.attn2.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_q.bias': 'output_blocks.0.1.transformer_blocks.6.attn2.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.6.attn2.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_k.bias': 'output_blocks.0.1.transformer_blocks.6.attn2.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.6.attn2.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_v.bias': 'output_blocks.0.1.transformer_blocks.6.attn2.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.6.attn2.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.6.attn2.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.norm3.weight': 'output_blocks.0.1.transformer_blocks.6.norm3.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.norm3.bias': 'output_blocks.0.1.transformer_blocks.6.norm3.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.6.ff.net.0.proj.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.6.ff.net.0.proj.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.6.ff.net.2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.6.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.6.ff.net.2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.norm1.weight': 'output_blocks.0.1.transformer_blocks.7.norm1.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.norm1.bias': 'output_blocks.0.1.transformer_blocks.7.norm1.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.7.attn1.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_q.bias': 'output_blocks.0.1.transformer_blocks.7.attn1.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.7.attn1.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_k.bias': 'output_blocks.0.1.transformer_blocks.7.attn1.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.7.attn1.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_v.bias': 'output_blocks.0.1.transformer_blocks.7.attn1.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.7.attn1.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.7.attn1.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.norm2.weight': 'output_blocks.0.1.transformer_blocks.7.norm2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.norm2.bias': 'output_blocks.0.1.transformer_blocks.7.norm2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.7.attn2.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_q.bias': 'output_blocks.0.1.transformer_blocks.7.attn2.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.7.attn2.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_k.bias': 'output_blocks.0.1.transformer_blocks.7.attn2.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.7.attn2.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_v.bias': 'output_blocks.0.1.transformer_blocks.7.attn2.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.7.attn2.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.7.attn2.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.norm3.weight': 'output_blocks.0.1.transformer_blocks.7.norm3.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.norm3.bias': 'output_blocks.0.1.transformer_blocks.7.norm3.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.7.ff.net.0.proj.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.7.ff.net.0.proj.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.7.ff.net.2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.7.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.7.ff.net.2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.norm1.weight': 'output_blocks.0.1.transformer_blocks.8.norm1.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.norm1.bias': 'output_blocks.0.1.transformer_blocks.8.norm1.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.8.attn1.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_q.bias': 'output_blocks.0.1.transformer_blocks.8.attn1.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.8.attn1.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_k.bias': 'output_blocks.0.1.transformer_blocks.8.attn1.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.8.attn1.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_v.bias': 'output_blocks.0.1.transformer_blocks.8.attn1.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.8.attn1.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.8.attn1.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.norm2.weight': 'output_blocks.0.1.transformer_blocks.8.norm2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.norm2.bias': 'output_blocks.0.1.transformer_blocks.8.norm2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.8.attn2.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_q.bias': 'output_blocks.0.1.transformer_blocks.8.attn2.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.8.attn2.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_k.bias': 'output_blocks.0.1.transformer_blocks.8.attn2.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.8.attn2.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_v.bias': 'output_blocks.0.1.transformer_blocks.8.attn2.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.8.attn2.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.8.attn2.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.norm3.weight': 'output_blocks.0.1.transformer_blocks.8.norm3.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.norm3.bias': 'output_blocks.0.1.transformer_blocks.8.norm3.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.8.ff.net.0.proj.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.8.ff.net.0.proj.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.8.ff.net.2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.8.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.8.ff.net.2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.norm1.weight': 'output_blocks.0.1.transformer_blocks.9.norm1.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.norm1.bias': 'output_blocks.0.1.transformer_blocks.9.norm1.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_q.weight': 'output_blocks.0.1.transformer_blocks.9.attn1.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_q.bias': 'output_blocks.0.1.transformer_blocks.9.attn1.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_k.weight': 'output_blocks.0.1.transformer_blocks.9.attn1.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_k.bias': 'output_blocks.0.1.transformer_blocks.9.attn1.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_v.weight': 'output_blocks.0.1.transformer_blocks.9.attn1.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_v.bias': 'output_blocks.0.1.transformer_blocks.9.attn1.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.9.attn1.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn1.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.9.attn1.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.norm2.weight': 'output_blocks.0.1.transformer_blocks.9.norm2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.norm2.bias': 'output_blocks.0.1.transformer_blocks.9.norm2.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_q.weight': 'output_blocks.0.1.transformer_blocks.9.attn2.to_q.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_q.bias': 'output_blocks.0.1.transformer_blocks.9.attn2.to_q.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_k.weight': 'output_blocks.0.1.transformer_blocks.9.attn2.to_k.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_k.bias': 'output_blocks.0.1.transformer_blocks.9.attn2.to_k.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_v.weight': 'output_blocks.0.1.transformer_blocks.9.attn2.to_v.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_v.bias': 'output_blocks.0.1.transformer_blocks.9.attn2.to_v.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_out.0.weight': 'output_blocks.0.1.transformer_blocks.9.attn2.to_out.0.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.attn2.to_out.0.bias': 'output_blocks.0.1.transformer_blocks.9.attn2.to_out.0.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.norm3.weight': 'output_blocks.0.1.transformer_blocks.9.norm3.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.norm3.bias': 'output_blocks.0.1.transformer_blocks.9.norm3.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.ff.net.0.proj.weight': 'output_blocks.0.1.transformer_blocks.9.ff.net.0.proj.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.ff.net.0.proj.bias': 'output_blocks.0.1.transformer_blocks.9.ff.net.0.proj.bias',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.ff.net.2.weight': 'output_blocks.0.1.transformer_blocks.9.ff.net.2.weight',\n",
       " 'up_blocks.0.attentions.0.transformer_blocks.9.ff.net.2.bias': 'output_blocks.0.1.transformer_blocks.9.ff.net.2.bias',\n",
       " 'up_blocks.0.attentions.0.proj_out.weight': 'output_blocks.0.1.proj_out.weight',\n",
       " 'up_blocks.0.attentions.0.proj_out.bias': 'output_blocks.0.1.proj_out.bias',\n",
       " 'up_blocks.0.attentions.1.norm.weight': 'output_blocks.1.1.norm.weight',\n",
       " 'up_blocks.0.attentions.1.norm.bias': 'output_blocks.1.1.norm.bias',\n",
       " 'up_blocks.0.attentions.1.proj_in.weight': 'output_blocks.1.1.proj_in.weight',\n",
       " 'up_blocks.0.attentions.1.proj_in.bias': 'output_blocks.1.1.proj_in.bias',\n",
       " 'up_blocks.0.attentions.1.transformer_blocks.0.norm1.weight': 'output_blocks.1.1.transformer_blocks.0.norm1.weight',\n",
       " 'up_blocks.0.attentions.1.transformer_blocks.0.norm1.bias': 'output_blocks.1.1.transformer_blocks.0.norm1.bias',\n",
       " 'up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight': 'output_blocks.1.1.transformer_blocks.0.attn1.to_q.weight',\n",
       " 'up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.bias': 'output_blocks.1.1.transformer_blocks.0.attn1.to_q.bias',\n",
       " ...}"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "f0252bed-d91b-42a6-a341-26dd74dff29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('state_dict_mapping.pkl', 'wb') as f:\n",
    "    pickle.dump(state_dict_mapping, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbc4e7c-5361-4c4e-b066-34d6f69d1a45",
   "metadata": {},
   "source": [
    "Now I should be able to load SDXL weights into the CNXS version of SDXL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a4584-ea32-4615-8659-f8a8a9a4cf00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
