{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bdc37ff-dab0-43f0-b401-0aa9fa146a0d",
   "metadata": {},
   "source": [
    "In this notebook, I want to understand in detail how `.save_pretrained` and `.from_pretrained` work, so I can use it for `ControlNetXSModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499ecede-776f-4f6a-a12f-c5a3e2d40cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.models import UNet2DConditionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7019a53e-ee1a-4493-92a7-a509fba8ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet2DConditionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e190b-1175-41a1-b152-3993b70f424c",
   "metadata": {},
   "source": [
    "```\n",
    "unet.__init__(\n",
    "    sample_size: Optional[int] = None,\n",
    "    in_channels: int = 4,\n",
    "    out_channels: int = 4,\n",
    "    center_input_sample: bool = False,\n",
    "    flip_sin_to_cos: bool = True,\n",
    "    freq_shift: int = 0,\n",
    "    down_block_types: Tuple[str] = ('CrossAttnDownBlock2D', 'CrossAttnDownBlock2D', 'CrossAttnDownBlock2D', 'DownBlock2D'),\n",
    "    mid_block_type: Optional[str] = 'UNetMidBlock2DCrossAttn',\n",
    "    up_block_types: Tuple[str] = ('UpBlock2D', 'CrossAttnUpBlock2D', 'CrossAttnUpBlock2D', 'CrossAttnUpBlock2D'),\n",
    "    only_cross_attention: Union[bool, Tuple[bool]] = False,\n",
    "    block_out_channels: Tuple[int] = (320, 640, 1280, 1280),\n",
    "    layers_per_block: Union[int, Tuple[int]] = 2,\n",
    "    downsample_padding: int = 1,\n",
    "    mid_block_scale_factor: float = 1,\n",
    "    dropout: float = 0.0,\n",
    "    act_fn: str = 'silu',\n",
    "    norm_num_groups: Optional[int] = 32,\n",
    "    norm_eps: float = 1e-05,\n",
    "    cross_attention_dim: Union[int, Tuple[int]] = 1280,\n",
    "    transformer_layers_per_block: Union[int, Tuple[int]] = 1,\n",
    "    encoder_hid_dim: Optional[int] = None,\n",
    "    encoder_hid_dim_type: Optional[str] = None,\n",
    "    attention_head_dim: Union[int, Tuple[int]] = 8,\n",
    "    num_attention_heads: Union[int, Tuple[int], NoneType] = None,\n",
    "    dual_cross_attention: bool = False,\n",
    "    use_linear_projection: bool = False,\n",
    "    class_embed_type: Optional[str] = None,\n",
    "    addition_embed_type: Optional[str] = None,\n",
    "    addition_time_embed_dim: Optional[int] = None,\n",
    "    num_class_embeds: Optional[int] = None,\n",
    "    upcast_attention: bool = False,\n",
    "    resnet_time_scale_shift: str = 'default',\n",
    "    resnet_skip_time_act: bool = False,\n",
    "    resnet_out_scale_factor: int = 1.0,\n",
    "    time_embedding_type: str = 'positional',\n",
    "    time_embedding_dim: Optional[int] = None,\n",
    "    time_embedding_act_fn: Optional[str] = None,\n",
    "    timestep_post_act: Optional[str] = None,\n",
    "    time_cond_proj_dim: Optional[int] = None,\n",
    "    conv_in_kernel: int = 3,\n",
    "    conv_out_kernel: int = 3,\n",
    "    projection_class_embeddings_input_dim: Optional[int] = None,\n",
    "    attention_type: str = 'default',\n",
    "    class_embeddings_concat: bool = False,\n",
    "    mid_block_only_cross_attention: Optional[bool] = None,\n",
    "    cross_attention_norm: Optional[str] = None,\n",
    "    addition_embed_type_num_heads=64,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "589aaecf-ff4d-4067-8046-59116916c418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenDict([('sample_size', None),\n",
       "            ('in_channels', 4),\n",
       "            ('out_channels', 4),\n",
       "            ('center_input_sample', False),\n",
       "            ('flip_sin_to_cos', True),\n",
       "            ('freq_shift', 0),\n",
       "            ('down_block_types',\n",
       "             ('CrossAttnDownBlock2D',\n",
       "              'CrossAttnDownBlock2D',\n",
       "              'CrossAttnDownBlock2D',\n",
       "              'DownBlock2D')),\n",
       "            ('mid_block_type', 'UNetMidBlock2DCrossAttn'),\n",
       "            ('up_block_types',\n",
       "             ('UpBlock2D',\n",
       "              'CrossAttnUpBlock2D',\n",
       "              'CrossAttnUpBlock2D',\n",
       "              'CrossAttnUpBlock2D')),\n",
       "            ('only_cross_attention', False),\n",
       "            ('block_out_channels', (320, 640, 1280, 1280)),\n",
       "            ('layers_per_block', 2),\n",
       "            ('downsample_padding', 1),\n",
       "            ('mid_block_scale_factor', 1),\n",
       "            ('dropout', 0.0),\n",
       "            ('act_fn', 'silu'),\n",
       "            ('norm_num_groups', 32),\n",
       "            ('norm_eps', 1e-05),\n",
       "            ('cross_attention_dim', 1280),\n",
       "            ('transformer_layers_per_block', 1),\n",
       "            ('encoder_hid_dim', None),\n",
       "            ('encoder_hid_dim_type', None),\n",
       "            ('attention_head_dim', 8),\n",
       "            ('num_attention_heads', None),\n",
       "            ('dual_cross_attention', False),\n",
       "            ('use_linear_projection', False),\n",
       "            ('class_embed_type', None),\n",
       "            ('addition_embed_type', None),\n",
       "            ('addition_time_embed_dim', None),\n",
       "            ('num_class_embeds', None),\n",
       "            ('upcast_attention', False),\n",
       "            ('resnet_time_scale_shift', 'default'),\n",
       "            ('resnet_skip_time_act', False),\n",
       "            ('resnet_out_scale_factor', 1.0),\n",
       "            ('time_embedding_type', 'positional'),\n",
       "            ('time_embedding_dim', None),\n",
       "            ('time_embedding_act_fn', None),\n",
       "            ('timestep_post_act', None),\n",
       "            ('time_cond_proj_dim', None),\n",
       "            ('conv_in_kernel', 3),\n",
       "            ('conv_out_kernel', 3),\n",
       "            ('projection_class_embeddings_input_dim', None),\n",
       "            ('attention_type', 'default'),\n",
       "            ('class_embeddings_concat', False),\n",
       "            ('mid_block_only_cross_attention', None),\n",
       "            ('cross_attention_norm', None),\n",
       "            ('addition_embed_type_num_heads', 64),\n",
       "            ('_use_default_values',\n",
       "             ['cross_attention_norm',\n",
       "              'block_out_channels',\n",
       "              'mid_block_only_cross_attention',\n",
       "              'num_class_embeds',\n",
       "              'norm_eps',\n",
       "              'conv_in_kernel',\n",
       "              'up_block_types',\n",
       "              'time_embedding_dim',\n",
       "              'cross_attention_dim',\n",
       "              'norm_num_groups',\n",
       "              'projection_class_embeddings_input_dim',\n",
       "              'class_embed_type',\n",
       "              'timestep_post_act',\n",
       "              'center_input_sample',\n",
       "              'dual_cross_attention',\n",
       "              'mid_block_scale_factor',\n",
       "              'addition_embed_type',\n",
       "              'upcast_attention',\n",
       "              'dropout',\n",
       "              'addition_time_embed_dim',\n",
       "              'time_cond_proj_dim',\n",
       "              'encoder_hid_dim',\n",
       "              'out_channels',\n",
       "              'resnet_skip_time_act',\n",
       "              'attention_type',\n",
       "              'addition_embed_type_num_heads',\n",
       "              'only_cross_attention',\n",
       "              'num_attention_heads',\n",
       "              'downsample_padding',\n",
       "              'sample_size',\n",
       "              'flip_sin_to_cos',\n",
       "              'act_fn',\n",
       "              'encoder_hid_dim_type',\n",
       "              'time_embedding_type',\n",
       "              'class_embeddings_concat',\n",
       "              'transformer_layers_per_block',\n",
       "              'conv_out_kernel',\n",
       "              'layers_per_block',\n",
       "              'use_linear_projection',\n",
       "              'freq_shift',\n",
       "              'resnet_out_scale_factor',\n",
       "              'time_embedding_act_fn',\n",
       "              'mid_block_type',\n",
       "              'in_channels',\n",
       "              'attention_head_dim',\n",
       "              'resnet_time_scale_shift',\n",
       "              'down_block_types'])])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55e1d4-3eda-4982-951f-d408daaa2245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
