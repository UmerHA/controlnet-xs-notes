{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a718e1-28e9-4766-9973-9207da3f986a",
   "metadata": {},
   "source": [
    "In this notebook, I want to map the modules of cnxs' unet and diffusers' onto each other. When done, I should be able to load diffuser weights into cnxs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0efad4-daef-4c45-b6b6-276d1de06161",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1ff2fc-41ba-4b77-82de-d76165e1f377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a08b518-d2d6-4251-b65f-fdb1aba792be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline, StableDiffusionControlNetXSPipeline, ControlNetXSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70686595-366a-4c49-91f5-7b044fc72fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54f5027610949f9b726f3f3d58a34b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "sd_pipe = StableDiffusionPipeline.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc691b66-7407-4cae-b649-92b0f98793ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = sd_pipe.unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a015b91e-0d55-48b1-b5b6-8775c497fe3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set `norm_num_groups` to `min(block_out_channels)` (=4) so it divides all block_out_channels` ([4, 8, 16, 16]). Set it explicitly to remove this information.\n"
     ]
    }
   ],
   "source": [
    "controlnet = ControlNetXSModel.create_as_in_paper(unet, sdxl=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd4c50d-f5bf-40ac-aee8-0c807bd19008",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e8dca895d743cda191e03efc774658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = StableDiffusionControlNetXSPipeline.from_pretrained(model, controlnet=controlnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "742b77c4-c801-49e2-9839-e7b915905637",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_unet = pipe.controlnet.control_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcce888-df2c-4cf5-b036-413d31664712",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc05ad01-2844-4ae9-a07f-8f88e90c6fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_dict(d, ignore_bias=True):\n",
    "    root = {}\n",
    "    for k,v in d.items():\n",
    "        if 'bias' in k: continue\n",
    "        parts = k.replace('.weight','').split(\".\")\n",
    "        d = root\n",
    "        for part in parts[:-1]:\n",
    "            d = d.setdefault(part, {})\n",
    "        d[parts[-1]] = v \n",
    "    return root\n",
    "\n",
    "def pretty_print_dict(d,lv=2,indent=0,depth=1):\n",
    "    if lv is not None and depth > lv: return\n",
    "    if not isinstance(d,dict):\n",
    "        print(d)\n",
    "        return\n",
    "    for k,v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            print('  ' * indent + str(k))\n",
    "            pretty_print_dict(v,lv,indent+2,depth+1)\n",
    "        else: \n",
    "            print('  ' * indent + str(k) + ' -> ' + str(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63b110f-4ff9-47a6-adaf-a38d84f7cace",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c850341-8974-49c2-986a-6c2c2c2e8bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_shape(o):\n",
    "    if isinstance(o,dict): return {k:to_shape(v) for k,v in o.items()}\n",
    "    elif isinstance(o,list): return o\n",
    "    else: return list(o.shape)\n",
    "\n",
    "def remove_bias(o):\n",
    "    if isinstance(o,dict): return {k.replace('.weight',''):remove_bias(v) for k,v in o.items() if not 'bias' in k}\n",
    "    else: return o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab290585-c9eb-4b3c-8e6f-4b66a3a74ae3",
   "metadata": {},
   "source": [
    "Load unet from CNXS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18fbc6e8-a9fc-43be-ac55-7594f97a6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05043d7d-50e9-47e2-b76c-6ca8b55d7ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cnsx_base_state_dict_with_shapes -- sd21.json', 'r') as infile:\n",
    "    cn_sdict = json.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59e657f0-7a5b-45e0-b479-3a850d924051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_list\n",
      "control_model\n",
      "enc_zero_convs_out\n",
      "enc_zero_convs_in\n",
      "dec_zero_convs_out\n",
      "middle_block_out\n",
      "input_hint_block\n",
      "\n",
      "control_model\n",
      "        time_embed\n",
      "        input_blocks\n",
      "        middle_block\n"
     ]
    }
   ],
   "source": [
    "from util import print_as_nested_dict\n",
    "print_as_nested_dict(cn_sdict, lv=1)\n",
    "print()\n",
    "print_as_nested_dict(cn_sdict, 'control_model', lv=2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b0ba1d-019b-4bab-b736-c372b3f48699",
   "metadata": {},
   "source": [
    "‼️ This notebook should only map the unet part of the control model. So let's delete the rest (connections, time embedding, input hint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80fefb26-6c4f-4d9d-8c6f-1038e0da77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_sdict = {\n",
    "    k.replace('control_model.',''): v for k,v in cn_sdict.items() if k.startswith('control_model.')  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d186b3c0-1fd1-4186-9fe6-7239929472b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_sdict = remove_bias(to_shape(cn_sdict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f1919e-fcab-4a25-a3f1-bc8103a8324b",
   "metadata": {},
   "source": [
    "Load unet from diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76e7816d-c4d8-452a-aa43-fa60a635222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sdict = remove_bias(to_shape(control_unet.state_dict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d38d7fb-cde0-4f48-9a1d-cc584fb4be1a",
   "metadata": {},
   "source": [
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f62d4a0f-d901-47c5-8738-1282e185a4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_bak = cn_sdict.copy()\n",
    "df_bak = df_sdict.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2244043-fdd2-4c37-98bd-855b24ffa072",
   "metadata": {},
   "source": [
    "### First goal: Map one resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c27daf3c-272a-4e8c-9de8-965cee58bbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MappedModule:\n",
    "    cn: str\n",
    "    df: str\n",
    "    shape: list\n",
    "    def __repr__(self): return f'{self.df} {self.shape}'\n",
    "\n",
    "\n",
    "class UnmappedModel:\n",
    "    # contains dict of style {'down_blocks.0.resnets.0': [4, 64, 64]}\n",
    "    def __init__(self, modules): self.modules = modules\n",
    "    def print(self, contains='', lv=None): pretty_print_dict(nested_dict(filter_dict(self.modules,by=contains)), lv=lv)\n",
    "    def remove(self,k): del self.modules[k]\n",
    "    def __getitem__(self,k): return self.modules[k]\n",
    "    def __len__(self): return len(self.modules)\n",
    "    def has(self,k): return any(k==k_ for k_ in self.modules.keys())\n",
    "    def __iter__(self): return iter(self.modules)\n",
    "\n",
    "def filter_dict(d,by): return {k:v for k,v in d.items() if by in k}\n",
    "\n",
    "class MappedModel:\n",
    "    modules = []\n",
    "\n",
    "    def __init__(self, unmapped_cn, unmapped_df):\n",
    "        self.unmapped_cn=UnmappedModel(unmapped_cn)\n",
    "        self.unmapped_df=UnmappedModel(unmapped_df)\n",
    "    \n",
    "    def add(self, cn_module, df_module):\n",
    "        # check shapes\n",
    "        cn_shape = self.unmapped_cn[cn_module]\n",
    "        df_shape = self.unmapped_df[df_module]\n",
    "        assert cn_shape==df_shape, f'Mapping don\\'t fit: {cn_shape} != {df_shape}'\n",
    "        # add to mapped\n",
    "        self.modules = sorted(self.modules + [MappedModule(cn=cn_module,df=df_module,shape=cn_shape)], key=lambda o:o.df)\n",
    "        # remove from unmapped\n",
    "        self.unmapped_cn.remove(cn_module)\n",
    "        self.unmapped_df.remove(df_module)\n",
    "        #print(f'Added {df_module} ✅')\n",
    "        \n",
    "    def __repr__(self): return '\\n'.join(str(m) for m in self.modules)\n",
    "    def __len__(self): return len(self.modules)\n",
    "\n",
    "    def __getitem__(self,k):\n",
    "        for m in self.modules:\n",
    "            if m.df==k: return m.cn\n",
    "        raise ValueError(f\"Didn't find  module with name {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c05ed78-5af2-4006-8278-35d74a15197e",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abbfa527-eb22-4b05-91ff-f2e4a86bb2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn = cn_bak.copy()\n",
    "df = df_bak.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58b4cb68-c408-4909-8e38-d9a0fb1cf56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped = MappedModel(cn,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f000c370-6f0f-4655-bbba-4717cdab9110",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_unmapped = UnmappedModel(cn)\n",
    "df_unmapped = UnmappedModel(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "550ec0d1-aa39-41e3-8641-7035ae079055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 177, 177)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped), len(cn_unmapped), len(df_unmapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475e0ea4-869a-474f-b124-ed754a24e8d9",
   "metadata": {},
   "source": [
    "#### Let's map the downblocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e31f6-e2d5-4923-b83c-0568305a5237",
   "metadata": {},
   "source": [
    "**Note:** The number of tranformer blocks varies between attentions. In downlock 1, there are 2, in downblock 2 each, there are 10 each.\n",
    "\n",
    "**Edit:** No, that's only the case for SDXL, not for SD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d51f217-535b-4764-8d1c-28ec213f42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import cls_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3500e242-9eae-40d3-bf41-7ee96c7a856a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0] CrossAttnDownBlock2D: 1 1\n",
      "1] CrossAttnDownBlock2D: 1 1\n",
      "2] CrossAttnDownBlock2D: 1 1\n",
      "3] DownBlock2D: \n"
     ]
    }
   ],
   "source": [
    "for i, down in enumerate(control_unet.down_blocks):\n",
    "    print(f'{i}] {cls_name(down)}: ', end='')\n",
    "    if hasattr(down, 'attentions'):\n",
    "         print(' '.join(str(len(a.transformer_blocks)) for a in down.attentions), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba35e953-908b-4992-9e6f-c4719efa7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import print_as_nested_dict\n",
    "\n",
    "def listy(o): return isinstance(o, (list, tuple))\n",
    "def listify(o): return o if listy(o) else [o]\n",
    "\n",
    "def compare_as_nested_dict(cnxs_search, df_search, lvs, print_leaf=True):\n",
    "    cnxs_search, df_search = listify(cnxs_search), listify(df_search)\n",
    "    if not listy(lvs): lvs = (lvs,lvs)\n",
    "    lv_cnxs, lv_df = lvs\n",
    "\n",
    "    for query in cnxs_search:\n",
    "        print_as_nested_dict(cn_sdict, query, lv=lv_cnxs, print_leaf=print_leaf)\n",
    "        print()\n",
    "    print('----')\n",
    "    for query in df_search:\n",
    "        print_as_nested_dict(df_sdict, query, lv=lv_df, print_leaf=print_leaf)\n",
    "        print()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca0b179c-7c01-4be1-a7ba-b9465f2dd0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare_as_nested_dict('input_blocks.1.0', 'down_blocks.0.resnets', lvs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8207950-985f-4eb7-a5f5-68b028c6df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_resnet(idx):\n",
    "    d1,d2,c=idx\n",
    "    cn_path = f'input_blocks.{c}.0.'\n",
    "    df_path = f'down_blocks.{d1}.resnets.{d2}.'\n",
    "    mapped.add(cn_module=cn_path+'in_layers.0',df_module=df_path+'norm1')\n",
    "    mapped.add(cn_module=cn_path+'in_layers.2',df_module=df_path+'conv1')\n",
    "    mapped.add(cn_module=cn_path+'emb_layers.1',df_module=df_path+'time_emb_proj')\n",
    "    mapped.add(cn_module=cn_path+'out_layers.0',df_module=df_path+'norm2')\n",
    "    mapped.add(cn_module=cn_path+'out_layers.3',df_module=df_path+'conv2')\n",
    "    if mapped.unmapped_df.has(df_path+'conv_shortcut'): mapped.add(cn_module=cn_path+'skip_connection',df_module=df_path+'conv_shortcut')\n",
    "    print(f'-- mapped resnet {d1},{d2} / {c}')\n",
    "\n",
    "def map_attn(idx):\n",
    "    d1,d2,c=idx\n",
    "    cn_path = f'input_blocks.{c}.1.'\n",
    "    df_path = f'down_blocks.{d1}.attentions.{d2}.'\n",
    "    mapped.add(cn_module=cn_path+'norm',df_module=df_path+'norm')\n",
    "    mapped.add(cn_module=cn_path+'proj_in',df_module=df_path+'proj_in')\n",
    "    num_tfs = 1 # sd21 always has 1 tf per layer for blocks 0 - 3; and none in block 4\n",
    "    for i in range(num_tfs): map_tfmr(f'{cn_path}transformer_blocks.{i}.',f'{df_path}transformer_blocks.{i}.')        \n",
    "    mapped.add(cn_module=cn_path+'proj_out',df_module=df_path+'proj_out')\n",
    "    print(f'-- mapped attn {d1},{d2} / {c}')\n",
    "\n",
    "\n",
    "def map_tfmr(cn_path,df_path):\n",
    "    # nomenclature of tranformers is equal in cnxs and diffuers\n",
    "    modules = [\n",
    "        'norm1',\n",
    "        'attn1.to_q','attn1.to_k','attn1.to_v','attn1.to_out.0',\n",
    "        'norm2',\n",
    "        'attn2.to_q','attn2.to_k','attn2.to_v','attn2.to_out.0',\n",
    "        'norm3',\n",
    "        'ff.net.0.proj','ff.net.2'\n",
    "    ]\n",
    "    for m in modules: mapped.add(cn_path+m,df_path+m)\n",
    "\n",
    "def map_downsample(idx):\n",
    "    d,c=idx\n",
    "    cn_path = f'input_blocks.{c}.0.'\n",
    "    df_path = f'down_blocks.{d}.downsamplers.0.'\n",
    "    mapped.add(cn_module=cn_path+'op',df_module=df_path+'conv')\n",
    "    print(f'-- mapped downsample {d} / {c}')\n",
    "\n",
    "def map_down_block():\n",
    "    blocks = 4\n",
    "    layers_per_block = 2\n",
    "\n",
    "    # # resnets\n",
    "    def subblock_no(b,l): return 1+b*(layers_per_block+1)+l\n",
    "    idx = [\n",
    "        (b,l, subblock_no(b,l))\n",
    "        for b in range(blocks)\n",
    "        for l in range(layers_per_block)\n",
    "    ]\n",
    "    for i in idx: map_resnet(i)\n",
    "    print(f'Mapped {len(idx)} Resnet blocks')\n",
    "    # # attentions\n",
    "    idx = [\n",
    "        (b,l, subblock_no(b,l))\n",
    "        for b in range(blocks-1) # in sd, last block has no attentions\n",
    "        for l in range(layers_per_block)\n",
    "    ]\n",
    "    for i in idx: map_attn(i)\n",
    "    print(f'Mapped {len(idx)} Attention blocks')\n",
    "    # # downsamplers\n",
    "    idx = [\n",
    "        (b,(b+1)*(layers_per_block+1))\n",
    "        for b in range(blocks-1) # last block has no downsampler\n",
    "    ]\n",
    "    for i in idx: map_downsample(i)\n",
    "    print(f'Mapped {len(idx)} Downsamplers blocks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46e1eff5-3264-4697-8e3d-c027054bc4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- mapped resnet 0,0 / 1\n",
      "-- mapped resnet 0,1 / 2\n",
      "-- mapped resnet 1,0 / 4\n",
      "-- mapped resnet 1,1 / 5\n",
      "-- mapped resnet 2,0 / 7\n",
      "-- mapped resnet 2,1 / 8\n",
      "-- mapped resnet 3,0 / 10\n",
      "-- mapped resnet 3,1 / 11\n",
      "Mapped 8 Resnet blocks\n",
      "-- mapped attn 0,0 / 1\n",
      "-- mapped attn 0,1 / 2\n",
      "-- mapped attn 1,0 / 4\n",
      "-- mapped attn 1,1 / 5\n",
      "-- mapped attn 2,0 / 7\n",
      "-- mapped attn 2,1 / 8\n",
      "Mapped 6 Attention blocks\n",
      "-- mapped downsample 0 / 3\n",
      "-- mapped downsample 1 / 6\n",
      "-- mapped downsample 2 / 9\n",
      "Mapped 3 Downsamplers blocks\n"
     ]
    }
   ],
   "source": [
    "map_down_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab9a441e-c5fe-49fa-8059-22c7f9732eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 30, 30)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped), len(cn_unmapped), len(df_unmapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8448be10-3a4e-4291-a25f-d6ebd6504ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_embed\n",
      "input_blocks\n",
      "middle_block\n"
     ]
    }
   ],
   "source": [
    "cn_unmapped.print(lv=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baebf344-6d99-40c7-bf97-205c617e667d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "108729d7-79f1-44ba-a698-4b66d906f253",
   "metadata": {},
   "source": [
    "#### Let's map the embeds, and conv in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f63c52d-414c-4bed-a482-a7f9ac5d7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_conv_in():\n",
    "    mapped.add(cn_module='input_blocks.0.0',df_module='conv_in')\n",
    "\n",
    "def map_embedds():\n",
    "    mapped.add(cn_module='time_embed.0',df_module='time_embedding.linear_1')\n",
    "    mapped.add(cn_module='time_embed.2',df_module='time_embedding.linear_2')\n",
    "    # # SD (unlike SDXL) has not micro-conditioning, so no add_embedding\n",
    "    # mapped.add(cn_module='label_emb.0.0',df_module='add_embedding.linear_1')\n",
    "    # mapped.add(cn_module='label_emb.0.2',df_module='add_embedding.linear_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61bfc092-7fc8-45d2-8601-1c4e20a7ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_conv_in()\n",
    "map_embedds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c6ec6a8-8255-4ac2-be24-4dd43bd02f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 27, 27)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped), len(cn_unmapped), len(df_unmapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06618283-e3c4-4547-bce6-c3bc2cd72cf4",
   "metadata": {},
   "source": [
    "#### Let's map the middle block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cafc724-2928-49e8-93bf-12671a9d3ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mid block has 2 resnets and 1 attentions\n",
      "Here are the # of transformers: 1"
     ]
    }
   ],
   "source": [
    "mid = control_unet.mid_block\n",
    "\n",
    "print(f'Mid block has {len(mid.resnets)} resnets and {len(mid.attentions)} attentions')\n",
    "\n",
    "print('Here are the # of transformers: ',end='')\n",
    "print(' '.join(str(len(a.transformer_blocks)) for a in mid.attentions), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5b8f082-9d5f-44ae-8e2d-59a836d96907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_resnet(d,c):\n",
    "    cn_path = f'middle_block.{c}.'\n",
    "    df_path = f'mid_block.resnets.{d}.'\n",
    "    mapped.add(cn_module=cn_path+'in_layers.0',df_module=df_path+'norm1')\n",
    "    mapped.add(cn_module=cn_path+'in_layers.2',df_module=df_path+'conv1')\n",
    "    mapped.add(cn_module=cn_path+'emb_layers.1',df_module=df_path+'time_emb_proj')\n",
    "    mapped.add(cn_module=cn_path+'out_layers.0',df_module=df_path+'norm2')\n",
    "    mapped.add(cn_module=cn_path+'out_layers.3',df_module=df_path+'conv2')\n",
    "    if mapped.unmapped_df.has(df_path+'conv_shortcut'): mapped.add(cn_module=cn_path+'skip_connection',df_module=df_path+'conv_shortcut')\n",
    "\n",
    "def map_attn(d,c):\n",
    "    cn_path = f'middle_block.{c}.'\n",
    "    df_path = f'mid_block.attentions.{d}.'\n",
    "    mapped.add(cn_module=cn_path+'norm',df_module=df_path+'norm')\n",
    "    mapped.add(cn_module=cn_path+'proj_in',df_module=df_path+'proj_in')\n",
    "    num_tfs = 1\n",
    "    for i in range(num_tfs): map_tfmr(f'{cn_path}transformer_blocks.{i}.',f'{df_path}transformer_blocks.{i}.')        \n",
    "    mapped.add(cn_module=cn_path+'proj_out',df_module=df_path+'proj_out')\n",
    "\n",
    "def map_tfmr(cn_path,df_path):\n",
    "    # nomenclature of tranformers is equal in cnxs and diffuers\n",
    "    modules = [\n",
    "        'norm1',\n",
    "        'attn1.to_q','attn1.to_k','attn1.to_v','attn1.to_out.0',\n",
    "        'norm2',\n",
    "        'attn2.to_q','attn2.to_k','attn2.to_v','attn2.to_out.0',\n",
    "        'norm3',\n",
    "        'ff.net.0.proj','ff.net.2'\n",
    "    ]\n",
    "    for m in modules: mapped.add(cn_path+m,df_path+m)\n",
    "\n",
    "def map_mid_block():\n",
    "    map_resnet(0,0)\n",
    "    map_attn(0,1)\n",
    "    map_resnet(1,2)\n",
    "    print(f'Mapped 2 Restnets and 1 Attention blocks (R/A/R)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4932c3dd-709c-4a53-8a5a-ad175053c46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped 2 Restnets and 1 Attention blocks (R/A/R)\n"
     ]
    }
   ],
   "source": [
    "map_mid_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be1b02b3-d883-420f-b49c-1bdccad0a507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 0, 0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapped), len(cn_unmapped), len(df_unmapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cfad78d-0c6a-4a43-8a39-c242c2fef000",
   "metadata": {},
   "outputs": [],
   "source": [
    "cn_to_skip = []\n",
    "df_to_skip = ['up_blocks', 'conv_norm_out', 'conv_out']\n",
    "\n",
    "for module in cn_unmapped:\n",
    "    assert any(o in str(module) for o in cn_to_skip), f\"Couldn't map {module}\"\n",
    "\n",
    "for module in df_unmapped:\n",
    "    assert any(o in str(module) for o in df_to_skip), f\"Couldn't map {module}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2487825-5adb-4fb2-8237-32217a55cc63",
   "metadata": {},
   "source": [
    "**Done!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e54e78-fbc6-4b5d-af84-bd8533ae3451",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a9cf0d-4442-44bf-822a-4b9515af9903",
   "metadata": {},
   "source": [
    "Now, let's create the final mapping dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607702f8-b362-4c71-ab27-4bbaecbe38ec",
   "metadata": {},
   "source": [
    "Let's quickly check that all weights are actually mapped (if not, the below line will throw a ValueError)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "202da85b-2e35-4597-b3f0-0f8ae1f400f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in pipe.unet.state_dict().keys():\n",
    "    if any(o in k for o in df_to_skip): continue\n",
    "    mapped[k.replace('.weight','').replace('.bias','')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa69392-a2fb-428d-aeea-da83a9378e1d",
   "metadata": {},
   "source": [
    "Works, cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "541ee1cf-1e53-4c8b-8939-812a86e426ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_mapping = {}\n",
    "for k in pipe.unet.state_dict().keys():\n",
    "    if any(o in k for o in df_to_skip): continue\n",
    "    \n",
    "    k_df = k.replace('.weight','').replace('.bias','')\n",
    "    k_cn = mapped[k_df]\n",
    "    state_dict_mapping[k_df+'.weight'] = k_cn+'.weight'\n",
    "    state_dict_mapping[k_df+'.bias'] = k_cn+'.bias'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "105345a2-3415-4b10-b5f0-890c6344181d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_in.weight': 'input_blocks.0.0.weight',\n",
       " 'conv_in.bias': 'input_blocks.0.0.bias',\n",
       " 'time_embedding.linear_1.weight': 'time_embed.0.weight',\n",
       " 'time_embedding.linear_1.bias': 'time_embed.0.bias',\n",
       " 'time_embedding.linear_2.weight': 'time_embed.2.weight',\n",
       " 'time_embedding.linear_2.bias': 'time_embed.2.bias',\n",
       " 'down_blocks.0.attentions.0.norm.weight': 'input_blocks.1.1.norm.weight',\n",
       " 'down_blocks.0.attentions.0.norm.bias': 'input_blocks.1.1.norm.bias',\n",
       " 'down_blocks.0.attentions.0.proj_in.weight': 'input_blocks.1.1.proj_in.weight',\n",
       " 'down_blocks.0.attentions.0.proj_in.bias': 'input_blocks.1.1.proj_in.bias',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.norm1.weight': 'input_blocks.1.1.transformer_blocks.0.norm1.weight',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.norm1.bias': 'input_blocks.1.1.transformer_blocks.0.norm1.bias',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.1.1.transformer_blocks.0.attn1.to_q.weight',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.bias': 'input_blocks.1.1.transformer_blocks.0.attn1.to_q.bias',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.1.1.transformer_blocks.0.attn1.to_k.weight',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.bias': 'input_blocks.1.1.transformer_blocks.0.attn1.to_k.bias',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.1.1.transformer_blocks.0.attn1.to_v.weight',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.bias': 'input_blocks.1.1.transformer_blocks.0.attn1.to_v.bias',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.weight',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.1.1.transformer_blocks.0.attn1.to_out.0.bias',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.norm2.weight': 'input_blocks.1.1.transformer_blocks.0.norm2.weight',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.norm2.bias': 'input_blocks.1.1.transformer_blocks.0.norm2.bias',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.1.1.transformer_blocks.0.attn2.to_q.weight',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.bias': 'input_blocks.1.1.transformer_blocks.0.attn2.to_q.bias',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.1.1.transformer_blocks.0.attn2.to_k.weight',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.bias': 'input_blocks.1.1.transformer_blocks.0.attn2.to_k.bias',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.1.1.transformer_blocks.0.attn2.to_v.weight',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.bias': 'input_blocks.1.1.transformer_blocks.0.attn2.to_v.bias',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.weight',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.1.1.transformer_blocks.0.attn2.to_out.0.bias',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.norm3.weight': 'input_blocks.1.1.transformer_blocks.0.norm3.weight',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.norm3.bias': 'input_blocks.1.1.transformer_blocks.0.norm3.bias',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.weight',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.1.1.transformer_blocks.0.ff.net.0.proj.bias',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight': 'input_blocks.1.1.transformer_blocks.0.ff.net.2.weight',\n",
       " 'down_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias': 'input_blocks.1.1.transformer_blocks.0.ff.net.2.bias',\n",
       " 'down_blocks.0.attentions.0.proj_out.weight': 'input_blocks.1.1.proj_out.weight',\n",
       " 'down_blocks.0.attentions.0.proj_out.bias': 'input_blocks.1.1.proj_out.bias',\n",
       " 'down_blocks.0.attentions.1.norm.weight': 'input_blocks.2.1.norm.weight',\n",
       " 'down_blocks.0.attentions.1.norm.bias': 'input_blocks.2.1.norm.bias',\n",
       " 'down_blocks.0.attentions.1.proj_in.weight': 'input_blocks.2.1.proj_in.weight',\n",
       " 'down_blocks.0.attentions.1.proj_in.bias': 'input_blocks.2.1.proj_in.bias',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.norm1.weight': 'input_blocks.2.1.transformer_blocks.0.norm1.weight',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.norm1.bias': 'input_blocks.2.1.transformer_blocks.0.norm1.bias',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.2.1.transformer_blocks.0.attn1.to_q.weight',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.bias': 'input_blocks.2.1.transformer_blocks.0.attn1.to_q.bias',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.2.1.transformer_blocks.0.attn1.to_k.weight',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.bias': 'input_blocks.2.1.transformer_blocks.0.attn1.to_k.bias',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.2.1.transformer_blocks.0.attn1.to_v.weight',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.bias': 'input_blocks.2.1.transformer_blocks.0.attn1.to_v.bias',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.weight',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.2.1.transformer_blocks.0.attn1.to_out.0.bias',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.norm2.weight': 'input_blocks.2.1.transformer_blocks.0.norm2.weight',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.norm2.bias': 'input_blocks.2.1.transformer_blocks.0.norm2.bias',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.2.1.transformer_blocks.0.attn2.to_q.weight',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.bias': 'input_blocks.2.1.transformer_blocks.0.attn2.to_q.bias',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.2.1.transformer_blocks.0.attn2.to_k.weight',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.bias': 'input_blocks.2.1.transformer_blocks.0.attn2.to_k.bias',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.2.1.transformer_blocks.0.attn2.to_v.weight',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.bias': 'input_blocks.2.1.transformer_blocks.0.attn2.to_v.bias',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.weight',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.2.1.transformer_blocks.0.attn2.to_out.0.bias',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.norm3.weight': 'input_blocks.2.1.transformer_blocks.0.norm3.weight',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.norm3.bias': 'input_blocks.2.1.transformer_blocks.0.norm3.bias',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.weight',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.2.1.transformer_blocks.0.ff.net.0.proj.bias',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight': 'input_blocks.2.1.transformer_blocks.0.ff.net.2.weight',\n",
       " 'down_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias': 'input_blocks.2.1.transformer_blocks.0.ff.net.2.bias',\n",
       " 'down_blocks.0.attentions.1.proj_out.weight': 'input_blocks.2.1.proj_out.weight',\n",
       " 'down_blocks.0.attentions.1.proj_out.bias': 'input_blocks.2.1.proj_out.bias',\n",
       " 'down_blocks.0.resnets.0.norm1.weight': 'input_blocks.1.0.in_layers.0.weight',\n",
       " 'down_blocks.0.resnets.0.norm1.bias': 'input_blocks.1.0.in_layers.0.bias',\n",
       " 'down_blocks.0.resnets.0.conv1.weight': 'input_blocks.1.0.in_layers.2.weight',\n",
       " 'down_blocks.0.resnets.0.conv1.bias': 'input_blocks.1.0.in_layers.2.bias',\n",
       " 'down_blocks.0.resnets.0.time_emb_proj.weight': 'input_blocks.1.0.emb_layers.1.weight',\n",
       " 'down_blocks.0.resnets.0.time_emb_proj.bias': 'input_blocks.1.0.emb_layers.1.bias',\n",
       " 'down_blocks.0.resnets.0.norm2.weight': 'input_blocks.1.0.out_layers.0.weight',\n",
       " 'down_blocks.0.resnets.0.norm2.bias': 'input_blocks.1.0.out_layers.0.bias',\n",
       " 'down_blocks.0.resnets.0.conv2.weight': 'input_blocks.1.0.out_layers.3.weight',\n",
       " 'down_blocks.0.resnets.0.conv2.bias': 'input_blocks.1.0.out_layers.3.bias',\n",
       " 'down_blocks.0.resnets.1.norm1.weight': 'input_blocks.2.0.in_layers.0.weight',\n",
       " 'down_blocks.0.resnets.1.norm1.bias': 'input_blocks.2.0.in_layers.0.bias',\n",
       " 'down_blocks.0.resnets.1.conv1.weight': 'input_blocks.2.0.in_layers.2.weight',\n",
       " 'down_blocks.0.resnets.1.conv1.bias': 'input_blocks.2.0.in_layers.2.bias',\n",
       " 'down_blocks.0.resnets.1.time_emb_proj.weight': 'input_blocks.2.0.emb_layers.1.weight',\n",
       " 'down_blocks.0.resnets.1.time_emb_proj.bias': 'input_blocks.2.0.emb_layers.1.bias',\n",
       " 'down_blocks.0.resnets.1.norm2.weight': 'input_blocks.2.0.out_layers.0.weight',\n",
       " 'down_blocks.0.resnets.1.norm2.bias': 'input_blocks.2.0.out_layers.0.bias',\n",
       " 'down_blocks.0.resnets.1.conv2.weight': 'input_blocks.2.0.out_layers.3.weight',\n",
       " 'down_blocks.0.resnets.1.conv2.bias': 'input_blocks.2.0.out_layers.3.bias',\n",
       " 'down_blocks.0.downsamplers.0.conv.weight': 'input_blocks.3.0.op.weight',\n",
       " 'down_blocks.0.downsamplers.0.conv.bias': 'input_blocks.3.0.op.bias',\n",
       " 'down_blocks.1.attentions.0.norm.weight': 'input_blocks.4.1.norm.weight',\n",
       " 'down_blocks.1.attentions.0.norm.bias': 'input_blocks.4.1.norm.bias',\n",
       " 'down_blocks.1.attentions.0.proj_in.weight': 'input_blocks.4.1.proj_in.weight',\n",
       " 'down_blocks.1.attentions.0.proj_in.bias': 'input_blocks.4.1.proj_in.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight': 'input_blocks.4.1.transformer_blocks.0.norm1.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias': 'input_blocks.4.1.transformer_blocks.0.norm1.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.4.1.transformer_blocks.0.attn1.to_q.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.bias': 'input_blocks.4.1.transformer_blocks.0.attn1.to_q.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.4.1.transformer_blocks.0.attn1.to_k.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.bias': 'input_blocks.4.1.transformer_blocks.0.attn1.to_k.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.4.1.transformer_blocks.0.attn1.to_v.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.bias': 'input_blocks.4.1.transformer_blocks.0.attn1.to_v.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.4.1.transformer_blocks.0.attn1.to_out.0.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight': 'input_blocks.4.1.transformer_blocks.0.norm2.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias': 'input_blocks.4.1.transformer_blocks.0.norm2.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.4.1.transformer_blocks.0.attn2.to_q.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.bias': 'input_blocks.4.1.transformer_blocks.0.attn2.to_q.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.4.1.transformer_blocks.0.attn2.to_k.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.bias': 'input_blocks.4.1.transformer_blocks.0.attn2.to_k.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.4.1.transformer_blocks.0.attn2.to_v.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.bias': 'input_blocks.4.1.transformer_blocks.0.attn2.to_v.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.4.1.transformer_blocks.0.attn2.to_out.0.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight': 'input_blocks.4.1.transformer_blocks.0.norm3.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias': 'input_blocks.4.1.transformer_blocks.0.norm3.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.4.1.transformer_blocks.0.ff.net.0.proj.bias',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight': 'input_blocks.4.1.transformer_blocks.0.ff.net.2.weight',\n",
       " 'down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias': 'input_blocks.4.1.transformer_blocks.0.ff.net.2.bias',\n",
       " 'down_blocks.1.attentions.0.proj_out.weight': 'input_blocks.4.1.proj_out.weight',\n",
       " 'down_blocks.1.attentions.0.proj_out.bias': 'input_blocks.4.1.proj_out.bias',\n",
       " 'down_blocks.1.attentions.1.norm.weight': 'input_blocks.5.1.norm.weight',\n",
       " 'down_blocks.1.attentions.1.norm.bias': 'input_blocks.5.1.norm.bias',\n",
       " 'down_blocks.1.attentions.1.proj_in.weight': 'input_blocks.5.1.proj_in.weight',\n",
       " 'down_blocks.1.attentions.1.proj_in.bias': 'input_blocks.5.1.proj_in.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight': 'input_blocks.5.1.transformer_blocks.0.norm1.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias': 'input_blocks.5.1.transformer_blocks.0.norm1.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.5.1.transformer_blocks.0.attn1.to_q.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.bias': 'input_blocks.5.1.transformer_blocks.0.attn1.to_q.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.5.1.transformer_blocks.0.attn1.to_k.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.bias': 'input_blocks.5.1.transformer_blocks.0.attn1.to_k.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.5.1.transformer_blocks.0.attn1.to_v.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.bias': 'input_blocks.5.1.transformer_blocks.0.attn1.to_v.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.5.1.transformer_blocks.0.attn1.to_out.0.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight': 'input_blocks.5.1.transformer_blocks.0.norm2.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias': 'input_blocks.5.1.transformer_blocks.0.norm2.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.5.1.transformer_blocks.0.attn2.to_q.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.bias': 'input_blocks.5.1.transformer_blocks.0.attn2.to_q.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.5.1.transformer_blocks.0.attn2.to_k.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.bias': 'input_blocks.5.1.transformer_blocks.0.attn2.to_k.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.5.1.transformer_blocks.0.attn2.to_v.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.bias': 'input_blocks.5.1.transformer_blocks.0.attn2.to_v.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.5.1.transformer_blocks.0.attn2.to_out.0.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight': 'input_blocks.5.1.transformer_blocks.0.norm3.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias': 'input_blocks.5.1.transformer_blocks.0.norm3.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.5.1.transformer_blocks.0.ff.net.0.proj.bias',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight': 'input_blocks.5.1.transformer_blocks.0.ff.net.2.weight',\n",
       " 'down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias': 'input_blocks.5.1.transformer_blocks.0.ff.net.2.bias',\n",
       " 'down_blocks.1.attentions.1.proj_out.weight': 'input_blocks.5.1.proj_out.weight',\n",
       " 'down_blocks.1.attentions.1.proj_out.bias': 'input_blocks.5.1.proj_out.bias',\n",
       " 'down_blocks.1.resnets.0.norm1.weight': 'input_blocks.4.0.in_layers.0.weight',\n",
       " 'down_blocks.1.resnets.0.norm1.bias': 'input_blocks.4.0.in_layers.0.bias',\n",
       " 'down_blocks.1.resnets.0.conv1.weight': 'input_blocks.4.0.in_layers.2.weight',\n",
       " 'down_blocks.1.resnets.0.conv1.bias': 'input_blocks.4.0.in_layers.2.bias',\n",
       " 'down_blocks.1.resnets.0.time_emb_proj.weight': 'input_blocks.4.0.emb_layers.1.weight',\n",
       " 'down_blocks.1.resnets.0.time_emb_proj.bias': 'input_blocks.4.0.emb_layers.1.bias',\n",
       " 'down_blocks.1.resnets.0.norm2.weight': 'input_blocks.4.0.out_layers.0.weight',\n",
       " 'down_blocks.1.resnets.0.norm2.bias': 'input_blocks.4.0.out_layers.0.bias',\n",
       " 'down_blocks.1.resnets.0.conv2.weight': 'input_blocks.4.0.out_layers.3.weight',\n",
       " 'down_blocks.1.resnets.0.conv2.bias': 'input_blocks.4.0.out_layers.3.bias',\n",
       " 'down_blocks.1.resnets.0.conv_shortcut.weight': 'input_blocks.4.0.skip_connection.weight',\n",
       " 'down_blocks.1.resnets.0.conv_shortcut.bias': 'input_blocks.4.0.skip_connection.bias',\n",
       " 'down_blocks.1.resnets.1.norm1.weight': 'input_blocks.5.0.in_layers.0.weight',\n",
       " 'down_blocks.1.resnets.1.norm1.bias': 'input_blocks.5.0.in_layers.0.bias',\n",
       " 'down_blocks.1.resnets.1.conv1.weight': 'input_blocks.5.0.in_layers.2.weight',\n",
       " 'down_blocks.1.resnets.1.conv1.bias': 'input_blocks.5.0.in_layers.2.bias',\n",
       " 'down_blocks.1.resnets.1.time_emb_proj.weight': 'input_blocks.5.0.emb_layers.1.weight',\n",
       " 'down_blocks.1.resnets.1.time_emb_proj.bias': 'input_blocks.5.0.emb_layers.1.bias',\n",
       " 'down_blocks.1.resnets.1.norm2.weight': 'input_blocks.5.0.out_layers.0.weight',\n",
       " 'down_blocks.1.resnets.1.norm2.bias': 'input_blocks.5.0.out_layers.0.bias',\n",
       " 'down_blocks.1.resnets.1.conv2.weight': 'input_blocks.5.0.out_layers.3.weight',\n",
       " 'down_blocks.1.resnets.1.conv2.bias': 'input_blocks.5.0.out_layers.3.bias',\n",
       " 'down_blocks.1.downsamplers.0.conv.weight': 'input_blocks.6.0.op.weight',\n",
       " 'down_blocks.1.downsamplers.0.conv.bias': 'input_blocks.6.0.op.bias',\n",
       " 'down_blocks.2.attentions.0.norm.weight': 'input_blocks.7.1.norm.weight',\n",
       " 'down_blocks.2.attentions.0.norm.bias': 'input_blocks.7.1.norm.bias',\n",
       " 'down_blocks.2.attentions.0.proj_in.weight': 'input_blocks.7.1.proj_in.weight',\n",
       " 'down_blocks.2.attentions.0.proj_in.bias': 'input_blocks.7.1.proj_in.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight': 'input_blocks.7.1.transformer_blocks.0.norm1.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias': 'input_blocks.7.1.transformer_blocks.0.norm1.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.7.1.transformer_blocks.0.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.bias': 'input_blocks.7.1.transformer_blocks.0.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.7.1.transformer_blocks.0.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.bias': 'input_blocks.7.1.transformer_blocks.0.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.7.1.transformer_blocks.0.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.bias': 'input_blocks.7.1.transformer_blocks.0.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.0.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight': 'input_blocks.7.1.transformer_blocks.0.norm2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias': 'input_blocks.7.1.transformer_blocks.0.norm2.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.7.1.transformer_blocks.0.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.bias': 'input_blocks.7.1.transformer_blocks.0.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.7.1.transformer_blocks.0.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.bias': 'input_blocks.7.1.transformer_blocks.0.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.7.1.transformer_blocks.0.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.bias': 'input_blocks.7.1.transformer_blocks.0.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.7.1.transformer_blocks.0.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight': 'input_blocks.7.1.transformer_blocks.0.norm3.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias': 'input_blocks.7.1.transformer_blocks.0.norm3.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.7.1.transformer_blocks.0.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight': 'input_blocks.7.1.transformer_blocks.0.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias': 'input_blocks.7.1.transformer_blocks.0.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.0.proj_out.weight': 'input_blocks.7.1.proj_out.weight',\n",
       " 'down_blocks.2.attentions.0.proj_out.bias': 'input_blocks.7.1.proj_out.bias',\n",
       " 'down_blocks.2.attentions.1.norm.weight': 'input_blocks.8.1.norm.weight',\n",
       " 'down_blocks.2.attentions.1.norm.bias': 'input_blocks.8.1.norm.bias',\n",
       " 'down_blocks.2.attentions.1.proj_in.weight': 'input_blocks.8.1.proj_in.weight',\n",
       " 'down_blocks.2.attentions.1.proj_in.bias': 'input_blocks.8.1.proj_in.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight': 'input_blocks.8.1.transformer_blocks.0.norm1.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias': 'input_blocks.8.1.transformer_blocks.0.norm1.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight': 'input_blocks.8.1.transformer_blocks.0.attn1.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.bias': 'input_blocks.8.1.transformer_blocks.0.attn1.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight': 'input_blocks.8.1.transformer_blocks.0.attn1.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.bias': 'input_blocks.8.1.transformer_blocks.0.attn1.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight': 'input_blocks.8.1.transformer_blocks.0.attn1.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.bias': 'input_blocks.8.1.transformer_blocks.0.attn1.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.0.attn1.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight': 'input_blocks.8.1.transformer_blocks.0.norm2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias': 'input_blocks.8.1.transformer_blocks.0.norm2.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight': 'input_blocks.8.1.transformer_blocks.0.attn2.to_q.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.bias': 'input_blocks.8.1.transformer_blocks.0.attn2.to_q.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight': 'input_blocks.8.1.transformer_blocks.0.attn2.to_k.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.bias': 'input_blocks.8.1.transformer_blocks.0.attn2.to_k.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight': 'input_blocks.8.1.transformer_blocks.0.attn2.to_v.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.bias': 'input_blocks.8.1.transformer_blocks.0.attn2.to_v.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight': 'input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias': 'input_blocks.8.1.transformer_blocks.0.attn2.to_out.0.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight': 'input_blocks.8.1.transformer_blocks.0.norm3.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias': 'input_blocks.8.1.transformer_blocks.0.norm3.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight': 'input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias': 'input_blocks.8.1.transformer_blocks.0.ff.net.0.proj.bias',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight': 'input_blocks.8.1.transformer_blocks.0.ff.net.2.weight',\n",
       " 'down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias': 'input_blocks.8.1.transformer_blocks.0.ff.net.2.bias',\n",
       " 'down_blocks.2.attentions.1.proj_out.weight': 'input_blocks.8.1.proj_out.weight',\n",
       " 'down_blocks.2.attentions.1.proj_out.bias': 'input_blocks.8.1.proj_out.bias',\n",
       " 'down_blocks.2.resnets.0.norm1.weight': 'input_blocks.7.0.in_layers.0.weight',\n",
       " 'down_blocks.2.resnets.0.norm1.bias': 'input_blocks.7.0.in_layers.0.bias',\n",
       " 'down_blocks.2.resnets.0.conv1.weight': 'input_blocks.7.0.in_layers.2.weight',\n",
       " 'down_blocks.2.resnets.0.conv1.bias': 'input_blocks.7.0.in_layers.2.bias',\n",
       " 'down_blocks.2.resnets.0.time_emb_proj.weight': 'input_blocks.7.0.emb_layers.1.weight',\n",
       " 'down_blocks.2.resnets.0.time_emb_proj.bias': 'input_blocks.7.0.emb_layers.1.bias',\n",
       " 'down_blocks.2.resnets.0.norm2.weight': 'input_blocks.7.0.out_layers.0.weight',\n",
       " 'down_blocks.2.resnets.0.norm2.bias': 'input_blocks.7.0.out_layers.0.bias',\n",
       " 'down_blocks.2.resnets.0.conv2.weight': 'input_blocks.7.0.out_layers.3.weight',\n",
       " 'down_blocks.2.resnets.0.conv2.bias': 'input_blocks.7.0.out_layers.3.bias',\n",
       " 'down_blocks.2.resnets.0.conv_shortcut.weight': 'input_blocks.7.0.skip_connection.weight',\n",
       " 'down_blocks.2.resnets.0.conv_shortcut.bias': 'input_blocks.7.0.skip_connection.bias',\n",
       " 'down_blocks.2.resnets.1.norm1.weight': 'input_blocks.8.0.in_layers.0.weight',\n",
       " 'down_blocks.2.resnets.1.norm1.bias': 'input_blocks.8.0.in_layers.0.bias',\n",
       " 'down_blocks.2.resnets.1.conv1.weight': 'input_blocks.8.0.in_layers.2.weight',\n",
       " 'down_blocks.2.resnets.1.conv1.bias': 'input_blocks.8.0.in_layers.2.bias',\n",
       " 'down_blocks.2.resnets.1.time_emb_proj.weight': 'input_blocks.8.0.emb_layers.1.weight',\n",
       " 'down_blocks.2.resnets.1.time_emb_proj.bias': 'input_blocks.8.0.emb_layers.1.bias',\n",
       " 'down_blocks.2.resnets.1.norm2.weight': 'input_blocks.8.0.out_layers.0.weight',\n",
       " 'down_blocks.2.resnets.1.norm2.bias': 'input_blocks.8.0.out_layers.0.bias',\n",
       " 'down_blocks.2.resnets.1.conv2.weight': 'input_blocks.8.0.out_layers.3.weight',\n",
       " 'down_blocks.2.resnets.1.conv2.bias': 'input_blocks.8.0.out_layers.3.bias',\n",
       " 'down_blocks.2.downsamplers.0.conv.weight': 'input_blocks.9.0.op.weight',\n",
       " 'down_blocks.2.downsamplers.0.conv.bias': 'input_blocks.9.0.op.bias',\n",
       " 'down_blocks.3.resnets.0.norm1.weight': 'input_blocks.10.0.in_layers.0.weight',\n",
       " 'down_blocks.3.resnets.0.norm1.bias': 'input_blocks.10.0.in_layers.0.bias',\n",
       " 'down_blocks.3.resnets.0.conv1.weight': 'input_blocks.10.0.in_layers.2.weight',\n",
       " 'down_blocks.3.resnets.0.conv1.bias': 'input_blocks.10.0.in_layers.2.bias',\n",
       " 'down_blocks.3.resnets.0.time_emb_proj.weight': 'input_blocks.10.0.emb_layers.1.weight',\n",
       " 'down_blocks.3.resnets.0.time_emb_proj.bias': 'input_blocks.10.0.emb_layers.1.bias',\n",
       " 'down_blocks.3.resnets.0.norm2.weight': 'input_blocks.10.0.out_layers.0.weight',\n",
       " 'down_blocks.3.resnets.0.norm2.bias': 'input_blocks.10.0.out_layers.0.bias',\n",
       " 'down_blocks.3.resnets.0.conv2.weight': 'input_blocks.10.0.out_layers.3.weight',\n",
       " 'down_blocks.3.resnets.0.conv2.bias': 'input_blocks.10.0.out_layers.3.bias',\n",
       " 'down_blocks.3.resnets.1.norm1.weight': 'input_blocks.11.0.in_layers.0.weight',\n",
       " 'down_blocks.3.resnets.1.norm1.bias': 'input_blocks.11.0.in_layers.0.bias',\n",
       " 'down_blocks.3.resnets.1.conv1.weight': 'input_blocks.11.0.in_layers.2.weight',\n",
       " 'down_blocks.3.resnets.1.conv1.bias': 'input_blocks.11.0.in_layers.2.bias',\n",
       " 'down_blocks.3.resnets.1.time_emb_proj.weight': 'input_blocks.11.0.emb_layers.1.weight',\n",
       " 'down_blocks.3.resnets.1.time_emb_proj.bias': 'input_blocks.11.0.emb_layers.1.bias',\n",
       " 'down_blocks.3.resnets.1.norm2.weight': 'input_blocks.11.0.out_layers.0.weight',\n",
       " 'down_blocks.3.resnets.1.norm2.bias': 'input_blocks.11.0.out_layers.0.bias',\n",
       " 'down_blocks.3.resnets.1.conv2.weight': 'input_blocks.11.0.out_layers.3.weight',\n",
       " 'down_blocks.3.resnets.1.conv2.bias': 'input_blocks.11.0.out_layers.3.bias',\n",
       " 'mid_block.attentions.0.norm.weight': 'middle_block.1.norm.weight',\n",
       " 'mid_block.attentions.0.norm.bias': 'middle_block.1.norm.bias',\n",
       " 'mid_block.attentions.0.proj_in.weight': 'middle_block.1.proj_in.weight',\n",
       " 'mid_block.attentions.0.proj_in.bias': 'middle_block.1.proj_in.bias',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.norm1.weight': 'middle_block.1.transformer_blocks.0.norm1.weight',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.norm1.bias': 'middle_block.1.transformer_blocks.0.norm1.bias',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight': 'middle_block.1.transformer_blocks.0.attn1.to_q.weight',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn1.to_q.bias': 'middle_block.1.transformer_blocks.0.attn1.to_q.bias',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight': 'middle_block.1.transformer_blocks.0.attn1.to_k.weight',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn1.to_k.bias': 'middle_block.1.transformer_blocks.0.attn1.to_k.bias',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight': 'middle_block.1.transformer_blocks.0.attn1.to_v.weight',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn1.to_v.bias': 'middle_block.1.transformer_blocks.0.attn1.to_v.bias',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight': 'middle_block.1.transformer_blocks.0.attn1.to_out.0.weight',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias': 'middle_block.1.transformer_blocks.0.attn1.to_out.0.bias',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.norm2.weight': 'middle_block.1.transformer_blocks.0.norm2.weight',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.norm2.bias': 'middle_block.1.transformer_blocks.0.norm2.bias',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight': 'middle_block.1.transformer_blocks.0.attn2.to_q.weight',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn2.to_q.bias': 'middle_block.1.transformer_blocks.0.attn2.to_q.bias',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight': 'middle_block.1.transformer_blocks.0.attn2.to_k.weight',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn2.to_k.bias': 'middle_block.1.transformer_blocks.0.attn2.to_k.bias',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight': 'middle_block.1.transformer_blocks.0.attn2.to_v.weight',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn2.to_v.bias': 'middle_block.1.transformer_blocks.0.attn2.to_v.bias',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight': 'middle_block.1.transformer_blocks.0.attn2.to_out.0.weight',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias': 'middle_block.1.transformer_blocks.0.attn2.to_out.0.bias',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.norm3.weight': 'middle_block.1.transformer_blocks.0.norm3.weight',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.norm3.bias': 'middle_block.1.transformer_blocks.0.norm3.bias',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight': 'middle_block.1.transformer_blocks.0.ff.net.0.proj.weight',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias': 'middle_block.1.transformer_blocks.0.ff.net.0.proj.bias',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight': 'middle_block.1.transformer_blocks.0.ff.net.2.weight',\n",
       " 'mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias': 'middle_block.1.transformer_blocks.0.ff.net.2.bias',\n",
       " 'mid_block.attentions.0.proj_out.weight': 'middle_block.1.proj_out.weight',\n",
       " 'mid_block.attentions.0.proj_out.bias': 'middle_block.1.proj_out.bias',\n",
       " 'mid_block.resnets.0.norm1.weight': 'middle_block.0.in_layers.0.weight',\n",
       " 'mid_block.resnets.0.norm1.bias': 'middle_block.0.in_layers.0.bias',\n",
       " 'mid_block.resnets.0.conv1.weight': 'middle_block.0.in_layers.2.weight',\n",
       " 'mid_block.resnets.0.conv1.bias': 'middle_block.0.in_layers.2.bias',\n",
       " 'mid_block.resnets.0.time_emb_proj.weight': 'middle_block.0.emb_layers.1.weight',\n",
       " 'mid_block.resnets.0.time_emb_proj.bias': 'middle_block.0.emb_layers.1.bias',\n",
       " 'mid_block.resnets.0.norm2.weight': 'middle_block.0.out_layers.0.weight',\n",
       " 'mid_block.resnets.0.norm2.bias': 'middle_block.0.out_layers.0.bias',\n",
       " 'mid_block.resnets.0.conv2.weight': 'middle_block.0.out_layers.3.weight',\n",
       " 'mid_block.resnets.0.conv2.bias': 'middle_block.0.out_layers.3.bias',\n",
       " 'mid_block.resnets.1.norm1.weight': 'middle_block.2.in_layers.0.weight',\n",
       " 'mid_block.resnets.1.norm1.bias': 'middle_block.2.in_layers.0.bias',\n",
       " 'mid_block.resnets.1.conv1.weight': 'middle_block.2.in_layers.2.weight',\n",
       " 'mid_block.resnets.1.conv1.bias': 'middle_block.2.in_layers.2.bias',\n",
       " 'mid_block.resnets.1.time_emb_proj.weight': 'middle_block.2.emb_layers.1.weight',\n",
       " 'mid_block.resnets.1.time_emb_proj.bias': 'middle_block.2.emb_layers.1.bias',\n",
       " 'mid_block.resnets.1.norm2.weight': 'middle_block.2.out_layers.0.weight',\n",
       " 'mid_block.resnets.1.norm2.bias': 'middle_block.2.out_layers.0.bias',\n",
       " 'mid_block.resnets.1.conv2.weight': 'middle_block.2.out_layers.3.weight',\n",
       " 'mid_block.resnets.1.conv2.bias': 'middle_block.2.out_layers.3.bias'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0252bed-d91b-42a6-a341-26dd74dff29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('sd21_state_dict_mapping.pkl', 'wb') as f:\n",
    "    pickle.dump(state_dict_mapping, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a4584-ea32-4615-8659-f8a8a9a4cf00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
