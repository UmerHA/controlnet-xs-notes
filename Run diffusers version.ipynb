{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0caaa193-85fa-4fdd-9c2c-efffbb0d24d8",
   "metadata": {},
   "source": [
    "Use this notebook to run 1 denoiser step and get updated intermediate steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b3ee84d-4eed-4374-b78b-c8e9dc4e223d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # needed to make torch deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9ac7b3d-0670-48ba-83b5-b0fc2c96c66d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.testing import assert_close\n",
    "from torch import allclose, nn, tensor\n",
    "torch.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccc434cf-df05-443c-875b-cf14fecf56be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
    "device_dtype = torch.float16 if device == 'cuda' else torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ae8cee-8c49-4616-a057-cb04c2379f9d",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eadcacd0-caa8-40b4-8382-484a77d64e85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "from diffusers.models.controlnetxs import ControlNetXSModel\n",
    "from diffusers.pipelines.controlnet_xs.pipeline_controlnet_xs_sd_xl import StableDiffusionXLControlNetXSPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55e16edb-e1a7-4c84-9e85-eafb99f3e6dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdxl_pipe = StableDiffusionXLPipeline.from_single_file('weights/sd_xl_base_1.0_0.9vae.safetensors').to(device)\n",
    "cnxs = ControlNetXSModel.from_pretrained('weights/cnxs').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb9a1b2d-f48d-4b14-bf81-81ff6df0bded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert cnxs.config.control_attention_head_dim==64\n",
    "assert cnxs.control_model.down_blocks[1].attentions[0].transformer_blocks[0].attn1.heads==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a55c488d-6a16-4fff-8ab8-c0e3e07d30c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnxs.base_model = sdxl_pipe.unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71a2cab-f0b6-4865-b1a2-9b187c288671",
   "metadata": {},
   "source": [
    "The example script of Heidelberg manually sets scale_list to 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb82c0b4-0266-421b-b9fd-f03a8e5d33ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnxs.scale_list = cnxs.scale_list * 0. + 0.95\n",
    "assert cnxs.scale_list[0] == .95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c4cfb-2ad6-4aea-a424-bdf3ed1810a2",
   "metadata": {},
   "source": [
    "Heidelberg uses `timestep_spacing = 'linspace'` in their scheduler, so let's do that as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bba85e97-5306-49a4-87e3-4f6e8add9de7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmas after (linear) interpolation: [14.61464691 12.93677721 11.49164976 10.24291444  9.16035419] ...\n"
     ]
    }
   ],
   "source": [
    "scheduler_cgf = dict(sdxl_pipe.scheduler.config)\n",
    "scheduler_cgf['timestep_spacing'] = 'linspace'\n",
    "sdxl_pipe.scheduler = EulerDiscreteScheduler.from_config(scheduler_cgf)\n",
    "\n",
    "# test it worked\n",
    "sdxl_pipe.scheduler.set_timesteps(50)\n",
    "assert sdxl_pipe.scheduler.timesteps[0]==999\n",
    "\n",
    "# reset\n",
    "sdxl_pipe.scheduler = EulerDiscreteScheduler.from_config(scheduler_cgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc68274d-afea-47b5-98ad-24b58419e6c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnxs_pipe = StableDiffusionXLControlNetXSPipeline(\n",
    "    vae=sdxl_pipe.vae,\n",
    "    text_encoder=sdxl_pipe.text_encoder,\n",
    "    text_encoder_2=sdxl_pipe.text_encoder_2,\n",
    "    tokenizer=sdxl_pipe.tokenizer,\n",
    "    tokenizer_2=sdxl_pipe.tokenizer_2,\n",
    "    unet=sdxl_pipe.unet,\n",
    "    controlnet=cnxs,\n",
    "    scheduler=sdxl_pipe.scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1292f02d-22a4-433a-ac78-48d954d296c3",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35062f5c-f174-4ab3-a107-298ad02b66c8",
   "metadata": {},
   "source": [
    "## Run 1 step locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00b7698e-b254-4e98-bb23-a7c3def06d6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from diffusers.utils import load_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CannyDetector:\n",
    "    def __call__(self, img, low_threshold, high_threshold):\n",
    "        return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def get_canny_edges(image, threshold=(100, 250)):\n",
    "    image = np.array(image).astype(np.uint8)\n",
    "    edges = CannyDetector()(image, *threshold)  # original sized greyscale edges\n",
    "    edges = edges / 255.\n",
    "    return edges\n",
    "\n",
    "def seed_everything(seed):\n",
    "    # paper used deprecated `seed_everything` from pytorch lightning\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "RANDOM_SEED_IN_PAPER = 1999158951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "715b742a-679a-4e33-a564-f98f1eb22420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "latents_sdxl_cloud = torch.load('latents_cloud_no_control.pth', map_location=torch.device(device))\n",
    "rand_from_cloud = latents_sdxl_cloud[0] / 14.6146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c91cb8d-0097-43f2-bec0-217d21f4a814",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'cinematic, shoe in the streets, made from meat, photorealistic shoe, highly detailed'\n",
    "neg_prompt = 'lowres, bad anatomy, worst quality, low quality'\n",
    "\n",
    "image = load_image('input_images/shoe.png')\n",
    "edges = get_canny_edges(image)\n",
    "\n",
    "edges_tensor = torch.tensor(edges)\n",
    "three_edges = torch.stack((edges_tensor,edges_tensor,edges_tensor))\n",
    "three_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c5274b-c128-4928-9e8a-62e640568c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers.umer_debug_logger import udl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49cd31d9-d1d6-4913-8226-c62ae564228b",
   "metadata": {},
   "outputs": [],
   "source": [
    "udl.set_dir('logs/local_cuda', clear=True)\n",
    "udl.set_condition('SUBBLOCK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c78e2a7e-5ca2-4d6e-96ce-eed37b2ffe75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already set to control mode == True\n"
     ]
    }
   ],
   "source": [
    "cnxs.toggle_control(to=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a530b16-9cff-448c-907a-865eb5b635c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from util_plot import save_latents\n",
    "\n",
    "lats = []\n",
    "save_lats = partial(save_latents, lats=lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35dc4f64-aba9-4a1e-8b82-35b7d0d82cea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmas after (linear) interpolation: [14.61464691 12.93677721 11.49164976 10.24291444  9.16035419] ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af2661a1a5a446c8af4f85cae90e479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control_scale: tensor([0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500, 0.9500], device='cuda:0')\n",
      "------ enc ------\n",
      ">> Applying base block\t>> Applying ctrl block\t\n",
      ">> Applying base block\t>> Applying ctrl block\t\n",
      ">> Applying base block\t>> Applying ctrl block\t\n",
      ">> Applying base block\t>> Applying ctrl block\t\n",
      ">> Applying base block\t>> Applying ctrl block\t\n",
      ">> Applying base block\t>> Applying ctrl block\t\n",
      ">> Applying base block\t>> Applying ctrl block\t\n",
      ">> Applying base block\t>> Applying ctrl block\t\n",
      "------ mid ------\n",
      ">> Applying base block\t\n",
      ">> Applying base block\t\n",
      ">> Applying ctrl block\t\n",
      ">> Applying ctrl block\t\n",
      "------ dec ------\n",
      ">> Applying base block\t\n",
      ">> Applying base block\t\n",
      ">> Applying base block\t\n",
      ">> Applying base block\t\n",
      ">> Applying base block\t\n",
      ">> Applying base block\t\n",
      ">> Applying base block\t\n",
      ">> Applying base block\t\n",
      ">> Applying base block\t\n",
      "\n",
      "The subblocks are cought. Let us gaze into their soul, their very essence.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "The subblocks are cought. Let us gaze into their soul, their very essence.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m The subblocks are cought. Let us gaze into their soul, their very essence.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "seed_everything(RANDOM_SEED_IN_PAPER)\n",
    "result = cnxs_pipe(prompt, negative_prompt=neg_prompt,image=three_edges, latents=rand_from_cloud, callback=save_lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7ab280-09a9-47cf-9ea1-69881ec6e1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a8099a2-9e6f-4a15-adea-56063dc1feb4",
   "metadata": {},
   "source": [
    "Convert pipe and latents to cpu, as we otherwise get an cuda oom error when decoding the image after each denoising step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7cac2b-b927-4605-97ac-95145fd2efe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_cpu(t): return t.cpu() if hasattr(t,'cpu') else t\n",
    "def only_lat(l): return l[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51c90a-85dc-4131-bd7a-e6dd47221294",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lats = [to_cpu(only_lat(l)) for l in lats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f36f8-4dd8-4435-bd8a-96455dc6aa6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe=cnxs_pipe.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a1e2f-d278-49cd-b57c-4b3397fe6140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lats[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849edea7-6d2e-4625-8cd2-fde6d94cee45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c2ec0-5f26-48bf-bca4-101cfa81f6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import einops\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def lat2img(lat, pipe, resize_to=None, output_type='pil'):\n",
    "    with torch.no_grad():\n",
    "        if lat.dim()==3: lat = lat.unsqueeze(0) # add batch dimension        \n",
    "        ims = pipe.vae.decode(lat / pipe.vae.config.scaling_factor, return_dict=False)[0]\n",
    "        ims = pipe.image_processor.postprocess(ims, output_type=output_type)\n",
    "        \n",
    "        if resize_to is not None:\n",
    "            if output_type=='pil': ims = [im.resize(resize_to) for im in ims]\n",
    "            else: print(f'Not resizing as output_type = {output_type} requested')\n",
    "    return ims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62010060-42e2-45a7-ac51-8b62e9705d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps, ImageDraw\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import partial\n",
    "\n",
    "def plot_latents_to_pil_grid(lats, pipe, every=1, cols=10, im_size=200, pbar=True, border=2, return_ims=True, output_type='pil'):\n",
    "    if not isinstance(im_size, (list, tuple)): im_size = (im_size, im_size)\n",
    "    \n",
    "    lats = [lat for i, lat in enumerate(lats) if i % every == 0 or i == len(lats)-1]\n",
    "    if pbar: lats = tqdm(lats)\n",
    "    \n",
    "    # decoce latents -> images\n",
    "    ims = [lat2img(lat, pipe, resize_to=im_size, output_type=output_type)[0] for lat in lats] # removed pipe argument\n",
    "    \n",
    "    # add border\n",
    "    ims_bordered = [ImageOps.expand(im, border=2, fill='black') for im in ims]\n",
    "    im_size = (im_size[0]+border, im_size[1]+border)\n",
    "\n",
    "    rows = len(ims) // cols\n",
    "    if rows * cols < len(ims): rows += 1\n",
    "\n",
    "    # draw background\n",
    "    grid_image = Image.new('RGB', (cols * im_size[0], rows * im_size[1]), color='grey')\n",
    "    draw = ImageDraw.Draw(grid_image)\n",
    "    for xy in range(0,2*max(cols * im_size[0], rows * im_size[1])+1,100):\n",
    "        draw.line([(xy, 0), (0, xy)], fill=\"white\", width=1)\n",
    "    \n",
    "    # draw images\n",
    "    for i, img in enumerate(ims_bordered):\n",
    "        x_offset = (i % cols) * im_size[0]\n",
    "        y_offset = (i // cols) * im_size[1]\n",
    "        grid_image.paste(img, (x_offset, y_offset))\n",
    "\n",
    "    if return_ims: return grid_image, ims\n",
    "    else: return grid_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da76bc07-5692-46fb-a9bc-c717dcc7db4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3adc4a1-2f0f-4c4f-9195-a7a643e779bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, ims = plot_latents_to_pil_grid(lats, pipe=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b67b91-48df-494b-bc7b-1b41ccd16966",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67e9df6-52d7-4ba3-9386-ce85b5b4df96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aad0f0-0abe-4426-b724-a56466cef7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7934cfa-2729-404e-9f27-5939ec6847fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43d1606-3ee4-4f2b-a716-6ded382ea35f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
