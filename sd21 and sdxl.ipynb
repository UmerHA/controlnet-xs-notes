{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2c1ecd-fc44-41f6-afc4-fb27140ad816",
   "metadata": {},
   "source": [
    "The purpose of this notebook is play around with the architecture of the diffusion models used by the ControlNet-XS authors: StableDiffusion 2.1 and StableDiffusionXL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ae239-bce6-4ab5-ab04-9298ce979d85",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0358ce56-4585-4649-99ab-ac52dce22c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import public_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96189e10-aaa5-4005-8321-304aeebd1243",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a743232-3458-4585-9e57-e2e4b2ff885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38da3eca-8f83-4d24-8199-d3ff8d69ab40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b433e786de204beb8a6a1c33593a6b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe21 = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fce2c42-fbd2-40b1-8161-08b7f2315bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16887e03-6dfe-4872-bb14-c1c5e2db1342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0cda8c4059647c8b3b32304d2f4b121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipexl = StableDiffusionXLPipeline.from_pretrained(\"stabilityai/stable-diffusion-xl-base-1.0\", torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06241546-1f8b-44a6-8cef-c0693643f213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d62e556b893423f803452cdd759ac7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    }
   ],
   "source": [
    "pipe15 = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae876739-6fcc-4274-943d-5cc2d97d4479",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcb9a0ee-a3bd-4668-bfc6-0f266885f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet21, unetxl, unet15 = pipe21.unet, pipexl.unet, pipe15.unet\n",
    "vae21, vaexl, vae15 = pipe21.vae, pipexl.vae, pipe15.vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52fca00c-4844-49f4-98b6-903546118315",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1,3,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6a5359a-3035-4452-b50e-8986d7591480",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents21 = vae21(x).sample\n",
    "latentsxl = vaexl(x).sample\n",
    "latents15 = vae15(x).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ac44cd-0223-4011-bce5-cd76502ac89e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 512, 512]),\n",
       " torch.Size([1, 3, 512, 512]),\n",
       " torch.Size([1, 3, 512, 512]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latents21.shape, latentsxl.shape, latents15.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbff658-24cc-40d9-8fce-f23055f8c6a6",
   "metadata": {},
   "source": [
    "**Q:** This is wrong. A vae tranforms an image `3x512x512` to a latent `4x64x64`. What am I missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a99e1a68-e151-44dd-9fba-33d99ddf2c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call_super_init',\n",
       " 'disable_xformers_memory_efficient_attention',\n",
       " 'enable_xformers_memory_efficient_attention',\n",
       " 'encode',\n",
       " 'encoder',\n",
       " 'forward',\n",
       " 'ignore_for_config',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'set_use_memory_efficient_attention_xformers',\n",
       " 'tiled_encode']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_attrs(vae15, contains=['enc', 'cal', 'for'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc82abc9-74d2-46d9-bd79-93758f17a07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mvae15\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_hf_hook\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pre_forward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Documents/GitHub/diffusers/diffusers/src/diffusers/utils/accelerate_utils.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vae15.encode??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "552f1d77-f9d3-4582-b394-505471fb6430",
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = vae15.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2515de62-6440-4198-baeb-8c950b3e226c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 512])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla.sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc33c2-a041-47d2-8180-840953245927",
   "metadata": {},
   "source": [
    "What the fuck?!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de72b02-d093-4d00-88d8-61b9f1e66164",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3594ceb2-5c55-4a93-9a8a-ad63c00d86bd",
   "metadata": {},
   "source": [
    "Let's go the opposite way & decode the latents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f676ce5-df46-41f8-b063-99773dc08e96",
   "metadata": {},
   "source": [
    "This line\n",
    "\n",
    "    im_rec_21 =   vae21.decode(latents21).sample  # reconstructed image\n",
    "\n",
    "produces an error\n",
    "    \n",
    "    --> 459 return F.conv2d(input, weight, bias, self.stride,\n",
    "        460                 self.padding, self.dilation, self.groups)\n",
    "    \n",
    "    RuntimeError: Given groups=1, weight of size [4, 4, 1, 1], expected input[1, 3, 512, 512] to have 4 channels, but got 3 channels instead\n",
    "\n",
    "This means `vae21.decode` can't handle input of shape `bla, 3, 512, 512`. This is as expected, good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6f4e31-459e-4fd7-9c7e-16469158b012",
   "metadata": {},
   "source": [
    "Let's now decode an input of shape `blub, 4, 64, 64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84484836-3109-4732-bac8-9dd08c5a0f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_im = torch.rand(1,3,512,512)\n",
    "rand_lat = torch.rand(1,4,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97be88f3-a743-488f-b587-308b56314602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae21.decode(rand_lat).sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ae8d34-80cc-4bae-990f-20e5690c46cd",
   "metadata": {},
   "source": [
    "Works, ie turns a shape `(1,4,64,64)` into `(1,3,512,512)`, good. But why does it's opposite function then not turn `(1,3,512,512)` into `(1,4,64,64)`, but intead remains at `(1,3,512,512)`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edadd37d-2296-470c-8262-92dc6ff8a4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 64, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae21.encode(rand_im).latent_dist.sample().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928f4f25-3b02-45da-ab35-27da1f45d719",
   "metadata": {},
   "source": [
    "It doesn't! Aha!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfc394f6-f952-4634-93f3-df0aba854a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 512])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae21(x).sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08411e6-ce9e-4be9-adbf-726f15b2a9ee",
   "metadata": {},
   "source": [
    "Aha again! `__call__` is **not the same** as `encode`. What I want is `encode`, while `__call__` seems to both `encode` and then `decode`.\n",
    "This makes sense actually, as the vae's job is to reproduce a given image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b40a5d9-8994-4557-9aeb-9e1047c9ffed",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ce59560-0324-4bcf-b8ec-8dce741c7281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae21 torch.Size([1, 4, 64, 64])\n",
      "vaexl torch.Size([1, 4, 64, 64])\n",
      "vae15 torch.Size([1, 4, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "for n, vae in zip(('vae21','vaexl','vae15'), (vae21,vaexl,vae15)):\n",
    "    print(n, vae.encode(rand_im).latent_dist.sample().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7c55b-0eb5-4e88-97f2-2a9a9f9065a0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00127a8b-77b7-44ae-b643-40d78566286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import simple_describe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4924216-5818-45e8-949d-7b2014d7393c",
   "metadata": {},
   "source": [
    "### Description of SDXL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59888e8d-2031-4623-831d-9f3668231fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Conv2d (4, 320)\n"
     ]
    }
   ],
   "source": [
    "simple_describe(unetxl.conv_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f95e2ad4-b4ba-4f90-8d3c-6634356a4c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ModuleList \n",
      "\t DownBlock2D \n",
      "\t\t ResnetBlock2D (320, 320)\n",
      "\t\t ResnetBlock2D (320, 320)\n",
      "\t\t Downsample2D (320, 320)\n",
      "\t CrossAttnDownBlock2D \n",
      "\t\t ResnetBlock2D (320, 640)\n",
      "\t\t Transformer2DModel (640, 640)\n",
      "\t\t ResnetBlock2D (640, 640)\n",
      "\t\t Transformer2DModel (640, 640)\n",
      "\t\t Downsample2D (640, 640)\n",
      "\t CrossAttnDownBlock2D \n",
      "\t\t ResnetBlock2D (640, 1280)\n",
      "\t\t Transformer2DModel (1280, 1280)\n",
      "\t\t ResnetBlock2D (1280, 1280)\n",
      "\t\t Transformer2DModel (1280, 1280)\n"
     ]
    }
   ],
   "source": [
    "simple_describe(unetxl.down_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1de3ca-a2fe-4953-9bda-b95c7d8df8f7",
   "metadata": {},
   "source": [
    "### Description of SD21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40b215e3-22ab-4ce1-aea1-3da9d6d0fc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Conv2d (4, 320)\n"
     ]
    }
   ],
   "source": [
    "simple_describe(unet21.conv_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bf97f82-70b3-4ac7-b616-7c319c0b5ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ModuleList \n",
      "\t CrossAttnDownBlock2D \n",
      "\t\t ResnetBlock2D (320, 320)\n",
      "\t\t Transformer2DModel (320, 320)\n",
      "\t\t ResnetBlock2D (320, 320)\n",
      "\t\t Transformer2DModel (320, 320)\n",
      "\t\t Downsample2D (320, 320)\n",
      "\t CrossAttnDownBlock2D \n",
      "\t\t ResnetBlock2D (320, 640)\n",
      "\t\t Transformer2DModel (640, 640)\n",
      "\t\t ResnetBlock2D (640, 640)\n",
      "\t\t Transformer2DModel (640, 640)\n",
      "\t\t Downsample2D (640, 640)\n",
      "\t CrossAttnDownBlock2D \n",
      "\t\t ResnetBlock2D (640, 1280)\n",
      "\t\t Transformer2DModel (1280, 1280)\n",
      "\t\t ResnetBlock2D (1280, 1280)\n",
      "\t\t Transformer2DModel (1280, 1280)\n",
      "\t\t Downsample2D (1280, 1280)\n",
      "\t DownBlock2D \n",
      "\t\t ResnetBlock2D (1280, 1280)\n",
      "\t\t ResnetBlock2D (1280, 1280)\n"
     ]
    }
   ],
   "source": [
    "simple_describe(unet21.down_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34d6bc0-4a2f-4413-92c1-35b15ea860ac",
   "metadata": {},
   "source": [
    "### Description of SD15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66630991-4a69-4392-8c77-9477a5374411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Conv2d (4, 320)\n"
     ]
    }
   ],
   "source": [
    "simple_describe(unet15.conv_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34077f5f-6d3a-4969-a087-0e5bc0dab3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ModuleList \n",
      "\t CrossAttnDownBlock2D \n",
      "\t\t ResnetBlock2D (320, 320)\n",
      "\t\t Transformer2DModel (320, 320)\n",
      "\t\t ResnetBlock2D (320, 320)\n",
      "\t\t Transformer2DModel (320, 320)\n",
      "\t\t Downsample2D (320, 320)\n",
      "\t CrossAttnDownBlock2D \n",
      "\t\t ResnetBlock2D (320, 640)\n",
      "\t\t Transformer2DModel (640, 640)\n",
      "\t\t ResnetBlock2D (640, 640)\n",
      "\t\t Transformer2DModel (640, 640)\n",
      "\t\t Downsample2D (640, 640)\n",
      "\t CrossAttnDownBlock2D \n",
      "\t\t ResnetBlock2D (640, 1280)\n",
      "\t\t Transformer2DModel (1280, 1280)\n",
      "\t\t ResnetBlock2D (1280, 1280)\n",
      "\t\t Transformer2DModel (1280, 1280)\n",
      "\t\t Downsample2D (1280, 1280)\n",
      "\t DownBlock2D \n",
      "\t\t ResnetBlock2D (1280, 1280)\n",
      "\t\t ResnetBlock2D (1280, 1280)\n"
     ]
    }
   ],
   "source": [
    "simple_describe(unet15.down_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfda08b-9b63-4cbe-808c-926628358fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404dafcd-c5d0-490e-b8c8-78ecf7d00ade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
