{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30794abe-5ec0-4ecd-90c5-5ef222fc2e48",
   "metadata": {},
   "source": [
    "This notebooks tests new code in diffusers: `ControlledUNet2DConditionModel.__init__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a82155-2d6a-4bd9-ac8a-d30f9b17641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb778d99-86e1-417b-95b7-da9433821a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.configuration_utils import ConfigMixin\n",
    "from diffusers.loaders import UNet2DConditionLoadersMixin\n",
    "from diffusers.utils import BaseOutput, logging\n",
    "\n",
    "from diffusers.models.embeddings import (\n",
    "    GaussianFourierProjection,\n",
    "    TimestepEmbedding,\n",
    "    Timesteps,\n",
    "    get_timestep_embedding\n",
    ")\n",
    "from diffusers.models.modeling_utils import ModelMixin\n",
    "from diffusers.models.unet_2d_blocks import (\n",
    "    CrossAttnDownBlock2D,\n",
    "    DownBlock2D,\n",
    "    CrossAttnUpBlock2D,\n",
    "    UpBlock2D,\n",
    ")\n",
    "from diffusers.models.unet_2d_condition import UNet2DConditionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c12658e-e040-4dbe-bbad-b7ca02f04269",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class UNet2DConditionOutput(BaseOutput):\n",
    "    sample: torch.FloatTensor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7425257-6c0e-4de7-ae35-5b30735ce7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_module(module):\n",
    "    for p in module.parameters():\n",
    "        nn.init.zeros_(p)\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c258cba-7d56-4b73-b280-8a98289e3a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.models import UNet2DConditionModel, ControlNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de30f6fd-30e3-40e9-bf33-c490e7b9e4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m.\u001b[m\u001b[m                               sd21_encD_depth_14m.ckpt\n",
      "\u001b[34m..\u001b[m\u001b[m                              sdxl_encD_canny_48m.safetensors\n",
      "sd21_encD_canny_14m.ckpt        sdxl_encD_depth_48m.safetensors\n"
     ]
    }
   ],
   "source": [
    "!ls -a \"../../../../.hf-cache/CVL-Heidelberg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c1af73f-a807-48f9-806e-d3e0db0c1b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../../../../.hf-cache/CVL-Heidelberg/sd21_encD_canny_14m.ckpt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a4de1f1e-4e67-455e-afcf-f59382df148c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ctrl_model_state_dict = {\n",
    "    k.replace('control_model.',''):v \n",
    "    for k,v in checkpoint['state_dict'].items() \n",
    "    if 'control_model.' in k\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8cb30fb-4b29-45c6-85a5-c53f8b57444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_state_dict(sdict, lv=None):\n",
    "    if lv is None: keys = list(sdict.keys())\n",
    "    else: keys = list({'.'.join(k.split('.')[:lv+1]): '' for k in sdict.keys()}). # dict preserves order, set doesn't (therefore :'')\n",
    "    for k in keys: print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "91f441bb-0c80-49bb-9ff1-dc61c1844283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_embed\n",
      "input_blocks\n",
      "middle_block\n"
     ]
    }
   ],
   "source": [
    "print_state_dict(ctrl_model_state_dict, lv=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d8790cf6-dbcd-40e4-bd48-781d9edf8328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_in\n",
      "time_embedding\n",
      "controlnet_cond_embedding\n",
      "down_blocks\n",
      "controlnet_down_blocks\n",
      "controlnet_mid_block\n",
      "mid_block\n"
     ]
    }
   ],
   "source": [
    "print_state_dict(cnet.state_dict(), lv=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2404689-b046-442f-976d-13f1dc5f618f",
   "metadata": {},
   "source": [
    "A `ControlNetModel` in diffusers already contains a base and ctrl model. **My assumption that it's just the ctrl model is wrong.**. This means **I have to define a new class for a ControlModel** in the sense of CN-XS, ie a model that exists in addition to the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e19d36c-7917-4fc6-872b-647b9b7f6833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_embed.0\n",
      "time_embed.2\n",
      "input_blocks.0\n",
      "input_blocks.1\n",
      "input_blocks.2\n",
      "input_blocks.3\n",
      "input_blocks.4\n",
      "input_blocks.5\n",
      "input_blocks.6\n",
      "input_blocks.7\n",
      "input_blocks.8\n",
      "input_blocks.9\n",
      "input_blocks.10\n",
      "input_blocks.11\n",
      "middle_block.0\n",
      "middle_block.1\n",
      "middle_block.2\n"
     ]
    }
   ],
   "source": [
    "print_state_dict(ctrl_model_state_dict, lv=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d618836-f488-403b-a95c-b8446cb476b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_in.weight\n",
      "conv_in.bias\n",
      "time_embedding.linear_1\n",
      "time_embedding.linear_2\n",
      "controlnet_cond_embedding.conv_in\n",
      "controlnet_cond_embedding.blocks\n",
      "controlnet_cond_embedding.conv_out\n",
      "down_blocks.0\n",
      "down_blocks.1\n",
      "down_blocks.2\n",
      "down_blocks.3\n",
      "controlnet_down_blocks.0\n",
      "controlnet_down_blocks.1\n",
      "controlnet_down_blocks.2\n",
      "controlnet_down_blocks.3\n",
      "controlnet_down_blocks.4\n",
      "controlnet_down_blocks.5\n",
      "controlnet_down_blocks.6\n",
      "controlnet_down_blocks.7\n",
      "controlnet_down_blocks.8\n",
      "controlnet_down_blocks.9\n",
      "controlnet_down_blocks.10\n",
      "controlnet_down_blocks.11\n",
      "controlnet_mid_block.weight\n",
      "controlnet_mid_block.bias\n",
      "mid_block.attentions\n",
      "mid_block.resnets\n"
     ]
    }
   ],
   "source": [
    "print_state_dict(cnet.state_dict(), lv=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32421d1-3e1a-4f77-a143-2c7aaf3ee2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49d96f8e-f538-45b1-a9a8-afd6f5749187",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnet = ControlNetModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2a17e8-21fe-4b8b-a928-5fd10901a403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e985d595-004b-4c14-9aee-daf76b9a9fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnet.load_state_dict(ctrl_model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e79abf-7d1b-446f-8ce9-593509563167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5cc8b2-1326-4ace-bb08-b0036098cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model.load_state_dict(checkpoint['unet_state_dict'])  # Replace 'unet_state_dict' with the actual key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea0876-8ff5-4190-923f-9ea7561b6fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4d3ac53-2e0a-415e-8acf-a226debb428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ctrl_model  = UNet2DConditionModel.from_pretrained('CVL-Heidelberg/ControlNet-XS', variant='sd21_encD_canny_14m.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1c1c07-4f11-4391-9cce-29aeee00bb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2385560f-0899-4f2c-b5f8-1236cd6bba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControlledUNet2DConditionModel(ModelMixin, ConfigMixin, UNet2DConditionLoadersMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            model_channels,\n",
    "            out_channels,\n",
    "            hint_channels,\n",
    "            num_res_blocks,\n",
    "            attention_resolutions,\n",
    "        ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1 - Save parameters\n",
    "        # TODO make variables\n",
    "        self.control_mode = \"canny\"\n",
    "        self.learn_embedding = False\n",
    "        self.infusion2control = \"cat\"\n",
    "        self.infusion2base = \"add\"\n",
    "        self.in_ch_factor = 1 if \"cat\" == 'add' else 2\n",
    "        self.guiding = \"encoder\"\n",
    "        self.two_stream_mode = \"cross\"\n",
    "        self.control_model_ratio = 1.0\n",
    "        self.out_channels = out_channels\n",
    "        self.dims = 2\n",
    "        self.model_channels = model_channels\n",
    "        self.no_control = False\n",
    "        self.control_scale = 1.0\n",
    "\n",
    "        self.hint_model = None\n",
    "\n",
    "        # 2 - Create base and control model\n",
    "        # TODO 1. create base model, or 2. pass it\n",
    "        self.base_model = base_model = UNet2DConditionModel()\n",
    "        # TODO create control model\n",
    "        self.control_model = ctrl_model = UNet2DConditionModel()\n",
    "\n",
    "\n",
    "        # 3 - Gather Channel Sizes\n",
    "        ch_inout_ctrl = {'enc': [], 'mid': [], 'dec': []}\n",
    "        ch_inout_base = {'enc': [], 'mid': [], 'dec': []}\n",
    "\n",
    "        # 3.1 - input convolution\n",
    "        ch_inout_ctrl['enc'].append((ctrl_model.conv_in.in_channels, ctrl_model.conv_in.out_channels))\n",
    "        ch_inout_base['enc'].append((base_model.conv_in.in_channels, base_model.conv_in.out_channels))\n",
    "\n",
    "        # 3.2 - encoder blocks\n",
    "        for module in ctrl_model.down_blocks:\n",
    "            if isinstance(module, (CrossAttnDownBlock2D, DownBlock2D)):\n",
    "                    for r in module.resnets:\n",
    "                        ch_inout_ctrl['enc'].append((r.in_channels, r.out_channels))\n",
    "                    if module.downsamplers:\n",
    "                        ch_inout_ctrl['enc'].append((module.downsamplers[0].channels, module.downsamplers[0].out_channels))\n",
    "            else:\n",
    "                raise ValueError(f'Encountered unknown module of type {type(module)} while creating ControlNet-XS.')\n",
    "    \n",
    "        for module in base_model.down_blocks:\n",
    "            if isinstance(module, (CrossAttnDownBlock2D, DownBlock2D)):\n",
    "                    for r in module.resnets:\n",
    "                        ch_inout_base['enc'].append((r.in_channels, r.out_channels))\n",
    "                    if module.downsamplers:\n",
    "                        ch_inout_base['enc'].append((module.downsamplers[0].channels, module.downsamplers[0].out_channels))\n",
    "            else:\n",
    "                raise ValueError(f'Encountered unknown module of type {type(module)} while creating ControlNet-XS.')\n",
    "\n",
    "        # 3.3 - middle block\n",
    "        ch_inout_ctrl['mid'].append((ctrl_model.mid_block.resnets[0].in_channels, ctrl_model.mid_block.resnets[0].in_channels))\n",
    "        ch_inout_base['mid'].append((base_model.mid_block.resnets[0].in_channels, base_model.mid_block.resnets[0].in_channels))\n",
    "    \n",
    "        # 3.4 - decoder blocks\n",
    "        for module in base_model.up_blocks:\n",
    "            if isinstance(module, (CrossAttnUpBlock2D, UpBlock2D)):\n",
    "                for r in module.resnets:\n",
    "                    ch_inout_base['dec'].append((r.in_channels, r.out_channels))\n",
    "            else:\n",
    "                raise ValueError(f'Encountered unknown module of type {type(module)} while creating ControlNet-XS.')\n",
    "            \n",
    "        self.ch_inout_ctrl = ch_inout_ctrl\n",
    "        self.ch_inout_base = ch_inout_base\n",
    "\n",
    "        # 4 - Build connections between base and control model\n",
    "        self.enc_zero_convs_out = nn.ModuleList([])\n",
    "        self.enc_zero_convs_in = nn.ModuleList([])\n",
    "\n",
    "        self.middle_block_out = nn.ModuleList([])\n",
    "        self.middle_block_in = nn.ModuleList([])\n",
    "\n",
    "        self.dec_zero_convs_out = nn.ModuleList([])\n",
    "        self.dec_zero_convs_in = nn.ModuleList([])\n",
    "\n",
    "        for ch_io_base in ch_inout_base['enc']:\n",
    "            self.enc_zero_convs_in.append(self.make_zero_conv(\n",
    "                in_channels=ch_io_base[1], out_channels=ch_io_base[1])\n",
    "            )\n",
    "        \n",
    "        self.middle_block_out = self.make_zero_conv(ch_inout_ctrl['mid'][-1][1], ch_inout_base['mid'][-1][1])\n",
    "        \n",
    "        self.dec_zero_convs_out.append(\n",
    "            self.make_zero_conv(ch_inout_ctrl['enc'][-1][1], ch_inout_base['mid'][-1][1])\n",
    "        )\n",
    "        for i in range(1, len(ch_inout_ctrl['enc'])):\n",
    "            self.dec_zero_convs_out.append(\n",
    "                self.make_zero_conv(ch_inout_ctrl['enc'][-(i + 1)][1], ch_inout_base['dec'][i - 1][1])\n",
    "            )\n",
    "    \n",
    "        # 5 - Input hint block TODO: Understand\n",
    "        self.input_hint_block = nn.Sequential(\n",
    "            nn.Conv2d(hint_channels, 16, 3, padding=1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(16, 32, 3, padding=1, stride=2),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(32, 96, 3, padding=1, stride=2),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(96, 96, 3, padding=1),\n",
    "            nn.SiLU(),\n",
    "            nn.Conv2d(96, 256, 3, padding=1, stride=2),\n",
    "            nn.SiLU(),\n",
    "            zero_module(nn.Conv2d(256, int(model_channels * self.control_model_ratio), 3, padding=1))\n",
    "        )\n",
    "    \n",
    "        scale_list = [1.] * len(self.enc_zero_convs_out) + [1.] + [1.] * len(self.dec_zero_convs_out)\n",
    "        self.register_buffer('scale_list', torch.tensor(scale_list))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        sample: torch.FloatTensor,\n",
    "        timestep: Union[torch.Tensor, float, int],\n",
    "        encoder_hidden_states: torch.Tensor,\n",
    "        class_labels: Optional[torch.Tensor] = None,\n",
    "        timestep_cond: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        cross_attention_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        added_cond_kwargs: Optional[Dict[str, torch.Tensor]] = None,\n",
    "        down_block_additional_residuals: Optional[Tuple[torch.Tensor]] = None,\n",
    "        mid_block_additional_residual: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        return_dict: bool = True,\n",
    "    ) -> Union[UNet2DConditionOutput, Tuple]:\n",
    "\n",
    "        # pass control_input into controlnet\n",
    "        \n",
    "        # # Encoder\n",
    "        # for zip(control_encoding, base_encoding):\n",
    "        # ...\n",
    "\n",
    "        # # Bottleneck\n",
    "        # control_encoding, base_encoding\n",
    "        # ...\n",
    "\n",
    "        # # Decoder\n",
    "        # for zip(base_decoding):\n",
    "        # ...\n",
    "\n",
    "        return UNet2DConditionOutput(sample=sample)\n",
    "\n",
    "    def make_zero_conv(self, in_channels, out_channels=None):\n",
    "        # keep running track # todo: better comment\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels or in_channels\n",
    "        return zero_module(nn.Conv2d(in_channels, out_channels, 1, padding=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e34ebbac-2858-4743-bd02-6143b5e8abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'in_channels': 4,\n",
    "    'out_channels': 4,\n",
    "    'hint_channels': 3,\n",
    "    'model_channels': 320,\n",
    "    'attention_resolutions': [4, 2],\n",
    "    'num_res_blocks': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c86393b-c6d4-435c-b111-750b8ded408f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ControlledUNet2DConditionModel(\n",
       "  (base_model): UNet2DConditionModel(\n",
       "    (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (time_proj): Timesteps()\n",
       "    (time_embedding): TimestepEmbedding(\n",
       "      (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (act): SiLU()\n",
       "      (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (down_blocks): ModuleList(\n",
       "      (0): CrossAttnDownBlock2D(\n",
       "        (attentions): ModuleList(\n",
       "          (0-1): 2 x Transformer2DModel(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn1): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff): FeedForward(\n",
       "                  (net): ModuleList(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (resnets): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): CrossAttnDownBlock2D(\n",
       "        (attentions): ModuleList(\n",
       "          (0-1): 2 x Transformer2DModel(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn1): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff): FeedForward(\n",
       "                  (net): ModuleList(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CrossAttnDownBlock2D(\n",
       "        (attentions): ModuleList(\n",
       "          (0-1): 2 x Transformer2DModel(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn1): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff): FeedForward(\n",
       "                  (net): ModuleList(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DownBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up_blocks): ModuleList(\n",
       "      (0): UpBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-2): 3 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): Upsample2D(\n",
       "            (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): CrossAttnUpBlock2D(\n",
       "        (attentions): ModuleList(\n",
       "          (0-2): 3 x Transformer2DModel(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn1): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff): FeedForward(\n",
       "                  (net): ModuleList(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (resnets): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): Upsample2D(\n",
       "            (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CrossAttnUpBlock2D(\n",
       "        (attentions): ModuleList(\n",
       "          (0-2): 3 x Transformer2DModel(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn1): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff): FeedForward(\n",
       "                  (net): ModuleList(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): Upsample2D(\n",
       "            (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): CrossAttnUpBlock2D(\n",
       "        (attentions): ModuleList(\n",
       "          (0-2): 3 x Transformer2DModel(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn1): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff): FeedForward(\n",
       "                  (net): ModuleList(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid_block): UNetMidBlock2DCrossAttn(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "    (conv_act): SiLU()\n",
       "    (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (control_model): UNet2DConditionModel(\n",
       "    (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (time_proj): Timesteps()\n",
       "    (time_embedding): TimestepEmbedding(\n",
       "      (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
       "      (act): SiLU()\n",
       "      (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    )\n",
       "    (down_blocks): ModuleList(\n",
       "      (0): CrossAttnDownBlock2D(\n",
       "        (attentions): ModuleList(\n",
       "          (0-1): 2 x Transformer2DModel(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn1): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff): FeedForward(\n",
       "                  (net): ModuleList(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (resnets): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): CrossAttnDownBlock2D(\n",
       "        (attentions): ModuleList(\n",
       "          (0-1): 2 x Transformer2DModel(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn1): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff): FeedForward(\n",
       "                  (net): ModuleList(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CrossAttnDownBlock2D(\n",
       "        (attentions): ModuleList(\n",
       "          (0-1): 2 x Transformer2DModel(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn1): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff): FeedForward(\n",
       "                  (net): ModuleList(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "        (downsamplers): ModuleList(\n",
       "          (0): Downsample2D(\n",
       "            (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DownBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (up_blocks): ModuleList(\n",
       "      (0): UpBlock2D(\n",
       "        (resnets): ModuleList(\n",
       "          (0-2): 3 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): Upsample2D(\n",
       "            (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): CrossAttnUpBlock2D(\n",
       "        (attentions): ModuleList(\n",
       "          (0-2): 3 x Transformer2DModel(\n",
       "            (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "            (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn1): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff): FeedForward(\n",
       "                  (net): ModuleList(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (resnets): ModuleList(\n",
       "          (0-1): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "            (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): Upsample2D(\n",
       "            (conv): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): CrossAttnUpBlock2D(\n",
       "        (attentions): ModuleList(\n",
       "          (0-2): 3 x Transformer2DModel(\n",
       "            (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
       "            (proj_in): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn1): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=640, out_features=640, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=640, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=640, out_features=640, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff): FeedForward(\n",
       "                  (net): ModuleList(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): LoRACompatibleLinear(in_features=640, out_features=5120, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): LoRACompatibleLinear(in_features=2560, out_features=640, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (proj_out): LoRACompatibleConv(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=640, bias=True)\n",
       "            (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (upsamplers): ModuleList(\n",
       "          (0): Upsample2D(\n",
       "            (conv): LoRACompatibleConv(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): CrossAttnUpBlock2D(\n",
       "        (attentions): ModuleList(\n",
       "          (0-2): 3 x Transformer2DModel(\n",
       "            (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
       "            (proj_in): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (transformer_blocks): ModuleList(\n",
       "              (0): BasicTransformerBlock(\n",
       "                (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn1): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (attn2): Attention(\n",
       "                  (to_q): LoRACompatibleLinear(in_features=320, out_features=320, bias=False)\n",
       "                  (to_k): LoRACompatibleLinear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_v): LoRACompatibleLinear(in_features=1280, out_features=320, bias=False)\n",
       "                  (to_out): ModuleList(\n",
       "                    (0): LoRACompatibleLinear(in_features=320, out_features=320, bias=True)\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
       "                (ff): FeedForward(\n",
       "                  (net): ModuleList(\n",
       "                    (0): GEGLU(\n",
       "                      (proj): LoRACompatibleLinear(in_features=320, out_features=2560, bias=True)\n",
       "                    )\n",
       "                    (1): Dropout(p=0.0, inplace=False)\n",
       "                    (2): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (proj_out): LoRACompatibleConv(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (resnets): ModuleList(\n",
       "          (0): ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x ResnetBlock2D(\n",
       "            (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
       "            (conv1): LoRACompatibleConv(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=320, bias=True)\n",
       "            (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (conv2): LoRACompatibleConv(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (nonlinearity): SiLU()\n",
       "            (conv_shortcut): LoRACompatibleConv(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mid_block): UNetMidBlock2DCrossAttn(\n",
       "      (attentions): ModuleList(\n",
       "        (0): Transformer2DModel(\n",
       "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
       "          (proj_in): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (transformer_blocks): ModuleList(\n",
       "            (0): BasicTransformerBlock(\n",
       "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn1): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (attn2): Attention(\n",
       "                (to_q): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_k): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_v): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=False)\n",
       "                (to_out): ModuleList(\n",
       "                  (0): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "              (ff): FeedForward(\n",
       "                (net): ModuleList(\n",
       "                  (0): GEGLU(\n",
       "                    (proj): LoRACompatibleLinear(in_features=1280, out_features=10240, bias=True)\n",
       "                  )\n",
       "                  (1): Dropout(p=0.0, inplace=False)\n",
       "                  (2): LoRACompatibleLinear(in_features=5120, out_features=1280, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (proj_out): LoRACompatibleConv(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (conv1): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=1280, bias=True)\n",
       "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): LoRACompatibleConv(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
       "    (conv_act): SiLU()\n",
       "    (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       "  (enc_zero_convs_out): ModuleList()\n",
       "  (enc_zero_convs_in): ModuleList(\n",
       "    (0-3): 4 x Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (4-6): 3 x Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7-11): 5 x Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (middle_block_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (middle_block_in): ModuleList()\n",
       "  (dec_zero_convs_out): ModuleList(\n",
       "    (0-4): 5 x Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (5-6): 2 x Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (8-9): 2 x Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (10-11): 2 x Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (dec_zero_convs_in): ModuleList()\n",
       "  (input_hint_block): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): SiLU()\n",
       "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): SiLU()\n",
       "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): SiLU()\n",
       "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): SiLU()\n",
       "    (8): Conv2d(32, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (9): SiLU()\n",
       "    (10): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): SiLU()\n",
       "    (12): Conv2d(96, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (13): SiLU()\n",
       "    (14): Conv2d(256, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ControlledUNet2DConditionModel(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14fcb8-2d2f-4d9c-a1cb-c03d0c90c1dd",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70be4365-c220-4fe6-9bff-ef7240adf5b1",
   "metadata": {},
   "source": [
    "Okay, let's run the code manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1565adad-ebaa-4f51-86d3-2ed2d097a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in params.items(): globals()[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c9f6a8a-0918-48d4-bb2e-aab50518c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Save parameters\n",
    "self__control_mode = \"canny\"\n",
    "self__learn_embedding = False\n",
    "self__infusion2control = \"cat\"\n",
    "self__infusion2base = \"add\"\n",
    "self__in_ch_factor = 1 if \"cat\" == 'add' else 2\n",
    "self__guiding = \"encoder\"\n",
    "self__two_stream_mode = \"cross\"\n",
    "self__control_model_ratio = 1.0\n",
    "self__out_channels = out_channels\n",
    "self__dims = 2\n",
    "self__model_channels = model_channels\n",
    "self__no_control = False\n",
    "self__control_scale = 1.0\n",
    "\n",
    "self__hint_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "201a427a-c965-472a-9ddf-3f5c2fff0ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Create base and control model\n",
    "self__base_model = base_model = UNet2DConditionModel()\n",
    "self__control_model = ctrl_model = UNet2DConditionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a43e8f68-2663-4a56-871e-d9c6a588c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Gather Channel Sizes\n",
    "ch_inout_ctrl = {'enc': [], 'mid': [], 'dec': []}\n",
    "ch_inout_base = {'enc': [], 'mid': [], 'dec': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2a01c2b-4c5c-43d8-8a3a-f63e184f9ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 - input convolution\n",
    "ch_inout_ctrl['enc'].append((ctrl_model.conv_in.in_channels, ctrl_model.conv_in.out_channels))\n",
    "ch_inout_base['enc'].append((base_model.conv_in.in_channels, base_model.conv_in.out_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c0d3cd6c-e16a-4f58-b5bb-a90431b230bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 - encoder blocks\n",
    "for module in ctrl_model.down_blocks:\n",
    "    if isinstance(module, (CrossAttnDownBlock2D, DownBlock2D)):\n",
    "            for r in module.resnets:\n",
    "                ch_inout_ctrl['enc'].append((r.in_channels, r.out_channels))\n",
    "            if module.downsamplers:\n",
    "                ch_inout_ctrl['enc'].append((module.downsamplers[0].channels, module.downsamplers[0].out_channels))\n",
    "    else:\n",
    "        raise ValueError(f'Encountered unknown module of type {type(module)} while creating ControlNet-XS.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6bcd0b93-b0cf-4c24-88e8-6813a354388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in base_model.down_blocks:\n",
    "    if isinstance(module, (CrossAttnDownBlock2D, DownBlock2D)):\n",
    "            for r in module.resnets:\n",
    "                ch_inout_base['enc'].append((r.in_channels, r.out_channels))\n",
    "            if module.downsamplers:\n",
    "                ch_inout_base['enc'].append((module.downsamplers[0].channels, module.downsamplers[0].out_channels))\n",
    "    else:\n",
    "        raise ValueError(f'Encountered unknown module of type {type(module)} while creating ControlNet-XS.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5e686b6-e36d-4e8d-a026-85c462def661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 - middle block\n",
    "ch_inout_ctrl['mid'].append((ctrl_model.mid_block.resnets[0].in_channels, ctrl_model.mid_block.resnets[0].in_channels))\n",
    "ch_inout_base['mid'].append((base_model.mid_block.resnets[0].in_channels, base_model.mid_block.resnets[0].in_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e01842fd-40cc-44ce-bbe8-e06e99ca719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 - decoder blocks\n",
    "for module in base_model.up_blocks:\n",
    "    if isinstance(module, (CrossAttnUpBlock2D, UpBlock2D)):\n",
    "        for r in module.resnets:\n",
    "            ch_inout_base['dec'].append((r.in_channels, r.out_channels))\n",
    "    else:\n",
    "        raise ValueError(f'Encountered unknown module of type {type(module)} while creating ControlNet-XS.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "34084bbe-6716-4da2-ada4-5654b9a7161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "self__ch_inout_ctrl = ch_inout_ctrl\n",
    "self__ch_inout_base = ch_inout_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c3dd298d-5f77-4f19-bb19-fa00476c8c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc': [(4, 320),\n",
       "  (320, 320),\n",
       "  (320, 320),\n",
       "  (320, 320),\n",
       "  (320, 640),\n",
       "  (640, 640),\n",
       "  (640, 640),\n",
       "  (640, 1280),\n",
       "  (1280, 1280),\n",
       "  (1280, 1280),\n",
       "  (1280, 1280),\n",
       "  (1280, 1280)],\n",
       " 'mid': [(1280, 1280)],\n",
       " 'dec': []}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self__ch_inout_ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca4f802d-1969-4f4a-84c2-718499a0d4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enc': [(4, 320),\n",
       "  (320, 320),\n",
       "  (320, 320),\n",
       "  (320, 320),\n",
       "  (320, 640),\n",
       "  (640, 640),\n",
       "  (640, 640),\n",
       "  (640, 1280),\n",
       "  (1280, 1280),\n",
       "  (1280, 1280),\n",
       "  (1280, 1280),\n",
       "  (1280, 1280)],\n",
       " 'mid': [(1280, 1280)],\n",
       " 'dec': [(2560, 1280),\n",
       "  (2560, 1280),\n",
       "  (2560, 1280),\n",
       "  (2560, 1280),\n",
       "  (2560, 1280),\n",
       "  (1920, 1280),\n",
       "  (1920, 640),\n",
       "  (1280, 640),\n",
       "  (960, 640),\n",
       "  (960, 320),\n",
       "  (640, 320),\n",
       "  (640, 320)]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self__ch_inout_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "22b9045f-c151-4ea1-a667-6af71b21ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Build connections between base and control model\n",
    "self__enc_zero_convs_out = nn.ModuleList([])\n",
    "self__enc_zero_convs_in = nn.ModuleList([])\n",
    "\n",
    "self__middle_block_out = nn.ModuleList([])\n",
    "self__middle_block_in = nn.ModuleList([])\n",
    "\n",
    "self__dec_zero_convs_out = nn.ModuleList([])\n",
    "self__dec_zero_convs_in = nn.ModuleList([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9ddbdb9d-c1b4-4667-b20a-5d0a0b8d04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyObject():\n",
    "    def make_zero_conv(self, in_channels, out_channels=None):\n",
    "        # keep running track # todo: better comment\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels or in_channels\n",
    "        return zero_module(nn.Conv2d(in_channels, out_channels, 1, padding=0))\n",
    "\n",
    "slimshady = DummyObject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bfda3483-9441-43c5-863d-0cfd9c1f176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch_io_base in ch_inout_base['enc']:\n",
    "    self__enc_zero_convs_in.append(slimshady.make_zero_conv(\n",
    "        in_channels=ch_io_base[1], out_channels=ch_io_base[1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22ad8844-64ec-4169-ac1f-d5d672fa3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "self__middle_block_out = slimshady.make_zero_conv(ch_inout_ctrl['mid'][-1][1], ch_inout_base['mid'][-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "51b0856c-a16b-4969-8d12-5a470eeae749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self__dec_zero_convs_out.append(\n",
    "    slimshady.make_zero_conv(ch_inout_ctrl['enc'][-1][1], ch_inout_base['mid'][-1][1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3e59b7c0-59f0-4d5f-a581-c14b4a7cd7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(ch_inout_ctrl['enc'])):\n",
    "    self__dec_zero_convs_out.append(\n",
    "        slimshady.make_zero_conv(ch_inout_ctrl['enc'][-(i + 1)][1], ch_inout_base['dec'][i - 1][1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "17281d32-37f8-48d3-b130-05439961279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 - Input hint block TODO: Understand\n",
    "self__input_hint_block = nn.Sequential(\n",
    "    nn.Conv2d(hint_channels, 16, 3, padding=1),\n",
    "    nn.SiLU(),\n",
    "    nn.Conv2d(16, 16, 3, padding=1),\n",
    "    nn.SiLU(),\n",
    "    nn.Conv2d(16, 32, 3, padding=1, stride=2),\n",
    "    nn.SiLU(),\n",
    "    nn.Conv2d(32, 32, 3, padding=1),\n",
    "    nn.SiLU(),\n",
    "    nn.Conv2d(32, 96, 3, padding=1, stride=2),\n",
    "    nn.SiLU(),\n",
    "    nn.Conv2d(96, 96, 3, padding=1),\n",
    "    nn.SiLU(),\n",
    "    nn.Conv2d(96, 256, 3, padding=1, stride=2),\n",
    "    nn.SiLU(),\n",
    "    zero_module(nn.Conv2d(256, int(model_channels * self__control_model_ratio), 3, padding=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b7d0d7c5-42bf-401f-a0a3-5650882a9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_list = [1.] * len(self__enc_zero_convs_out) + [1.] + [1.] * len(self__dec_zero_convs_out)\n",
    "#self__register_buffer('scale_list', torch.tensor(scale_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfde418-210f-4f91-ae27-173246535b64",
   "metadata": {},
   "source": [
    "Works! 🎉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b79dc53-068e-400f-8582-6a10be0eda28",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b8eff952-5d64-464c-827f-2c64902eca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_stream_model = ControlledUNet2DConditionModel(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66e806e-455e-49b2-afba-1d98e56a2a07",
   "metadata": {},
   "source": [
    "Works! 🎉"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d772283e-5372-44f2-aa7f-1090a469b026",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "529d2be9-9af1-4c47-b718-5567e095a184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.models.unet_2d_condition_control import ControlledUNet2DConditionModel as ControlledUNet2DConditionModelFromCodeBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d9b66bf7-7d9f-4221-85b6-f5eaa42bdab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diffusers.models.unet_2d_condition_control.ControlledUNet2DConditionModel"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ControlledUNet2DConditionModelFromCodeBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "042f3d04-e87d-487a-8f01-73d94a95c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_stream_model = ControlledUNet2DConditionModelFromCodeBase(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11d6bb8-5e4b-41d0-beb6-14d49cdec397",
   "metadata": {},
   "source": [
    "Works! 🎉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887f301c-9c95-4b87-a47a-b278a1fff72c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
