{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30794abe-5ec0-4ecd-90c5-5ef222fc2e48",
   "metadata": {},
   "source": [
    "I've now added SDXL-specific conditioning information (namely crop, original image size and target image size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa846a7-09c0-472e-b00b-53e1946eb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ae4f5a-d7eb-4471-be6f-cae1f309ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
    "device_dtype = torch.float16 if device == 'cuda' else torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739024d-d8ee-4aee-882c-9c5388ff6057",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c565cf82-1eaa-4e68-8d35-a6459ee60097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "from diffusers.models.controlnetxs import ControlNetXSModel\n",
    "from diffusers.pipelines.controlnet_xs.pipeline_controlnet_xs_sd_xl import StableDiffusionXLControlNetXSPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b304d6-cb41-49f5-849d-3e955da3e5e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the end of __init__, the sigmas are tensor([14.6146, 14.5263, 14.4386, 14.3515, 14.2651]) ...\n",
      "At the end of __init__, the sigmas are tensor([14.6146, 14.5263, 14.4386, 14.3515, 14.2651]) ...\n"
     ]
    }
   ],
   "source": [
    "sdxl_pipe = StableDiffusionXLPipeline.from_single_file('weights/sdxl/sd_xl_base_1.0_0.9vae.safetensors').to(device)\n",
    "cnxs = ControlNetXSModel.from_pretrained('weights/cnxs').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff484d8-80b5-4752-82f3-41187902a432",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxs.base_model = sdxl_pipe.unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8133f0b-7f0c-4ed4-8f6b-c4bc7d7e3efd",
   "metadata": {},
   "source": [
    "The example script of Heidelberg manually sets scale_list to 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c9d2935-7757-461f-9e71-f1bf4edce97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxs.scale_list = cnxs.scale_list * 0. + 0.95\n",
    "assert cnxs.scale_list[0] == .95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c41b8a-5e54-47d8-b9f6-86bb11d5a662",
   "metadata": {},
   "source": [
    "Heidelberg uses `timestep_spacing = 'linspace'` in their scheduler, so let's do that as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bc73d3f-4e90-487d-ae2d-07c8eb4e47c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the end of __init__, the sigmas are tensor([14.6146, 14.5263, 14.4386, 14.3515, 14.2651]) ...\n",
      "timestep_spacing = \"leading\" and timesteps=[999.      978.61224 958.2245  937.83673 917.449  ] ...\n",
      "sigmas before interpolation: [0.02916753 0.04131448 0.05068044 0.05861427 0.06563709] ...\n",
      "sigmas after (linear) interpolation: [14.61464691 12.93677721 11.49164976 10.24291444  9.16035419] ...\n",
      "At end of `set_timesteps`:\n",
      "sigmas =  tensor([14.6146, 12.9368, 11.4916, 10.2429,  9.1604]) ...\n",
      "timesteps = tensor([999.0000, 978.6122, 958.2245, 937.8367, 917.4490]) ...\n",
      "At the end of __init__, the sigmas are tensor([14.6146, 14.5263, 14.4386, 14.3515, 14.2651]) ...\n"
     ]
    }
   ],
   "source": [
    "scheduler_cgf = dict(sdxl_pipe.scheduler.config)\n",
    "scheduler_cgf['timestep_spacing'] = 'linspace'\n",
    "sdxl_pipe.scheduler = EulerDiscreteScheduler.from_config(scheduler_cgf)\n",
    "\n",
    "# test it worked\n",
    "sdxl_pipe.scheduler.set_timesteps(50)\n",
    "assert sdxl_pipe.scheduler.timesteps[0]==999\n",
    "\n",
    "# reset\n",
    "sdxl_pipe.scheduler = EulerDiscreteScheduler.from_config(scheduler_cgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a120b84b-1126-4d6c-b08e-8114b5761c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxs_pipe = StableDiffusionXLControlNetXSPipeline(\n",
    "    vae=sdxl_pipe.vae,\n",
    "    text_encoder=sdxl_pipe.text_encoder,\n",
    "    text_encoder_2=sdxl_pipe.text_encoder_2,\n",
    "    tokenizer=sdxl_pipe.tokenizer,\n",
    "    tokenizer_2=sdxl_pipe.tokenizer_2,\n",
    "    unet=sdxl_pipe.unet,\n",
    "    controlnet=cnxs,\n",
    "    scheduler=sdxl_pipe.scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994cd8cf-1682-47e5-a7ff-4ccb3095ad61",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b393e7e-b0c3-4563-8320-2f94c48d6e35",
   "metadata": {},
   "source": [
    "## Prepare the input to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb8fc37b-ed41-4b8e-b01b-4e0c10fd7c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from diffusers.utils import load_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CannyDetector:\n",
    "    def __call__(self, img, low_threshold, high_threshold):\n",
    "        return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def get_canny_edges(image, threshold=(100, 250)):\n",
    "    image = np.array(image).astype(np.uint8)\n",
    "    edges = CannyDetector()(image, *threshold)  # original sized greyscale edges\n",
    "    edges = edges / 255.\n",
    "    return edges\n",
    "\n",
    "def seed_everything(seed):\n",
    "    # paper used deprecated `seed_everything` from pytorch lightning\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "RANDOM_SEED_IN_PAPER = 1999158951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "026d6d8a-0580-4ab5-8b6a-c57037aa568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_sdxl_cloud = torch.load('latents_cloud_no_control.pth', map_location=torch.device(device))\n",
    "rand_from_cloud = latents_sdxl_cloud[0] / 14.6146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1594fe31-ba81-4308-b217-a73fd5bbdca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = 'cinematic, shoe in the streets, made from meat, photorealistic shoe, highly detailed'\n",
    "neg_prompt = 'lowres, bad anatomy, worst quality, low quality'\n",
    "\n",
    "image = load_image('input_images/shoe_cloud.png')\n",
    "edges = get_canny_edges(image)\n",
    "\n",
    "edges_tensor = torch.tensor(edges)\n",
    "three_edges = torch.stack((edges_tensor,edges_tensor,edges_tensor))\n",
    "three_edges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afbc4d4f-ecb6-41ac-ba85-40b2db9bddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxs_pipe.controlnet.DEBUG_LOG_by_Umer = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec7fdeb-a307-43db-b4cc-c36c03959506",
   "metadata": {},
   "source": [
    "## Let's run the denoising loop with control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9ed2c95-4be1-44a0-96f1-f91ea06dd291",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_plot import plot_latents_to_pil_grid, save_latents\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e61c519e-b4cf-4cc9-91d6-bf1601fff323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to save intermediate outputs of 1st denoising loop\n",
    "cnxs.DEBUG_LOG_by_Umer = True\n",
    "\n",
    "# # Uncomment to save intermediate outputs of 1st ResNet in 1st denoising loop\n",
    "#from diffusers.models.resnet import ResnetBlock2D\n",
    "#ResnetBlock2D.toggle_DO_UMER_CACHE(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bae92039-3af0-4d22-afff-6e87d7afd6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestep_spacing = \"leading\" and timesteps=[999.      978.61224 958.2245  937.83673 917.449  ] ...\n",
      "sigmas before interpolation: [0.02916753 0.04131448 0.05068044 0.05861427 0.06563709] ...\n",
      "sigmas after (linear) interpolation: [14.61464691 12.93677721 11.49164976 10.24291444  9.16035419] ...\n",
      "At end of `set_timesteps`:\n",
      "sigmas =  tensor([14.6146, 12.9368, 11.4916, 10.2429,  9.1604], device='mps:0') ...\n",
      "timesteps = tensor([999.0000, 978.6122, 958.2245, 937.8367, 917.4490], device='mps:0') ...\n",
      "Passed in latents:  tensor([ 1.3333,  0.5155,  0.4647, -0.5344,  1.0102], device='mps:0')\n",
      "initial_unscaled_latents:  tensor([ 1.3333,  0.5155,  0.4647, -0.5344,  1.0102], device='mps:0')\n",
      "latents:  tensor([19.4858,  7.5339,  6.7910, -7.8098, 14.7639], device='mps:0')\n",
      "add_time_ids = tensor([[768., 768.,   0.,   0., 768., 768.],\n",
      "        [768., 768.,   0.,   0., 768., 768.]], device='mps:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31fc972bc3842b0a6a6cb8bb4fa1468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps = tensor(999., device='mps:0')\n",
      "timesteps = tensor([999.], device='mps:0')\n",
      "t_emb.shape = [1, 320]\n",
      "learn_embedding = True\n",
      "t_emb.shape = [1, 1280]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/umer/Documents/GitHub/diffusers/diffusers/src/diffusers/models/controlnetxs.py:311: FutureWarning: Accessing config attribute `control_scale` directly via 'ControlNetXSModel' object attribute is deprecated. Please access 'control_scale' over 'ControlNetXSModel's config object instead, e.g. 'unet.config.control_scale'.\n",
      "  temb = self.control_model.time_embedding(t_emb) * self.control_scale ** 0.3 + self.base_model.time_embedding(t_emb) * (1 - self.control_scale ** 0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding aug_emb to temb. Shapes: [1, 1280] + [2, 1280] = [2, 1280]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Debug Log saved successfully",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m seed_everything(RANDOM_SEED_IN_PAPER)\n\u001b[1;32m      3\u001b[0m lats \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 4\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mcnxs_pipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneg_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthree_edges\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlatents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrand_from_cloud\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_latents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlats\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/controlnet-xs-ngkyeIE7/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/diffusers/diffusers/src/diffusers/pipelines/controlnet_xs/pipeline_controlnet_xs_sd_xl.py:753\u001b[0m, in \u001b[0;36mStableDiffusionXLControlNetXSPipeline.__call__\u001b[0;34m(self, prompt, prompt_2, image, height, width, num_inference_steps, guidance_scale, negative_prompt, negative_prompt_2, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds, output_type, return_dict, callback, callback_steps, cross_attention_kwargs, controlnet_conditioning_scale, guess_mode, control_guidance_start, control_guidance_end, original_size, crops_coords_top_left, target_size, negative_original_size, negative_crops_coords_top_left, negative_target_size)\u001b[0m\n\u001b[1;32m    750\u001b[0m added_cond_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m: add_text_embeds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: add_time_ids}\n\u001b[1;32m    752\u001b[0m \u001b[38;5;66;03m# predict the noise residual\u001b[39;00m\n\u001b[0;32m--> 753\u001b[0m noise_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrolnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlatent_model_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# todo: better naming\u001b[39;49;00m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attention_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madded_cond_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#return_dict=False,\u001b[39;49;00m\n\u001b[1;32m    761\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msample\n\u001b[1;32m    763\u001b[0m \u001b[38;5;66;03m# perform guidance\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_classifier_free_guidance:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/controlnet-xs-ngkyeIE7/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/controlnet-xs-ngkyeIE7/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/diffusers/diffusers/src/diffusers/models/controlnetxs.py:434\u001b[0m, in \u001b[0;36mControlNetXSModel.forward\u001b[0;34m(self, x, t, encoder_hidden_states, hint, cross_attention_kwargs, added_cond_kwargs, no_control)\u001b[0m\n\u001b[1;32m    431\u001b[0m     h_base \u001b[38;5;241m=\u001b[39m m_base(h_base, temb, cemb)\n\u001b[1;32m    432\u001b[0m     debug_by_umer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdec\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh_base\u001b[39m\u001b[38;5;124m'\u001b[39m, h_base)\n\u001b[0;32m--> 434\u001b[0m \u001b[43mdebug_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m UNet2DConditionOutput(sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mconv_out(h_base))\n",
      "File \u001b[0;32m~/Documents/GitHub/diffusers/diffusers/src/diffusers/models/controlnetxs.py:378\u001b[0m, in \u001b[0;36mControlNetXSModel.forward.<locals>.debug_save\u001b[0;34m()\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m    377\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(debug_log, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDEBUG_LOG_by_Umer_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDebug Log saved successfully\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Debug Log saved successfully"
     ]
    }
   ],
   "source": [
    "seed_everything(RANDOM_SEED_IN_PAPER)\n",
    "\n",
    "lats = []\n",
    "res = cnxs_pipe(\n",
    "    prompt, negative_prompt=neg_prompt,image=three_edges,latents=rand_from_cloud,\n",
    "    callback=partial(save_latents, lats=lats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6177e9-7fec-43ad-ae68-6d2a7d603d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b827afe7-53ff-449f-8252-111f67cb3d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda29465-f00c-40b1-a6be-5b3b23b47832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b9efd-476f-47b3-9b69-7ef3884460ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0bde5c-cb57-40b6-b730-3b00b8443c74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83af1fea-4806-4217-b897-34efe20e28a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = plot_latents_to_pil_grid(lats, pipe=cnxs_pipe, every=1, cols=10, im_size=(200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c48cfe-dee5-409a-859a-5cdd2004bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5dc5d73-d0d0-4e5f-88a7-c3a536a72d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnxs_pipe.unet.config.sample_size * cnxs_pipe.vae_scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b81cb0-1444-447f-9b51-69e2cb5a007c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
