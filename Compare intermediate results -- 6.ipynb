{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30794abe-5ec0-4ecd-90c5-5ef222fc2e48",
   "metadata": {},
   "source": [
    "The current issue seems to be applying the ctrl subblock. Let's analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fa846a7-09c0-472e-b00b-53e1946eb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.testing import assert_close\n",
    "from torch import allclose, nn, tensor\n",
    "torch.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ae4f5a-d7eb-4471-be6f-cae1f309ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps'\n",
    "device_dtype = torch.float16 if device == 'cuda' else torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c739024d-d8ee-4aee-882c-9c5388ff6057",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c565cf82-1eaa-4e68-8d35-a6459ee60097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "from diffusers import EulerDiscreteScheduler\n",
    "from diffusers.models.controlnetxs import ControlNetXSModel\n",
    "from diffusers.pipelines.controlnet_xs.pipeline_controlnet_xs_sd_xl import StableDiffusionXLControlNetXSPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b304d6-cb41-49f5-849d-3e955da3e5e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sdxl_pipe = StableDiffusionXLPipeline.from_single_file('weights/sdxl/sd_xl_base_1.0_0.9vae.safetensors').to(device)\n",
    "cnxs = ControlNetXSModel.from_pretrained('weights/cnxs').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1af1ff7f-cb94-448b-9988-6a309b56cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxs.base_model = sdxl_pipe.unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7758a1-6260-4d2c-a874-b63271eb9b61",
   "metadata": {},
   "source": [
    "The example script of Heidelberg manually sets scale_list to 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7f0107-b0ff-4989-aabf-533638fb7eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxs.scale_list = cnxs.scale_list * 0. + 0.95\n",
    "assert cnxs.scale_list[0] == .95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b95d9c-ac7a-42d3-82cf-4eef25a591ae",
   "metadata": {},
   "source": [
    "Heidelberg uses `timestep_spacing = 'linspace'` in their scheduler, so let's do that as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca82d739-fb30-429a-a902-3e711428ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmas after (linear) interpolation: [14.61464691 12.93677721 11.49164976 10.24291444  9.16035419] ...\n"
     ]
    }
   ],
   "source": [
    "scheduler_cgf = dict(sdxl_pipe.scheduler.config)\n",
    "scheduler_cgf['timestep_spacing'] = 'linspace'\n",
    "sdxl_pipe.scheduler = EulerDiscreteScheduler.from_config(scheduler_cgf)\n",
    "\n",
    "# test it worked\n",
    "sdxl_pipe.scheduler.set_timesteps(50)\n",
    "assert sdxl_pipe.scheduler.timesteps[0]==999\n",
    "\n",
    "# reset\n",
    "sdxl_pipe.scheduler = EulerDiscreteScheduler.from_config(scheduler_cgf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a120b84b-1126-4d6c-b08e-8114b5761c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxs_pipe = StableDiffusionXLControlNetXSPipeline(\n",
    "    vae=sdxl_pipe.vae,\n",
    "    text_encoder=sdxl_pipe.text_encoder,\n",
    "    text_encoder_2=sdxl_pipe.text_encoder_2,\n",
    "    tokenizer=sdxl_pipe.tokenizer,\n",
    "    tokenizer_2=sdxl_pipe.tokenizer_2,\n",
    "    unet=sdxl_pipe.unet,\n",
    "    controlnet=cnxs,\n",
    "    scheduler=sdxl_pipe.scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994cd8cf-1682-47e5-a7ff-4ccb3095ad61",
   "metadata": {},
   "source": [
    "## Compare intermediate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75837c73-7725-4fd1-92b4-7eef93cec881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_inspect import load_intermediate_outputs, print_metadata, compare_intermediate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f993133a-e5db-48e8-a7b5-2f8fad5e2b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 72)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outp_cloud = load_intermediate_outputs('intermediate_output/cloud_debug_log.pkl')\n",
    "model_outp_local = load_intermediate_outputs('intermediate_output/local_debug_log.pkl')\n",
    "len(model_outp_cloud),len(model_outp_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c63293d3-f987-4013-b2d1-ebcef00ead14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-  | cloud               | local               | equal name? | equal shape? | equal values? | mean abs Î”\n",
      "   |                     |                     |             |              |    prec=3     |     prec=5\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "8  | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[92m      y      \u001b[0m |    0.00008   added ctrl -> base\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "9  | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[92m      y      \u001b[0m |    0.00006   concatted base -> ctrl\n",
      "10 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00226   applied base subblock\n",
      "11 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[92m      y      \u001b[0m |    0.00019   applied ctrl subblock\n",
      "12 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00226   added ctrl -> base\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "13 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[92m      y      \u001b[0m |    0.00110   concatted base -> ctrl\n",
      "14 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00469   applied base subblock\n",
      "15 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00201   applied ctrl subblock\n",
      "16 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00466   added ctrl -> base\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "17 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00211   concatted base -> ctrl\n",
      "18 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00817   applied base subblock\n",
      "19 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.01570   applied ctrl subblock\n",
      "20 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00812   added ctrl -> base\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "21 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00592   concatted base -> ctrl\n",
      "22 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00677   applied base subblock\n",
      "23 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.20753   applied ctrl subblock\n",
      "24 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.03086   added ctrl -> base\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "25 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.05815   concatted base -> ctrl\n",
      "26 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.04061   applied base subblock\n",
      "27 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.16134   applied ctrl subblock\n",
      "28 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.04526   added ctrl -> base\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "29 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.04356   concatted base -> ctrl\n",
      "30 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.08757   applied base subblock\n",
      "31 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.34387   applied ctrl subblock\n",
      "32 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.09519   added ctrl -> base\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "33 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.09331   concatted base -> ctrl\n",
      "34 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.07433   applied base subblock\n",
      "35 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.34045   applied ctrl subblock\n",
      "36 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.20447   added ctrl -> base\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "37 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.44173   concatted base -> ctrl\n",
      "38 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.23572   applied base block\n",
      "39 | enc    h_ctrl       | enc    h_ctrl       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.28962   applied ctrl block\n",
      "40 | enc    h_base       | enc    h_base       | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.27217   added ctrl -> base\n"
     ]
    }
   ],
   "source": [
    "compare_intermediate_results(model_outp_cloud, model_outp_local, n=8+8*4, n_start=8,prec=5, compare_prec=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b774ae-522e-4243-a423-a4fa2eb1564d",
   "metadata": {},
   "source": [
    "## Analyze difference after application of `m_ctrl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe27d6e2-7c68-47b7-9a02-27594ef72b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.models.controlnetxs import to_sub_blocks\n",
    "ctrl_down_subblocks = to_sub_blocks(cnxs.control_model.down_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "667211d2-b49c-415b-8067-29588123bba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ctrl_down_subblocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f163e-3794-4305-ab74-872221edb8cc",
   "metadata": {},
   "source": [
    "To get a better understanding of the downblocks, let's print each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6886ab6b-3e3e-437b-bdf3-68a7ff977ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import cls_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1058617e-6360-4767-a8ed-2e8ec75e2e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : ResnetBlock2D\n",
      "1 : ResnetBlock2D\n",
      "2 : Downsample2D\n",
      "3 : ResnetBlock2D Transformer2DModel\n",
      "4 : ResnetBlock2D Transformer2DModel\n",
      "5 : Downsample2D\n",
      "6 : ResnetBlock2D Transformer2DModel\n",
      "7 : ResnetBlock2D Transformer2DModel\n"
     ]
    }
   ],
   "source": [
    "for i, b in enumerate(ctrl_down_subblocks):\n",
    "    print(i,':',' '.join(cls_name(m) for m in b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31416626-374d-4fce-9dce-a304587da66d",
   "metadata": {},
   "source": [
    "**Q:** Did I maybe also load their weights incorrectly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92267c79-9175-47d7-a458-0696d67ad15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResnetBlock2D(\n",
       "  (norm1): GroupNorm(32, 352, eps=1e-05, affine=True)\n",
       "  (conv1): LoRACompatibleConv(352, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_emb_proj): LoRACompatibleLinear(in_features=1280, out_features=32, bias=True)\n",
       "  (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (conv2): LoRACompatibleConv(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (nonlinearity): SiLU()\n",
       "  (conv_shortcut): LoRACompatibleConv(352, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_resblock = cnxs.control_model.down_blocks[0].resnets[0]\n",
    "first_resblock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d458c3a8-82eb-4462-8fa6-d6877cc93ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_parts = ('conv1','time_emb_proj','conv2','conv_shortcut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d556244-29e3-4e4b-9a02-6631bd4eb375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import cls_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba722067-911c-4adb-9b28-b56e64118b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transformer_keys(block_num):\n",
    "    keys = []\n",
    "    for i in range(block_num):\n",
    "        keys.extend([\n",
    "            f'transformer_blocks.{i}.attn1.to_q',\n",
    "            f'transformer_blocks.{i}.attn1.to_k',\n",
    "            f'transformer_blocks.{i}.attn1.to_v',\n",
    "            f'transformer_blocks.{i}.attn1.to_out.0',\n",
    "            f'transformer_blocks.{i}.attn2.to_q',\n",
    "            f'transformer_blocks.{i}.attn2.to_k',\n",
    "            f'transformer_blocks.{i}.attn2.to_v',\n",
    "            f'transformer_blocks.{i}.attn2.to_out.0',\n",
    "            f'transformer_blocks.{i}.ff.net.0.proj',\n",
    "            f'transformer_blocks.{i}.ff.net.2'\n",
    "        ])\n",
    "    return keys\n",
    "\n",
    "param_parts = {\n",
    "    'ResnetBlock2D': ['conv1','time_emb_proj','conv2','conv_shortcut'],\n",
    "    'Downsample2D': ['conv'],\n",
    "    'Transformer2DModel': [\n",
    "        'proj_in',\n",
    "        *generate_transformer_keys(10),\n",
    "        'proj_out'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f546d7b7-e199-4976-8f57-dfd58c18714c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 102)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param_parts['ResnetBlock2D']), len(param_parts['Downsample2D']), len(param_parts['Transformer2DModel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd8b49ec-1fd8-473b-bba9-af2945aad3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attr(o, attr_str):\n",
    "    attrs = attr_str.split('.')\n",
    "    for a in attrs:\n",
    "        if a.isdigit(): a = int(a)\n",
    "        o = o[a] if isinstance(a, int) else getattr(o,a)\n",
    "    return o\n",
    "\n",
    "def get_tf_idx(param_name):\n",
    "    if not 'transformer_blocks' in param_name: return -1\n",
    "    transformer_blocks, idx, *_ = param_name.split('.')\n",
    "    assert transformer_blocks=='transformer_blocks'\n",
    "    return int(idx)\n",
    "\n",
    "assert get_tf_idx('time_emb_proj')==-1\n",
    "assert get_tf_idx('transformer_blocks.0.ff.net.2')==0\n",
    "assert get_tf_idx('transformer_blocks.8.attn1.to_out.0')==8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4cc2bb7-861a-41f5-9943-dc1ff57209e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>> Subblock 0:\n",
      ">> ResnetBlock2D\n",
      "conv1                          tensor([-0.0225,  0.0219, -0.0374,  0.0109,  0.0028,  0.0212,  0.0164, -0.0133, -0.0110, -0.0135])\n",
      "time_emb_proj                  tensor([-0.0152,  0.0160, -0.0025,  0.0155, -0.0167,  0.0045, -0.0243, -0.0039,  0.0127, -0.0094])\n",
      "conv2                          tensor([-0.0180, -0.0231, -0.0207, -0.0339, -0.0294, -0.0046, -0.0047, -0.0194,  0.0065,  0.0078])\n",
      "conv_shortcut                  tensor([ 0.0269,  0.0493, -0.0816,  0.0297, -0.0484,  0.0082,  0.0849, -0.0301, -0.1588,  0.0405])\n",
      "\n",
      ">>>>>> Subblock 1:\n",
      ">> ResnetBlock2D\n",
      "conv1                          tensor([ 0.0023, -0.0076, -0.0082,  0.0090,  0.0185,  0.0055, -0.0044, -0.0300,  0.0023,  0.0091])\n",
      "time_emb_proj                  tensor([-0.0142,  0.0132, -0.0026,  0.0191, -0.0068,  0.0182, -0.0076,  0.0256,  0.0187, -0.0159])\n",
      "conv2                          tensor([ 0.0116,  0.0100, -0.0316, -0.0018,  0.0002, -0.0166, -0.0173,  0.0020, -0.0167, -0.0232])\n",
      "conv_shortcut                  tensor([ 0.0024, -0.0124, -0.0311, -0.0614, -0.0990, -0.0994, -0.0391, -0.1036,  0.0628,  0.0304])\n",
      "\n",
      ">>>>>> Subblock 2:\n",
      ">> Downsample2D\n",
      "conv                           tensor([ 0.0014, -0.0107, -0.0256, -0.0322, -0.0727, -0.0276, -0.0175, -0.0603, -0.0378, -0.0008])\n",
      "\n",
      ">>>>>> Subblock 3:\n",
      ">> ResnetBlock2D\n",
      "conv1                          tensor([ 0.0038, -0.0225, -0.0137,  0.0118,  0.0261,  0.0445,  0.0046,  0.0254,  0.0123,  0.0196])\n",
      "time_emb_proj                  tensor([ 0.0029,  0.0281,  0.0008,  0.0192,  0.0290,  0.0038, -0.0110,  0.0048, -0.0119,  0.0320])\n",
      "conv2                          tensor([-0.0015,  0.0039,  0.0196,  0.0022,  0.0137,  0.0201,  0.0038,  0.0015,  0.0076, -0.0116])\n",
      "conv_shortcut                  tensor([ 0.0105,  0.0405, -0.0068, -0.0370,  0.0426, -0.0199,  0.0712, -0.0207, -0.0158,  0.0146])\n",
      "\n",
      ">> Transformer2DModel\n",
      "proj_in                        tensor([-0.0132, -0.1289,  0.0080, -0.0004, -0.0598,  0.0756, -0.0536, -0.0622,  0.0140,  0.0685])\n",
      "tf.0.attn1.to_q                tensor([-0.0708, -0.0618, -0.0029, -0.0556,  0.0298, -0.0028, -0.0147, -0.1424, -0.0171, -0.0752])\n",
      "tf.0.attn1.to_k                tensor([ 0.0727,  0.0083,  0.0534, -0.0251,  0.0558,  0.0942,  0.0368, -0.0854,  0.0654, -0.0102])\n",
      "tf.0.attn1.to_v                tensor([-0.0920,  0.0127,  0.1043, -0.0144, -0.0748, -0.1255, -0.0276, -0.0074,  0.0802,  0.0938])\n",
      "tf.0.attn1.to_out.0            tensor([-0.0705, -0.0527, -0.0485, -0.1120, -0.0157, -0.1151, -0.0008,  0.1085,  0.0554,  0.0202])\n",
      "tf.0.attn2.to_q                tensor([ 0.0909,  0.0012, -0.0579,  0.1220, -0.0907, -0.0729,  0.0093,  0.0325,  0.0106,  0.0366])\n",
      "tf.0.attn2.to_k                tensor([ 0.0034, -0.0200,  0.0147,  0.0052, -0.0245, -0.0253, -0.0157,  0.0025,  0.0085,  0.0241])\n",
      "tf.0.attn2.to_v                tensor([ 0.0213, -0.0212, -0.0205, -0.0282, -0.0069,  0.0284,  0.0279, -0.0139,  0.0026,  0.0291])\n",
      "tf.0.attn2.to_out.0            tensor([-0.0420, -0.1001, -0.0411,  0.0139,  0.0870,  0.0107, -0.0535,  0.0694,  0.0958, -0.0267])\n",
      "tf.0.ff.net.0.proj             tensor([-0.1054,  0.0382,  0.0608,  0.1278,  0.0515, -0.0704,  0.0612,  0.1175, -0.0368, -0.0248])\n",
      "tf.0.ff.net.2                  tensor([-0.0155,  0.0287, -0.0662, -0.0337, -0.0223, -0.0203, -0.0853, -0.0299, -0.0747, -0.0123])\n",
      "tf.1.attn1.to_q                tensor([-0.0060,  0.0691,  0.0062,  0.0420,  0.0744, -0.1089,  0.0367,  0.1032,  0.1067, -0.0371])\n",
      "tf.1.attn1.to_k                tensor([-0.0108, -0.0416, -0.0039, -0.0450, -0.1244,  0.0041, -0.1120, -0.0808, -0.1015, -0.1183])\n",
      "tf.1.attn1.to_v                tensor([-0.0743,  0.0413, -0.1096,  0.0828,  0.0318, -0.1079,  0.0030, -0.0420,  0.0379,  0.1180])\n",
      "tf.1.attn1.to_out.0            tensor([-0.1213,  0.0590,  0.0283,  0.0682,  0.0934, -0.0513,  0.0045, -0.0866, -0.0492, -0.0423])\n",
      "tf.1.attn2.to_q                tensor([-0.0392, -0.0018, -0.0586,  0.0911,  0.1088, -0.0871, -0.0810, -0.0251,  0.0848, -0.0351])\n",
      "tf.1.attn2.to_k                tensor([ 0.0158, -0.0097,  0.0380,  0.0140, -0.0054,  0.0190, -0.0013,  0.0231, -0.0004,  0.0242])\n",
      "tf.1.attn2.to_v                tensor([ 0.0160, -0.0043,  0.0084,  0.0044, -0.0142, -0.0202, -0.0029, -0.0058,  0.0093, -0.0315])\n",
      "tf.1.attn2.to_out.0            tensor([-0.0556,  0.0267, -0.0045,  0.0777,  0.1275, -0.1263,  0.0006,  0.0915,  0.0830, -0.0559])\n",
      "tf.1.ff.net.0.proj             tensor([-0.0577,  0.0061,  0.0396, -0.1326,  0.0570,  0.0141,  0.1159, -0.1100,  0.0683,  0.0349])\n",
      "tf.1.ff.net.2                  tensor([-0.0617, -0.0759, -0.0257, -0.0202,  0.0523, -0.0043, -0.0112,  0.0737,  0.0493, -0.0288])\n",
      "proj_out                       tensor([-0.0172,  0.0044,  0.0066,  0.0124, -0.0120,  0.0134, -0.0232,  0.0067,  0.0279,  0.0055])\n",
      "\n",
      ">>>>>> Subblock 4:\n",
      ">> ResnetBlock2D\n",
      "conv1                          tensor([ 0.0125,  0.0231,  0.0078,  0.0088,  0.0212, -0.0005,  0.0063, -0.0082, -0.0049, -0.0073])\n",
      "time_emb_proj                  tensor([-0.0077,  0.0140, -0.0198, -0.0020,  0.0209,  0.0031,  0.0255,  0.0376,  0.0209,  0.0419])\n",
      "conv2                          tensor([ 0.0068,  0.0122,  0.0078, -0.0034,  0.0013,  0.0023, -0.0065,  0.0048,  0.0061, -0.0060])\n",
      "conv_shortcut                  tensor([ 0.0409,  0.0009,  0.0166,  0.0155, -0.0032,  0.0379, -0.0255,  0.0058, -0.0301,  0.0224])\n",
      "\n",
      ">> Transformer2DModel\n",
      "proj_in                        tensor([-0.0882,  0.0295,  0.0214,  0.0450, -0.0125, -0.0079, -0.0029, -0.0458,  0.1266, -0.0593])\n",
      "tf.0.attn1.to_q                tensor([ 0.0585, -0.0012, -0.0359, -0.1217,  0.0055, -0.1100, -0.0448, -0.0641, -0.0566,  0.0655])\n",
      "tf.0.attn1.to_k                tensor([ 0.0264, -0.0487, -0.0145, -0.0382, -0.0374, -0.1064,  0.0143, -0.0755,  0.0601,  0.1224])\n",
      "tf.0.attn1.to_v                tensor([ 0.0760,  0.0773, -0.0409,  0.0395, -0.0971, -0.0224, -0.0915, -0.0639, -0.0095, -0.0849])\n",
      "tf.0.attn1.to_out.0            tensor([ 0.0903,  0.0508, -0.1079,  0.0743,  0.1055, -0.0680, -0.0831,  0.0024, -0.0042, -0.1190])\n",
      "tf.0.attn2.to_q                tensor([-0.0951, -0.0242, -0.0196, -0.0132,  0.0370,  0.0970,  0.0110, -0.0003,  0.0644, -0.0903])\n",
      "tf.0.attn2.to_k                tensor([ 0.0301,  0.0111, -0.0144,  0.0089, -0.0023,  0.0023,  0.0196,  0.0137, -0.0110, -0.0184])\n",
      "tf.0.attn2.to_v                tensor([ 2.3207e-02,  1.1530e-02, -1.9561e-02,  1.3230e-05, -9.1913e-03,  3.4394e-03, -1.9755e-02,  2.0320e-02, -2.8509e-02,  2.1515e-02])\n",
      "tf.0.attn2.to_out.0            tensor([ 0.0443, -0.0029, -0.0546, -0.0021, -0.0197,  0.0154, -0.0603,  0.0990,  0.0235,  0.1166])\n",
      "tf.0.ff.net.0.proj             tensor([ 0.0912, -0.0214,  0.0722,  0.0358,  0.0028, -0.0358,  0.0736, -0.0054, -0.1129, -0.0010])\n",
      "tf.0.ff.net.2                  tensor([-0.0467, -0.0355, -0.0659, -0.0291,  0.0344, -0.0402, -0.0436,  0.0573, -0.0560, -0.0349])\n",
      "tf.1.attn1.to_q                tensor([-0.0845, -0.0594, -0.0133,  0.0125,  0.0351, -0.0746, -0.0448,  0.0442, -0.0644, -0.0901])\n",
      "tf.1.attn1.to_k                tensor([ 0.1027, -0.0331, -0.0730,  0.1103,  0.0440,  0.0811, -0.0045, -0.0377,  0.0662,  0.0727])\n",
      "tf.1.attn1.to_v                tensor([-0.0832,  0.0543,  0.0073,  0.0902, -0.0481, -0.1083,  0.0063,  0.0526, -0.0918,  0.1251])\n",
      "tf.1.attn1.to_out.0            tensor([-0.0990,  0.0737,  0.0995,  0.0736,  0.0691,  0.1058,  0.0751, -0.0016, -0.0089, -0.0876])\n",
      "tf.1.attn2.to_q                tensor([ 0.0065, -0.1133, -0.0172,  0.0338,  0.0565, -0.0616,  0.1085,  0.0741,  0.0702, -0.0095])\n",
      "tf.1.attn2.to_k                tensor([ 0.0070, -0.0235,  0.0309, -0.0002,  0.0356,  0.0033,  0.0035, -0.0044, -0.0147, -0.0182])\n",
      "tf.1.attn2.to_v                tensor([-0.0197, -0.0098,  0.0079,  0.0089,  0.0170, -0.0023, -0.0121, -0.0030,  0.0095, -0.0093])\n",
      "tf.1.attn2.to_out.0            tensor([ 0.0738,  0.0930, -0.0131,  0.0148,  0.0276,  0.0288, -0.0498, -0.0109, -0.0474,  0.0885])\n",
      "tf.1.ff.net.0.proj             tensor([-0.0192, -0.0088,  0.1059, -0.0440, -0.0777,  0.0659,  0.0965,  0.0080, -0.0292, -0.1160])\n",
      "tf.1.ff.net.2                  tensor([ 0.0116,  0.0227,  0.0470, -0.0382,  0.0422,  0.0449,  0.0117, -0.0723, -0.0177,  0.0224])\n",
      "proj_out                       tensor([-0.0058,  0.0089, -0.0026, -0.0059, -0.0066,  0.0005, -0.0066, -0.0025, -0.0029, -0.0119])\n",
      "\n",
      ">>>>>> Subblock 5:\n",
      ">> Downsample2D\n",
      "conv                           tensor([-0.0161, -0.0169, -0.0305, -0.0299, -0.0325, -0.0410, -0.0279, -0.0187, -0.0390,  0.0234])\n",
      "\n",
      ">>>>>> Subblock 6:\n",
      ">> ResnetBlock2D\n",
      "conv1                          tensor([ 0.0206,  0.0154,  0.0105,  0.0079,  0.0243,  0.0134,  0.0070,  0.0179,  0.0059, -0.0110])\n",
      "time_emb_proj                  tensor([-1.9000e-02,  1.4582e-02, -2.6406e-02,  2.2612e-02,  1.5059e-05,  3.3383e-02,  1.0330e-02, -1.6467e-03,  8.3065e-03, -2.8895e-03])\n",
      "conv2                          tensor([ 0.0040,  0.0018,  0.0039, -0.0016, -0.0038, -0.0039, -0.0098, -0.0114, -0.0120,  0.0087])\n",
      "conv_shortcut                  tensor([-0.0092,  0.0251,  0.0145, -0.0126, -0.0410,  0.0210, -0.0353, -0.0262, -0.0098, -0.0207])\n",
      "\n",
      ">> Transformer2DModel\n",
      "proj_in                        tensor([-0.0476, -0.0654, -0.0078, -0.0303,  0.0036, -0.0018, -0.0010,  0.0461, -0.0422,  0.0214])\n",
      "tf.0.attn1.to_q                tensor([-0.0341,  0.0308,  0.0333, -0.0587,  0.0798, -0.0723,  0.0641, -0.0184, -0.0369,  0.0115])\n",
      "tf.0.attn1.to_k                tensor([ 0.0690, -0.0033,  0.0097, -0.0481, -0.0098,  0.0273, -0.0306,  0.0797,  0.0111,  0.0326])\n",
      "tf.0.attn1.to_v                tensor([ 0.0892, -0.0664, -0.0588, -0.0735, -0.0289,  0.0799,  0.0773, -0.0010,  0.0808,  0.0263])\n",
      "tf.0.attn1.to_out.0            tensor([-0.0157,  0.0553, -0.0601,  0.0269,  0.0483,  0.0176, -0.0985, -0.0933, -0.0624,  0.0085])\n",
      "tf.0.attn2.to_q                tensor([ 0.0969,  0.0585,  0.0871,  0.0380,  0.0690,  0.0348, -0.0575,  0.0014,  0.0148, -0.0197])\n",
      "tf.0.attn2.to_k                tensor([-0.0286, -0.0156,  0.0261,  0.0139, -0.0146, -0.0233, -0.0192, -0.0117,  0.0310,  0.0352])\n",
      "tf.0.attn2.to_v                tensor([ 0.0130,  0.0041,  0.0188,  0.0084, -0.0094,  0.0148,  0.0175, -0.0121, -0.0086, -0.0133])\n",
      "tf.0.attn2.to_out.0            tensor([-0.0808,  0.0404,  0.0124, -0.0667,  0.0512, -0.0361, -0.0488, -0.0795,  0.0538,  0.0380])\n",
      "tf.0.ff.net.0.proj             tensor([-0.0325, -0.0108,  0.0237,  0.0182, -0.0108, -0.0270, -0.0518,  0.0437,  0.0734,  0.0114])\n",
      "tf.0.ff.net.2                  tensor([-0.0026, -0.0102, -0.0196, -0.0231, -0.0398, -0.0104, -0.0045, -0.0357,  0.0181,  0.0217])\n",
      "tf.1.attn1.to_q                tensor([-0.0695,  0.0387,  0.0475, -0.0996, -0.0015, -0.0003,  0.0931,  0.0018,  0.0190, -0.0086])\n",
      "tf.1.attn1.to_k                tensor([-0.0226, -0.0212,  0.0304,  0.0128, -0.0456, -0.0309,  0.0571, -0.0808, -0.0381, -0.0003])\n",
      "tf.1.attn1.to_v                tensor([ 0.0842, -0.0274,  0.0140,  0.0634, -0.0188,  0.0260,  0.0767,  0.0055,  0.0319, -0.0483])\n",
      "tf.1.attn1.to_out.0            tensor([-0.0014,  0.0140,  0.0093,  0.0794, -0.0627, -0.0321, -0.0368, -0.0455, -0.0559, -0.0531])\n",
      "tf.1.attn2.to_q                tensor([ 0.0602,  0.0520, -0.0294,  0.0268, -0.0655,  0.0130, -0.0466,  0.0265, -0.0792, -0.0943])\n",
      "tf.1.attn2.to_k                tensor([-0.0005, -0.0025,  0.0266,  0.0053, -0.0196,  0.0078,  0.0047, -0.0147,  0.0249, -0.0149])\n",
      "tf.1.attn2.to_v                tensor([ 0.0029, -0.0120,  0.0041, -0.0001,  0.0136,  0.0120,  0.0162,  0.0106,  0.0084,  0.0188])\n",
      "tf.1.attn2.to_out.0            tensor([ 0.0631,  0.0990, -0.0185, -0.0824,  0.0648,  0.0208,  0.0798,  0.0424,  0.0003, -0.0814])\n",
      "tf.1.ff.net.0.proj             tensor([ 0.0575,  0.0835,  0.0032, -0.0205,  0.0096,  0.0592,  0.0704,  0.0031,  0.0501, -0.0608])\n",
      "tf.1.ff.net.2                  tensor([ 0.0132,  0.0053, -0.0175, -0.0076,  0.0275, -0.0424,  0.0056,  0.0075,  0.0218, -0.0063])\n",
      "tf.2.attn1.to_q                tensor([ 0.0198,  0.0334, -0.0707, -0.0714, -0.0581, -0.0294,  0.0172, -0.0887,  0.0181,  0.0168])\n",
      "tf.2.attn1.to_k                tensor([-0.0791, -0.0674,  0.0450,  0.0798,  0.0133, -0.0509,  0.0194,  0.0317,  0.0568, -0.0599])\n",
      "tf.2.attn1.to_v                tensor([ 0.0718,  0.0064, -0.0640, -0.0326,  0.0560, -0.0152, -0.0779,  0.0476,  0.0282, -0.0087])\n",
      "tf.2.attn1.to_out.0            tensor([ 0.0408,  0.0540, -0.0551,  0.0418, -0.0102,  0.0067, -0.0538, -0.0349, -0.0676,  0.0473])\n",
      "tf.2.attn2.to_q                tensor([ 0.0127, -0.0087, -0.0182,  0.0173,  0.0424, -0.0575,  0.0816,  0.0185, -0.0099,  0.0213])\n",
      "tf.2.attn2.to_k                tensor([-0.0007,  0.0102,  0.0102,  0.0121, -0.0195, -0.0172,  0.0052, -0.0206, -0.0063, -0.0079])\n",
      "tf.2.attn2.to_v                tensor([-0.0043,  0.0029,  0.0148, -0.0087, -0.0065,  0.0026, -0.0195, -0.0084,  0.0018, -0.0245])\n",
      "tf.2.attn2.to_out.0            tensor([ 0.0314,  0.0197, -0.0791, -0.0340,  0.0554,  0.0351,  0.0099,  0.0545, -0.0593,  0.0172])\n",
      "tf.2.ff.net.0.proj             tensor([-0.0208,  0.0156,  0.0226, -0.0474,  0.0043, -0.0794, -0.0834, -0.0355, -0.0021,  0.0005])\n",
      "tf.2.ff.net.2                  tensor([ 0.0498,  0.0080, -0.0117, -0.0073,  0.0255,  0.0257, -0.0152,  0.0120,  0.0337, -0.0424])\n",
      "tf.3.attn1.to_q                tensor([-0.0236, -0.0382,  0.0142,  0.0002, -0.0619,  0.0838, -0.0318,  0.0805, -0.0043,  0.0396])\n",
      "tf.3.attn1.to_k                tensor([-0.0981, -0.0253, -0.0076,  0.0432, -0.0406, -0.0322, -0.0084, -0.0620,  0.0023,  0.0624])\n",
      "tf.3.attn1.to_v                tensor([ 0.0719, -0.0727,  0.0385,  0.0337, -0.0250,  0.0102,  0.0770, -0.0785, -0.0037,  0.0038])\n",
      "tf.3.attn1.to_out.0            tensor([-0.0538,  0.0237, -0.0848,  0.0059,  0.0437,  0.0827,  0.0577,  0.0526, -0.0255, -0.0532])\n",
      "tf.3.attn2.to_q                tensor([ 0.0763, -0.0042, -0.0156,  0.0615, -0.0397,  0.0588, -0.0162, -0.0470,  0.0560,  0.0804])\n",
      "tf.3.attn2.to_k                tensor([ 2.8897e-02, -1.1310e-02,  1.5304e-02,  2.7474e-05,  1.8081e-02,  5.5237e-04,  4.6104e-03,  2.2884e-02, -3.2629e-02, -9.8536e-03])\n",
      "tf.3.attn2.to_v                tensor([ 0.0157, -0.0093, -0.0058,  0.0122, -0.0139,  0.0164, -0.0028, -0.0093,  0.0098,  0.0233])\n",
      "tf.3.attn2.to_out.0            tensor([-0.0741,  0.0177, -0.0467,  0.0282, -0.0514, -0.0965,  0.0430, -0.0178,  0.0519, -0.0357])\n",
      "tf.3.ff.net.0.proj             tensor([ 0.0402,  0.0199, -0.0427, -0.0028,  0.0491, -0.0148,  0.0580, -0.0100, -0.0454,  0.0608])\n",
      "tf.3.ff.net.2                  tensor([ 0.0290,  0.0069,  0.0082, -0.0038,  0.0364, -0.0255, -0.0612,  0.0280,  0.0170, -0.0156])\n",
      "tf.4.attn1.to_q                tensor([-0.0044,  0.0680,  0.0011, -0.0700, -0.0301, -0.0086, -0.0441, -0.0197, -0.0702, -0.1036])\n",
      "tf.4.attn1.to_k                tensor([-0.0519, -0.0403, -0.0458,  0.0904,  0.0094,  0.0401, -0.0596,  0.0721,  0.0591, -0.0404])\n",
      "tf.4.attn1.to_v                tensor([-0.0333, -0.0085, -0.0570, -0.0376, -0.0483, -0.0112, -0.0197,  0.0031, -0.0437,  0.0137])\n",
      "tf.4.attn1.to_out.0            tensor([ 0.0616, -0.0595,  0.0581, -0.0484,  0.0177,  0.0373,  0.0578,  0.0218, -0.0010,  0.0236])\n",
      "tf.4.attn2.to_q                tensor([-0.0313,  0.0645,  0.0655, -0.0792, -0.0005, -0.0047, -0.0257, -0.0825,  0.0307,  0.0159])\n",
      "tf.4.attn2.to_k                tensor([ 0.0127,  0.0038, -0.0237, -0.0072,  0.0169,  0.0231, -0.0075, -0.0113,  0.0093,  0.0115])\n",
      "tf.4.attn2.to_v                tensor([ 0.0010,  0.0076, -0.0154,  0.0262, -0.0041,  0.0054,  0.0030, -0.0099,  0.0063,  0.0182])\n",
      "tf.4.attn2.to_out.0            tensor([-0.0712, -0.0641, -0.0340,  0.0256, -0.0242, -0.0185,  0.0742, -0.0036, -0.0540,  0.0232])\n",
      "tf.4.ff.net.0.proj             tensor([-0.0501, -0.0287, -0.0626,  0.0530, -0.0387,  0.0071, -0.0762,  0.0696, -0.0030, -0.0699])\n",
      "tf.4.ff.net.2                  tensor([ 0.0115,  0.0304,  0.0098,  0.0249,  0.0105, -0.0065,  0.0287, -0.0038,  0.0113, -0.0451])\n",
      "tf.5.attn1.to_q                tensor([ 0.0841,  0.0599,  0.0478,  0.0236,  0.0461,  0.0026,  0.0823, -0.0319, -0.0838, -0.0078])\n",
      "tf.5.attn1.to_k                tensor([ 0.0633,  0.0024,  0.0011,  0.0295, -0.0388,  0.0744, -0.0658,  0.0101,  0.0680,  0.0164])\n",
      "tf.5.attn1.to_v                tensor([ 0.0165,  0.0339, -0.0681,  0.0227,  0.0262,  0.0474, -0.0083, -0.0458, -0.0613, -0.0054])\n",
      "tf.5.attn1.to_out.0            tensor([ 0.0059,  0.0100,  0.0794,  0.0460, -0.0366, -0.0853,  0.0061, -0.0621, -0.0646,  0.0078])\n",
      "tf.5.attn2.to_q                tensor([ 0.0696, -0.0774, -0.0390,  0.0878,  0.0584, -0.0538,  0.0528,  0.0093,  0.0534,  0.0187])\n",
      "tf.5.attn2.to_k                tensor([ 0.0144,  0.0006, -0.0149, -0.0016,  0.0127, -0.0254,  0.0086, -0.0204,  0.0268,  0.0077])\n",
      "tf.5.attn2.to_v                tensor([ 0.0090, -0.0116,  0.0043,  0.0311,  0.0123, -0.0265,  0.0214,  0.0017, -0.0004, -0.0121])\n",
      "tf.5.attn2.to_out.0            tensor([-0.0160, -0.0765, -0.0706,  0.0044,  0.0132, -0.0124, -0.0796,  0.0619, -0.0474, -0.0759])\n",
      "tf.5.ff.net.0.proj             tensor([-0.0832, -0.0316, -0.0346,  0.0013, -0.0417,  0.0099, -0.0217,  0.0624, -0.0640,  0.0862])\n",
      "tf.5.ff.net.2                  tensor([ 0.0295,  0.0322,  0.0276, -0.0175,  0.0227, -0.0304,  0.0320, -0.0338,  0.0041, -0.0057])\n",
      "tf.6.attn1.to_q                tensor([ 0.0401, -0.0464, -0.0269, -0.0760, -0.0504,  0.0604,  0.0509, -0.0421, -0.0833, -0.0112])\n",
      "tf.6.attn1.to_k                tensor([-0.0754, -0.0144, -0.0689,  0.0303, -0.0435,  0.0067,  0.0492,  0.0762, -0.0527,  0.0077])\n",
      "tf.6.attn1.to_v                tensor([ 0.0535, -0.0262, -0.0025, -0.0104,  0.0557, -0.0296, -0.0849,  0.0850,  0.0593, -0.0548])\n",
      "tf.6.attn1.to_out.0            tensor([-0.0456, -0.0819, -0.0758, -0.0766, -0.0691,  0.0131, -0.0875,  0.0759,  0.0116,  0.0628])\n",
      "tf.6.attn2.to_q                tensor([ 0.0637, -0.0334, -0.0220,  0.0304, -0.0803, -0.0099, -0.0434,  0.0398,  0.0663, -0.0652])\n",
      "tf.6.attn2.to_k                tensor([ 2.3806e-02,  3.0377e-03, -2.5903e-02,  1.1734e-02,  9.8110e-03,  4.1499e-03,  1.1366e-02,  4.3166e-05, -7.2907e-03,  6.4405e-03])\n",
      "tf.6.attn2.to_v                tensor([ 0.0084, -0.0070, -0.0144,  0.0165, -0.0305,  0.0185,  0.0243, -0.0082, -0.0175,  0.0132])\n",
      "tf.6.attn2.to_out.0            tensor([-0.0008,  0.0476,  0.0992,  0.0471,  0.0542, -0.0032,  0.0159, -0.0543, -0.0344,  0.0661])\n",
      "tf.6.ff.net.0.proj             tensor([-0.0283, -0.0021,  0.0265, -0.0665,  0.0085,  0.0375,  0.0873,  0.0190, -0.0402,  0.0558])\n",
      "tf.6.ff.net.2                  tensor([ 0.0088,  0.0526, -0.0191,  0.0163, -0.0221, -0.0081,  0.0068, -0.0175,  0.0134,  0.0318])\n",
      "tf.7.attn1.to_q                tensor([-0.0232,  0.0853,  0.0047, -0.0732, -0.0131,  0.0702,  0.0356,  0.0671,  0.0563,  0.0023])\n",
      "tf.7.attn1.to_k                tensor([ 0.0169, -0.0253, -0.0517,  0.0361,  0.0169, -0.0363, -0.0082, -0.0154, -0.0611, -0.0654])\n",
      "tf.7.attn1.to_v                tensor([-0.0466,  0.0962, -0.0127, -0.0386, -0.0680, -0.0448, -0.0659, -0.0777,  0.0178, -0.0325])\n",
      "tf.7.attn1.to_out.0            tensor([-0.0191,  0.0195,  0.0516, -0.0223, -0.0776,  0.0403, -0.0308, -0.0279, -0.0011, -0.0336])\n",
      "tf.7.attn2.to_q                tensor([ 0.0400, -0.0404, -0.0598, -0.0665, -0.0456, -0.0628,  0.0815,  0.0381, -0.0118, -0.0145])\n",
      "tf.7.attn2.to_k                tensor([-0.0311, -0.0015,  0.0082, -0.0067,  0.0288,  0.0115, -0.0144, -0.0169,  0.0028, -0.0097])\n",
      "tf.7.attn2.to_v                tensor([ 0.0030, -0.0051,  0.0086,  0.0231,  0.0226,  0.0018, -0.0271, -0.0343, -0.0052, -0.0085])\n",
      "tf.7.attn2.to_out.0            tensor([ 0.0901, -0.0293,  0.0141,  0.0704, -0.0183, -0.0149,  0.0140,  0.0201, -0.0531,  0.0316])\n",
      "tf.7.ff.net.0.proj             tensor([-0.0024, -0.0775,  0.0030, -0.0117,  0.0096, -0.0732, -0.0496,  0.0315,  0.0369, -0.0819])\n",
      "tf.7.ff.net.2                  tensor([-0.0380,  0.0439, -0.0090, -0.0367, -0.0196, -0.0027,  0.0056, -0.0206, -0.0022,  0.0558])\n",
      "tf.8.attn1.to_q                tensor([ 0.0443,  0.0767,  0.0342,  0.0530, -0.0294,  0.0033,  0.0154,  0.0339,  0.0854, -0.0513])\n",
      "tf.8.attn1.to_k                tensor([ 0.0602, -0.0747, -0.0807,  0.0489, -0.0622,  0.0638,  0.0828,  0.0076,  0.0416,  0.0384])\n",
      "tf.8.attn1.to_v                tensor([ 0.0542, -0.0802,  0.0832,  0.0426,  0.0050,  0.0539,  0.0545,  0.0755, -0.0257, -0.0525])\n",
      "tf.8.attn1.to_out.0            tensor([ 0.0123, -0.0585, -0.0221, -0.0209,  0.0228, -0.0207,  0.0795, -0.0154,  0.0649,  0.0373])\n",
      "tf.8.attn2.to_q                tensor([-0.0665,  0.0903, -0.0549,  0.0425, -0.0052,  0.0326, -0.0949, -0.0487,  0.0700, -0.0766])\n",
      "tf.8.attn2.to_k                tensor([-0.0234, -0.0056,  0.0063, -0.0198, -0.0115, -0.0410, -0.0043, -0.0235,  0.0147, -0.0315])\n",
      "tf.8.attn2.to_v                tensor([ 0.0031,  0.0040, -0.0370, -0.0045,  0.0046,  0.0057, -0.0045, -0.0012, -0.0047,  0.0120])\n",
      "tf.8.attn2.to_out.0            tensor([-0.0710, -0.0496, -0.0347, -0.0417,  0.0756, -0.0060, -0.0556,  0.0804,  0.0188,  0.0141])\n",
      "tf.8.ff.net.0.proj             tensor([-0.0216,  0.0138, -0.0358,  0.0237, -0.0409, -0.0325,  0.0220, -0.0861,  0.0784,  0.0031])\n",
      "tf.8.ff.net.2                  tensor([ 0.0168, -0.0152, -0.0055,  0.0484,  0.0257, -0.0161, -0.0185,  0.0148, -0.0066,  0.0291])\n",
      "tf.9.attn1.to_q                tensor([ 0.0076,  0.0334, -0.0162,  0.0413,  0.0012,  0.0315,  0.0486,  0.0202,  0.0166, -0.0385])\n",
      "tf.9.attn1.to_k                tensor([-0.0698,  0.0244,  0.0332,  0.0396, -0.0407, -0.0394, -0.0829,  0.0504,  0.0027, -0.0031])\n",
      "tf.9.attn1.to_v                tensor([-0.0041,  0.0292,  0.0041, -0.0184,  0.0185,  0.0624, -0.0010,  0.0377,  0.0111,  0.0134])\n",
      "tf.9.attn1.to_out.0            tensor([-0.0263, -0.0128, -0.0439, -0.0511, -0.0081,  0.0511, -0.0293, -0.0145,  0.0345, -0.0352])\n",
      "tf.9.attn2.to_q                tensor([ 0.0343,  0.0658,  0.0613, -0.0005,  0.0183, -0.0467, -0.0671,  0.0180,  0.0257,  0.0828])\n",
      "tf.9.attn2.to_k                tensor([ 0.0052, -0.0191,  0.0019, -0.0095, -0.0176,  0.0151,  0.0218,  0.0220, -0.0137,  0.0035])\n",
      "tf.9.attn2.to_v                tensor([ 0.0253, -0.0072, -0.0018,  0.0158, -0.0129,  0.0009, -0.0191,  0.0157, -0.0065, -0.0214])\n",
      "tf.9.attn2.to_out.0            tensor([-0.0372,  0.0555, -0.0232,  0.0724,  0.0485, -0.0053,  0.0177, -0.0260, -0.0155,  0.0017])\n",
      "tf.9.ff.net.0.proj             tensor([-0.0502,  0.0054, -0.0510, -0.0669, -0.0146,  0.0425,  0.0325,  0.0359, -0.0242,  0.0158])\n",
      "tf.9.ff.net.2                  tensor([ 0.0427,  0.0147,  0.0486,  0.0202, -0.0033,  0.0346,  0.0293,  0.0266,  0.0252,  0.0358])\n",
      "proj_out                       tensor([ 0.0032,  0.0013, -0.0018,  0.0103,  0.0057, -0.0103,  0.0031,  0.0093,  0.0029, -0.0051])\n",
      "\n",
      ">>>>>> Subblock 7:\n",
      ">> ResnetBlock2D\n",
      "conv1                          tensor([-9.8836e-05,  1.3444e-02,  1.0174e-02,  4.2135e-03,  5.0547e-03,  4.8702e-03, -7.1490e-03,  6.3899e-03,  8.2130e-03,  5.3117e-03])\n",
      "time_emb_proj                  tensor([-0.0073,  0.0077, -0.0156,  0.0150, -0.0060,  0.0162,  0.0031, -0.0053,  0.0093, -0.0236])\n",
      "conv2                          tensor([ 0.0107, -0.0005, -0.0032,  0.0017, -0.0033, -0.0045,  0.0066,  0.0030,  0.0046, -0.0098])\n",
      "conv_shortcut                  tensor([-0.0185, -0.0004, -0.0143,  0.0176,  0.0277,  0.0025, -0.0249, -0.0079,  0.0086,  0.0037])\n",
      "\n",
      ">> Transformer2DModel\n",
      "proj_in                        tensor([ 0.0303, -0.0019,  0.0922,  0.0365,  0.0314,  0.0869, -0.0709,  0.0110, -0.1126,  0.0459])\n",
      "tf.0.attn1.to_q                tensor([ 0.0047, -0.0457,  0.0094,  0.0264, -0.0553, -0.0106,  0.0183, -0.0123, -0.0306,  0.0301])\n",
      "tf.0.attn1.to_k                tensor([-0.0040,  0.0324,  0.0916,  0.0136, -0.0257, -0.0236, -0.0022,  0.0480,  0.0869,  0.0686])\n",
      "tf.0.attn1.to_v                tensor([ 0.0891, -0.0682, -0.0736, -0.0678, -0.0726, -0.0600,  0.0646, -0.0600,  0.0522,  0.0027])\n",
      "tf.0.attn1.to_out.0            tensor([ 0.0656,  0.0415, -0.0389, -0.0214, -0.0467,  0.0048,  0.0098, -0.0585,  0.0325,  0.0084])\n",
      "tf.0.attn2.to_q                tensor([ 0.0031, -0.0022, -0.0379, -0.0592, -0.0086, -0.0123,  0.0813, -0.0865,  0.0440, -0.0424])\n",
      "tf.0.attn2.to_k                tensor([-0.0127, -0.0279,  0.0181,  0.0273, -0.0215, -0.0005,  0.0070, -0.0151,  0.0195,  0.0006])\n",
      "tf.0.attn2.to_v                tensor([-0.0037, -0.0147,  0.0092, -0.0062,  0.0149,  0.0062, -0.0266, -0.0176, -0.0154, -0.0050])\n",
      "tf.0.attn2.to_out.0            tensor([-0.0495,  0.0325, -0.0399,  0.0091,  0.0580,  0.0242,  0.0257,  0.0623,  0.0272, -0.0121])\n",
      "tf.0.ff.net.0.proj             tensor([ 0.0807, -0.0508, -0.0137,  0.0791,  0.0482, -0.0303,  0.0628, -0.0719, -0.0331, -0.0500])\n",
      "tf.0.ff.net.2                  tensor([-0.0423, -0.0213,  0.0277,  0.0158, -0.0233, -0.0037, -0.0145, -0.0302,  0.0036, -0.0072])\n",
      "tf.1.attn1.to_q                tensor([-0.0096,  0.0257,  0.0076,  0.0171,  0.0801,  0.0694, -0.0333, -0.0751,  0.0165,  0.0092])\n",
      "tf.1.attn1.to_k                tensor([-0.0346,  0.0401, -0.0573, -0.0935,  0.0327,  0.0251,  0.0544, -0.0817,  0.0787,  0.0233])\n",
      "tf.1.attn1.to_v                tensor([-0.0434, -0.0319,  0.0577, -0.0232,  0.0744,  0.0517,  0.0319,  0.0504, -0.0312,  0.0061])\n",
      "tf.1.attn1.to_out.0            tensor([ 0.0268, -0.0585, -0.0655, -0.0528, -0.0784, -0.0607,  0.0366, -0.0414, -0.0527, -0.0222])\n",
      "tf.1.attn2.to_q                tensor([-0.0669, -0.0635,  0.0851,  0.0901, -0.0086, -0.0006,  0.0318,  0.0948,  0.0050,  0.0026])\n",
      "tf.1.attn2.to_k                tensor([-0.0191,  0.0044,  0.0053,  0.0136,  0.0026, -0.0169, -0.0060, -0.0217,  0.0223,  0.0163])\n",
      "tf.1.attn2.to_v                tensor([-0.0074,  0.0136, -0.0212,  0.0127, -0.0038,  0.0256,  0.0293,  0.0121,  0.0131, -0.0084])\n",
      "tf.1.attn2.to_out.0            tensor([ 0.0722,  0.0776, -0.0022, -0.0489, -0.0529,  0.0509, -0.0768, -0.0761,  0.0627,  0.0332])\n",
      "tf.1.ff.net.0.proj             tensor([ 0.0804,  0.0469,  0.0533,  0.0024, -0.0621, -0.0784, -0.0109,  0.0447, -0.0419,  0.0029])\n",
      "tf.1.ff.net.2                  tensor([-0.0010, -0.0433, -0.0219,  0.0066,  0.0440, -0.0351,  0.0391,  0.0430, -0.0337,  0.0238])\n",
      "tf.2.attn1.to_q                tensor([-0.0217,  0.0573,  0.0616, -0.0778,  0.0154,  0.0146,  0.0718, -0.0238, -0.0401, -0.0147])\n",
      "tf.2.attn1.to_k                tensor([ 0.0565, -0.0128,  0.0120, -0.0003, -0.0589,  0.0666,  0.0533, -0.0463,  0.0309,  0.0709])\n",
      "tf.2.attn1.to_v                tensor([ 0.0838,  0.0735,  0.0684,  0.0573, -0.0504,  0.0618,  0.0225,  0.0679,  0.0107, -0.0517])\n",
      "tf.2.attn1.to_out.0            tensor([-0.0062,  0.0380, -0.0050, -0.0428,  0.0207, -0.0668,  0.0745,  0.0553, -0.0586,  0.0381])\n",
      "tf.2.attn2.to_q                tensor([ 0.0716,  0.0269, -0.0178,  0.0532, -0.0109,  0.0563, -0.0745, -0.0241,  0.0409,  0.0523])\n",
      "tf.2.attn2.to_k                tensor([ 0.0064, -0.0055,  0.0114, -0.0051, -0.0035, -0.0100, -0.0085, -0.0119,  0.0030,  0.0053])\n",
      "tf.2.attn2.to_v                tensor([ 1.9471e-02,  1.8939e-02,  3.6853e-03, -3.4951e-03,  6.0521e-05,  4.4903e-03,  1.1573e-02,  1.5326e-02,  8.7045e-04, -2.1390e-02])\n",
      "tf.2.attn2.to_out.0            tensor([ 0.0177, -0.0098,  0.0495, -0.0314,  0.0189, -0.0722,  0.0690,  0.0038,  0.0496,  0.0588])\n",
      "tf.2.ff.net.0.proj             tensor([-0.0747, -0.0606,  0.0884,  0.0759,  0.0551, -0.0441,  0.0684, -0.0446,  0.0232,  0.0177])\n",
      "tf.2.ff.net.2                  tensor([-0.0210, -0.0002,  0.0002,  0.0140, -0.0072,  0.0188, -0.0125, -0.0024, -0.0246,  0.0297])\n",
      "tf.3.attn1.to_q                tensor([ 0.0801, -0.0559, -0.0045, -0.0665, -0.0106, -0.0440, -0.0073, -0.0345,  0.0084, -0.0063])\n",
      "tf.3.attn1.to_k                tensor([ 0.0676, -0.0546, -0.0397,  0.0390, -0.0610,  0.0171, -0.0038, -0.0505, -0.0777,  0.0608])\n",
      "tf.3.attn1.to_v                tensor([-0.0021,  0.0092, -0.0551, -0.0157, -0.0176,  0.0315,  0.0018,  0.0311,  0.0266, -0.0457])\n",
      "tf.3.attn1.to_out.0            tensor([-0.0056,  0.0783, -0.0497, -0.0132, -0.0316, -0.0218, -0.0232, -0.0325,  0.0008, -0.0502])\n",
      "tf.3.attn2.to_q                tensor([-0.0120,  0.0154,  0.0052, -0.0737, -0.0378,  0.0171, -0.0589,  0.0691, -0.0004,  0.0621])\n",
      "tf.3.attn2.to_k                tensor([ 0.0180,  0.0192,  0.0152,  0.0103,  0.0088,  0.0207,  0.0095, -0.0057, -0.0096, -0.0098])\n",
      "tf.3.attn2.to_v                tensor([-0.0013,  0.0011,  0.0054,  0.0004, -0.0195,  0.0136, -0.0033,  0.0100,  0.0104, -0.0069])\n",
      "tf.3.attn2.to_out.0            tensor([-0.0813,  0.0188, -0.0551,  0.0725,  0.0369, -0.0518,  0.0264, -0.0803, -0.0343, -0.0697])\n",
      "tf.3.ff.net.0.proj             tensor([-0.0437,  0.0663,  0.0495, -0.0093,  0.0191, -0.0213, -0.0412, -0.0026,  0.0208, -0.0712])\n",
      "tf.3.ff.net.2                  tensor([ 0.0240, -0.0334,  0.0224, -0.0032,  0.0024,  0.0111,  0.0161, -0.0247, -0.0009, -0.0302])\n",
      "tf.4.attn1.to_q                tensor([-0.0777,  0.0245, -0.0161, -0.0414,  0.0652, -0.0308, -0.0285, -0.0322,  0.0273, -0.0788])\n",
      "tf.4.attn1.to_k                tensor([ 0.0690, -0.0521,  0.0492, -0.0513,  0.0648,  0.0608,  0.0611, -0.0742,  0.0259,  0.0329])\n",
      "tf.4.attn1.to_v                tensor([ 0.0153, -0.0411,  0.0918, -0.0417, -0.0261,  0.0365,  0.0526,  0.0647, -0.0212,  0.0356])\n",
      "tf.4.attn1.to_out.0            tensor([-0.0795,  0.0841,  0.0027, -0.0382,  0.0067,  0.0699,  0.0687,  0.0527, -0.0635,  0.0133])\n",
      "tf.4.attn2.to_q                tensor([-0.0658, -0.0640, -0.0782, -0.0650, -0.0761,  0.0562,  0.0524, -0.0776,  0.0764, -0.0898])\n",
      "tf.4.attn2.to_k                tensor([ 0.0151,  0.0095,  0.0050,  0.0133, -0.0134, -0.0178, -0.0201, -0.0179,  0.0133, -0.0145])\n",
      "tf.4.attn2.to_v                tensor([ 0.0175,  0.0145, -0.0045, -0.0030,  0.0259, -0.0024, -0.0078,  0.0284, -0.0250, -0.0085])\n",
      "tf.4.attn2.to_out.0            tensor([-0.0614, -0.0301, -0.0327, -0.0004, -0.0335, -0.0373,  0.0095, -0.0341,  0.0536, -0.0372])\n",
      "tf.4.ff.net.0.proj             tensor([-0.0042, -0.0025,  0.0391, -0.0815,  0.0202,  0.0225,  0.0316, -0.0860, -0.0501,  0.0597])\n",
      "tf.4.ff.net.2                  tensor([-0.0349, -0.0207,  0.0275, -0.0215,  0.0380,  0.0379,  0.0427,  0.0052, -0.0234, -0.0178])\n",
      "tf.5.attn1.to_q                tensor([ 0.0628, -0.0724, -0.0349,  0.0328,  0.0824, -0.0638,  0.0637,  0.0028,  0.0825, -0.0306])\n",
      "tf.5.attn1.to_k                tensor([ 0.0769,  0.0576, -0.0779,  0.0421, -0.0710,  0.0572,  0.0375, -0.0108, -0.0358,  0.0183])\n",
      "tf.5.attn1.to_v                tensor([-0.0727,  0.0808,  0.0676, -0.0401, -0.0198,  0.0238,  0.0924, -0.1001,  0.0880, -0.0786])\n",
      "tf.5.attn1.to_out.0            tensor([-0.0110,  0.0812,  0.0162, -0.0445,  0.0190, -0.0584,  0.0370,  0.0606, -0.0482, -0.0429])\n",
      "tf.5.attn2.to_q                tensor([-0.0302,  0.0176,  0.0612,  0.0600, -0.0452,  0.0819, -0.0674,  0.0114, -0.0219,  0.0244])\n",
      "tf.5.attn2.to_k                tensor([-0.0120,  0.0125,  0.0146, -0.0217,  0.0039,  0.0029,  0.0013,  0.0116, -0.0122,  0.0180])\n",
      "tf.5.attn2.to_v                tensor([-0.0077,  0.0029,  0.0125, -0.0225, -0.0207, -0.0211,  0.0156,  0.0176,  0.0007,  0.0262])\n",
      "tf.5.attn2.to_out.0            tensor([-0.0738,  0.0448, -0.0848,  0.0580, -0.0476,  0.0057, -0.0734,  0.0582, -0.0493,  0.0271])\n",
      "tf.5.ff.net.0.proj             tensor([ 0.0447,  0.0595, -0.0488, -0.0137, -0.0573, -0.0248,  0.0184,  0.0359, -0.0237,  0.0107])\n",
      "tf.5.ff.net.2                  tensor([ 0.0335,  0.0405,  0.0102, -0.0316, -0.0468,  0.0372, -0.0069, -0.0084, -0.0200,  0.0425])\n",
      "tf.6.attn1.to_q                tensor([-0.0724, -0.0155,  0.0609,  0.0284, -0.0173, -0.0041,  0.0627,  0.0638,  0.0495,  0.0803])\n",
      "tf.6.attn1.to_k                tensor([-0.0346, -0.0492, -0.0012,  0.0763, -0.0146,  0.0211,  0.0932,  0.0717,  0.0371,  0.0600])\n",
      "tf.6.attn1.to_v                tensor([ 0.0288,  0.0776,  0.0566, -0.0266, -0.0438,  0.0435, -0.0389, -0.0523, -0.0201, -0.0194])\n",
      "tf.6.attn1.to_out.0            tensor([-0.0576,  0.0167, -0.0446, -0.0817, -0.0146, -0.0379, -0.0236, -0.0475,  0.0004,  0.0395])\n",
      "tf.6.attn2.to_q                tensor([ 0.0460, -0.0633, -0.0887,  0.0237,  0.0260,  0.0507, -0.0042, -0.0262,  0.0025,  0.0520])\n",
      "tf.6.attn2.to_k                tensor([ 0.0344,  0.0030, -0.0027, -0.0212, -0.0182,  0.0377,  0.0069, -0.0031, -0.0135,  0.0142])\n",
      "tf.6.attn2.to_v                tensor([ 0.0199, -0.0190, -0.0092,  0.0256,  0.0231, -0.0012,  0.0005, -0.0063, -0.0026, -0.0163])\n",
      "tf.6.attn2.to_out.0            tensor([-0.0191, -0.0513,  0.0552, -0.1031, -0.0527, -0.0393,  0.0417,  0.0116, -0.0453, -0.0969])\n",
      "tf.6.ff.net.0.proj             tensor([ 0.0689,  0.0204, -0.0172, -0.0224,  0.0876, -0.0280, -0.0551, -0.0538, -0.0426, -0.0215])\n",
      "tf.6.ff.net.2                  tensor([ 0.0208, -0.0175,  0.0198, -0.0338,  0.0415,  0.0122, -0.0452,  0.0131,  0.0453,  0.0022])\n",
      "tf.7.attn1.to_q                tensor([ 0.0250, -0.0659, -0.0132, -0.0699, -0.0160,  0.0342,  0.0259,  0.0730, -0.0955, -0.0274])\n",
      "tf.7.attn1.to_k                tensor([ 0.0506, -0.0432, -0.0526, -0.0584,  0.0737,  0.0798, -0.0438, -0.0237, -0.0656,  0.0329])\n",
      "tf.7.attn1.to_v                tensor([-0.0066,  0.0428, -0.0543,  0.0035,  0.0079,  0.0171,  0.0676,  0.0455,  0.0768,  0.0081])\n",
      "tf.7.attn1.to_out.0            tensor([ 0.0027, -0.0563,  0.0170, -0.0340,  0.0254,  0.0807, -0.0402, -0.0324,  0.0024,  0.0106])\n",
      "tf.7.attn2.to_q                tensor([ 0.0377, -0.0617, -0.0359,  0.0098, -0.0847, -0.0642,  0.0633, -0.0332, -0.0798,  0.0118])\n",
      "tf.7.attn2.to_k                tensor([-0.0261, -0.0337,  0.0387,  0.0076, -0.0043, -0.0021, -0.0099, -0.0389,  0.0160,  0.0083])\n",
      "tf.7.attn2.to_v                tensor([-8.4636e-03,  1.1421e-02, -2.7787e-02, -2.0293e-02,  2.3324e-02,  1.2340e-02,  1.0920e-02,  1.9674e-03, -1.4922e-02,  9.7133e-05])\n",
      "tf.7.attn2.to_out.0            tensor([ 0.0128, -0.0830,  0.0305,  0.0478, -0.0613,  0.0178,  0.0594, -0.0653,  0.0346, -0.0158])\n",
      "tf.7.ff.net.0.proj             tensor([-0.0033, -0.0098, -0.0524, -0.0444, -0.0726, -0.0302,  0.0332, -0.0172,  0.0266, -0.0538])\n",
      "tf.7.ff.net.2                  tensor([-0.0124, -0.0077, -0.0463, -0.0080, -0.0311, -0.0065, -0.0112,  0.0089, -0.0173, -0.0123])\n",
      "tf.8.attn1.to_q                tensor([-0.0218,  0.0061,  0.0049,  0.0470, -0.0751,  0.0723, -0.0750,  0.0642,  0.0461, -0.0135])\n",
      "tf.8.attn1.to_k                tensor([-0.0244, -0.0574,  0.0404,  0.0087,  0.0283, -0.0617,  0.0227,  0.0674, -0.0183,  0.0602])\n",
      "tf.8.attn1.to_v                tensor([-0.0645,  0.0180,  0.0492, -0.0919, -0.0103,  0.0305, -0.0497, -0.0758, -0.0719,  0.0565])\n",
      "tf.8.attn1.to_out.0            tensor([ 0.0210, -0.0432,  0.0683,  0.0177,  0.0646, -0.0024,  0.0192, -0.0234, -0.0693, -0.0401])\n",
      "tf.8.attn2.to_q                tensor([ 0.0345,  0.0982,  0.0686,  0.0269, -0.0827, -0.0614,  0.0812, -0.0768, -0.0240,  0.0416])\n",
      "tf.8.attn2.to_k                tensor([ 0.0040, -0.0036,  0.0164,  0.0250,  0.0110,  0.0274, -0.0204,  0.0166,  0.0070,  0.0145])\n",
      "tf.8.attn2.to_v                tensor([ 1.0492e-02,  1.4649e-02, -1.3898e-02, -8.1911e-03, -1.4835e-03, -6.4739e-03,  3.6117e-03,  3.2890e-06, -1.9819e-02,  5.6907e-03])\n",
      "tf.8.attn2.to_out.0            tensor([ 0.0192, -0.0187, -0.0004, -0.0206, -0.0552,  0.0342, -0.0363,  0.0572,  0.0261, -0.0172])\n",
      "tf.8.ff.net.0.proj             tensor([-0.0628, -0.0587,  0.0719, -0.0783, -0.0295, -0.0302, -0.0365, -0.0001, -0.0235, -0.0281])\n",
      "tf.8.ff.net.2                  tensor([-0.0222,  0.0234,  0.0366, -0.0248, -0.0022,  0.0319,  0.0242,  0.0016, -0.0298, -0.0214])\n",
      "tf.9.attn1.to_q                tensor([ 0.0191,  0.0569, -0.0841,  0.0027,  0.0642,  0.0306, -0.0130, -0.0510, -0.0567,  0.0564])\n",
      "tf.9.attn1.to_k                tensor([-0.0563,  0.0572, -0.0488, -0.0343, -0.0647, -0.0371,  0.0827,  0.0287, -0.0068,  0.0487])\n",
      "tf.9.attn1.to_v                tensor([ 0.0371,  0.0103,  0.0680,  0.0209,  0.0728, -0.0445, -0.0331,  0.0732,  0.0510,  0.0362])\n",
      "tf.9.attn1.to_out.0            tensor([-0.0583,  0.0066, -0.0710,  0.0286, -0.0095, -0.0723,  0.0115,  0.0120, -0.0436,  0.0176])\n",
      "tf.9.attn2.to_q                tensor([ 0.0777, -0.0406, -0.0506,  0.0949, -0.0030,  0.0127, -0.0147,  0.0177, -0.0482,  0.0331])\n",
      "tf.9.attn2.to_k                tensor([-0.0018,  0.0172,  0.0076,  0.0013, -0.0051,  0.0168, -0.0128, -0.0106, -0.0242, -0.0103])\n",
      "tf.9.attn2.to_v                tensor([ 0.0075,  0.0104, -0.0093,  0.0244,  0.0189, -0.0222, -0.0058, -0.0070, -0.0166,  0.0122])\n",
      "tf.9.attn2.to_out.0            tensor([-0.0359, -0.0634, -0.0363, -0.0275, -0.0245,  0.0064, -0.0743,  0.0134, -0.0397,  0.0460])\n",
      "tf.9.ff.net.0.proj             tensor([ 0.0693,  0.0393,  0.0809,  0.0027,  0.0659,  0.0797, -0.0567, -0.0019,  0.0492,  0.0721])\n",
      "tf.9.ff.net.2                  tensor([-0.0090,  0.0471, -0.0200,  0.0027, -0.0005,  0.0275,  0.0291, -0.0180, -0.0114, -0.0166])\n",
      "proj_out                       tensor([ 0.0132, -0.0043,  0.0045,  0.0054, -0.0034, -0.0144,  0.0111, -0.0111,  0.0072,  0.0056])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,b in enumerate(ctrl_down_subblocks):\n",
    "    print(f'>>>>>> Subblock {i}:')\n",
    "    for m in b:\n",
    "        print('>>',cls_name(m))\n",
    "        for p in param_parts[cls_name(m)]:\n",
    "            if i<3 and get_tf_idx(p)>=0: continue # 1st level has no attentions\n",
    "            if i<6 and get_tf_idx(p)>=2: continue # 2nd level attentions with only 2 transformers\n",
    "            first_values = attr(m,p).weight.flatten().cpu().detach()[:10]\n",
    "            p = p.replace('transformer_blocks','tf')\n",
    "            print(f'{p:<30} {first_values}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e7e50c-c479-4c08-8cf3-75d25237bda6",
   "metadata": {},
   "source": [
    "**A:** No, none of the downblocks is empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f65912-f249-4af6-ae1c-f5ccd88d91e3",
   "metadata": {},
   "source": [
    "Also, the (non-attention) weights on cloud are exactly identical:\n",
    "```\n",
    "Subblock 0 - ResBlock:\n",
    "conv1                tensor([-0.0225,  0.0219, -0.0374,  0.0109,  0.0028,  0.0212,  0.0164, -0.0133, -0.0110, -0.0135])\n",
    "time_emb_proj        tensor([-0.0152,  0.0160, -0.0025,  0.0155, -0.0167,  0.0045, -0.0243, -0.0039,  0.0127, -0.0094])\n",
    "conv2                tensor([-0.0180, -0.0231, -0.0207, -0.0339, -0.0294, -0.0046, -0.0047, -0.0194,  0.0065,  0.0078])\n",
    "conv_shortcut        tensor([ 0.0269,  0.0493, -0.0816,  0.0297, -0.0484,  0.0082,  0.0849, -0.0301, -0.1588,  0.0405])\n",
    "\n",
    "Subblock 1 - ResBlock:\n",
    "conv1                tensor([ 0.0023, -0.0076, -0.0082,  0.0090,  0.0185,  0.0055, -0.0044, -0.0300,  0.0023,  0.0091])\n",
    "time_emb_proj        tensor([-0.0142,  0.0132, -0.0026,  0.0191, -0.0068,  0.0182, -0.0076,  0.0256,  0.0187, -0.0159])\n",
    "conv2                tensor([ 0.0116,  0.0100, -0.0316, -0.0018,  0.0002, -0.0166, -0.0173,  0.0020, -0.0167, -0.0232])\n",
    "conv_shortcut        tensor([ 0.0024, -0.0124, -0.0311, -0.0614, -0.0990, -0.0994, -0.0391, -0.1036,  0.0628,  0.0304])\n",
    "\n",
    "Subblock 2 - Downsample:\n",
    "conv                 tensor([ 0.0014, -0.0107, -0.0256, -0.0322, -0.0727, -0.0276, -0.0175, -0.0603, -0.0378, -0.0008])\n",
    "\n",
    "Subblock 3 - ResBlock:\n",
    "conv1                tensor([ 0.0038, -0.0225, -0.0137,  0.0118,  0.0261,  0.0445,  0.0046,  0.0254,  0.0123,  0.0196])\n",
    "time_emb_proj        tensor([ 0.0029,  0.0281,  0.0008,  0.0192,  0.0290,  0.0038, -0.0110,  0.0048, -0.0119,  0.0320])\n",
    "conv2                tensor([-0.0015,  0.0039,  0.0196,  0.0022,  0.0137,  0.0201,  0.0038,  0.0015,  0.0076, -0.0116])\n",
    "conv_shortcut        tensor([ 0.0105,  0.0405, -0.0068, -0.0370,  0.0426, -0.0199,  0.0712, -0.0207, -0.0158,  0.0146])\n",
    "\n",
    "Subblock 4 - ResBlock:\n",
    "conv1                tensor([ 0.0125,  0.0231,  0.0078,  0.0088,  0.0212, -0.0005,  0.0063, -0.0082, -0.0049, -0.0073])\n",
    "time_emb_proj        tensor([-0.0077,  0.0140, -0.0198, -0.0020,  0.0209,  0.0031,  0.0255,  0.0376,  0.0209,  0.0419])\n",
    "conv2                tensor([ 0.0068,  0.0122,  0.0078, -0.0034,  0.0013,  0.0023, -0.0065,  0.0048,  0.0061, -0.0060])\n",
    "conv_shortcut        tensor([ 0.0409,  0.0009,  0.0166,  0.0155, -0.0032,  0.0379, -0.0255,  0.0058, -0.0301,  0.0224])\n",
    "\n",
    "Subblock 5 - Downsample:\n",
    "conv                 tensor([-0.0161, -0.0169, -0.0305, -0.0299, -0.0325, -0.0410, -0.0279, -0.0187, -0.0390,  0.0234])\n",
    "\n",
    "Subblock 6 - ResBlock:\n",
    "conv1                tensor([ 0.0206,  0.0154,  0.0105,  0.0079,  0.0243,  0.0134,  0.0070,  0.0179,  0.0059, -0.0110])\n",
    "time_emb_proj        tensor([-1.9000e-02,  1.4582e-02, -2.6406e-02,  2.2612e-02,  1.5059e-05,  3.3383e-02,  1.0330e-02, -1.6467e-03,  8.3065e-03, -2.8895e-03])\n",
    "conv2                tensor([ 0.0040,  0.0018,  0.0039, -0.0016, -0.0038, -0.0039, -0.0098, -0.0114, -0.0120,  0.0087])\n",
    "conv_shortcut        tensor([-0.0092,  0.0251,  0.0145, -0.0126, -0.0410,  0.0210, -0.0353, -0.0262, -0.0098, -0.0207])\n",
    "\n",
    "Subblock 7 - ResBlock:\n",
    "conv1                tensor([-9.8836e-05,  1.3444e-02,  1.0174e-02,  4.2135e-03,  5.0547e-03,  4.8702e-03, -7.1490e-03,  6.3899e-03,  8.2130e-03,  5.3117e-03])\n",
    "time_emb_proj        tensor([-0.0073,  0.0077, -0.0156,  0.0150, -0.0060,  0.0162,  0.0031, -0.0053,  0.0093, -0.0236])\n",
    "conv2                tensor([ 0.0107, -0.0005, -0.0032,  0.0017, -0.0033, -0.0045,  0.0066,  0.0030,  0.0046, -0.0098])\n",
    "conv_shortcut        tensor([-0.0185, -0.0004, -0.0143,  0.0176,  0.0277,  0.0025, -0.0249, -0.0079,  0.0086,  0.0037])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01395133-acad-439c-9936-5cd6c20456f1",
   "metadata": {},
   "source": [
    "Hmmmmmm...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb43fc-2907-4e0a-8f00-ed0090e528e5",
   "metadata": {},
   "source": [
    "Sanity check: Is the local bias non-empty?\n",
    "\n",
    "Edit: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ddd21083-ab5c-452d-8daf-89ecfced62f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subblock 0 - ResnetBlock2D:\n",
      "conv1                tensor([-0.0062,  0.0141, -0.0095, -0.0061,  0.0170, -0.0133, -0.0058, -0.0010, -0.0014,  0.0013])\n",
      "time_emb_proj        tensor([-0.0074, -0.0122,  0.0255,  0.0128,  0.0008, -0.0081,  0.0084, -0.0132, -0.0229,  0.0129])\n",
      "conv2                tensor([-0.0061, -0.0048, -0.0087,  0.0158,  0.0009, -0.0058, -0.0021, -0.0009, -0.0136,  0.0085])\n",
      "conv_shortcut        tensor([-0.0050, -0.0129, -0.0212,  0.0425, -0.0277,  0.0116, -0.0132,  0.0346,  0.0079, -0.0265])\n",
      "\n",
      "Subblock 1 - ResnetBlock2D:\n",
      "conv1                tensor([-0.0027,  0.0005, -0.0158,  0.0097, -0.0110,  0.0160,  0.0056,  0.0125,  0.0093, -0.0074])\n",
      "time_emb_proj        tensor([ 0.0102,  0.0091,  0.0214,  0.0138, -0.0254, -0.0157, -0.0252, -0.0064, -0.0081,  0.0197])\n",
      "conv2                tensor([ 0.0032,  0.0020, -0.0006, -0.0114,  0.0030,  0.0048,  0.0055,  0.0015,  0.0002, -0.0041])\n",
      "conv_shortcut        tensor([ 0.0400,  0.0060, -0.0259, -0.0382,  0.0090,  0.0439,  0.0229, -0.0307, -0.0274, -0.0543])\n",
      "\n",
      "Subblock 2 - Downsample2D:\n",
      "conv                 tensor([ 0.0362, -0.0134,  0.0077, -0.0310,  0.0306, -0.0224, -0.0158,  0.0294, -0.0319,  0.0094])\n",
      "\n",
      "Subblock 3 - ResnetBlock2D:\n",
      "conv1                tensor([-0.0077,  0.0133,  0.0152, -0.0135, -0.0021, -0.0162,  0.0276, -0.0379, -0.0212, -0.0067])\n",
      "time_emb_proj        tensor([ 0.0166,  0.0136, -0.0186, -0.0068, -0.0180, -0.0051,  0.0439, -0.0240, -0.0069,  0.0033])\n",
      "conv2                tensor([ 2.5702e-03, -2.3700e-03, -1.2646e-03,  3.9678e-03, -2.3217e-03, -6.2726e-03,  1.0730e-02, -5.2188e-05,  1.4820e-02,  1.6954e-03])\n",
      "conv_shortcut        tensor([-0.0035, -0.0215, -0.0182, -0.0022,  0.0149, -0.0286,  0.0385,  0.0343,  0.0644,  0.0230])\n",
      "\n",
      "Subblock 4 - ResnetBlock2D:\n",
      "conv1                tensor([-0.0033,  0.0038, -0.0302,  0.0125,  0.0069,  0.0041,  0.0055,  0.0043,  0.0130, -0.0003])\n",
      "time_emb_proj        tensor([-0.0178, -0.0041, -0.0006,  0.0417,  0.0117, -0.0190,  0.0144, -0.0214, -0.0013, -0.0099])\n",
      "conv2                tensor([ 0.0018,  0.0089, -0.0038,  0.0121,  0.0016,  0.0152, -0.0092,  0.0071, -0.0136, -0.0207])\n",
      "conv_shortcut        tensor([ 0.0316, -0.0259, -0.0098,  0.0348,  0.0027,  0.0295, -0.0299,  0.0192, -0.0326, -0.0364])\n",
      "\n",
      "Subblock 5 - Downsample2D:\n",
      "conv                 tensor([-0.0168,  0.0036, -0.0008, -0.0154,  0.0146, -0.0244,  0.0022, -0.0051,  0.0218,  0.0094])\n",
      "\n",
      "Subblock 6 - ResnetBlock2D:\n",
      "conv1                tensor([-0.0111, -0.0280,  0.0065,  0.0187,  0.0169,  0.0091, -0.0182, -0.0290, -0.0088, -0.0183])\n",
      "time_emb_proj        tensor([-0.0012, -0.0405,  0.0006,  0.0222, -0.0090,  0.0218, -0.0139, -0.0291,  0.0088,  0.0043])\n",
      "conv2                tensor([-0.0171,  0.0010,  0.0049,  0.0099, -0.0110,  0.0287,  0.0253, -0.0285,  0.0103, -0.0267])\n",
      "conv_shortcut        tensor([ 0.0065, -0.0067, -0.0008,  0.0457, -0.0197,  0.0307,  0.0395, -0.0352,  0.0129, -0.0412])\n",
      "\n",
      "Subblock 7 - ResnetBlock2D:\n",
      "conv1                tensor([ 0.0047,  0.0074,  0.0062, -0.0084, -0.0264, -0.0093,  0.0163,  0.0227,  0.0177, -0.0016])\n",
      "time_emb_proj        tensor([ 0.0267, -0.0094,  0.0052,  0.0044, -0.0434, -0.0076,  0.0416,  0.0226,  0.0071, -0.0069])\n",
      "conv2                tensor([ 0.0197, -0.0123,  0.0054,  0.0051,  0.0057,  0.0107, -0.0066, -0.0014,  0.0007, -0.0128])\n",
      "conv_shortcut        tensor([ 0.0197, -0.0295,  0.0038,  0.0138,  0.0210,  0.0262, -0.0223, -0.0168, -0.0101, -0.0376])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,m in enumerate(ctrl_down_subblocks):\n",
    "    m = m[0] # unwrap EmbedSequential\n",
    "    print(f'Subblock {i} - {cls_name(m)}:')\n",
    "    for p in param_parts[cls_name(m)]:\n",
    "        first_values = getattr(m,p).bias.flatten().cpu().detach()[:10]\n",
    "        print(f'{p:<20} {first_values}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ac0b4f-3eaa-4373-accf-5c94c6a2b917",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5ee82-1f6e-4582-afdd-e51336990e06",
   "metadata": {},
   "source": [
    "Sanity check: base and ctrl have same number of subblocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89a7ad18-82ad-4519-9976-0105173f6157",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_down_subblocks = to_sub_blocks(cnxs.base_model.down_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a489e3c-b0d3-424d-b8a8-0e622529b6d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(base_down_subblocks)==len(ctrl_down_subblocks)\n",
    "len(base_down_subblocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98319442-edd1-460e-9099-1f40177b3abd",
   "metadata": {},
   "source": [
    "Sanity check: base and ctrl have same number of transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8fec8557-c290-434f-9624-a617128881db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base subblock 3 has 2 transformers\n",
      "base subblock 4 has 2 transformers\n",
      "base subblock 6 has 10 transformers\n",
      "base subblock 7 has 10 transformers\n",
      "\n",
      "ctrl subblock 3 has 2 transformers\n",
      "ctrl subblock 4 has 2 transformers\n",
      "ctrl subblock 6 has 10 transformers\n",
      "ctrl subblock 7 has 10 transformers\n"
     ]
    }
   ],
   "source": [
    "for i, b in enumerate(base_down_subblocks):\n",
    "    if len(b)==1: continue # no 2nd part, which would be the attention\n",
    "    print('base subblock',i,'has',len(b[1].transformer_blocks),'transformers')\n",
    "print()\n",
    "for i, b in enumerate(ctrl_down_subblocks):\n",
    "    if len(b)==1: continue # no 2nd part, which would be the attention\n",
    "    print('ctrl subblock',i,'has',len(b[1].transformer_blocks),'transformers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5158a298-3aec-45ee-9a6b-731243bfa815",
   "metadata": {},
   "source": [
    "Okay, I've saved a detailled debug log (at level subblock minus 1). Let's confirm none of those is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d4fe8789-1145-4cbb-b6bb-04b9ae8585ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('intermediate_output/subblock-minus-1/cloud_detailled_debug_log.pkl', 'rb') as f:\n",
    "    dlog_c = pickle.load(f)\n",
    "with open('intermediate_output/subblock-minus-1/local_detailled_debug_log.pkl', 'rb') as f:\n",
    "    dlog_l = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "efb2d347-c8a7-4109-b974-9552c1db816a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "882b9149-a0e8-473f-a8f5-e814113ff0e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1               [2, 32, 96, 96]     tensor([-0.828, -0.465, -0.597, -0.728, -0.992,  0.050, -0.500, -1.920, -1.507, -0.325])\n",
      "add time_emb_proj   [2, 32, 96, 96]     tensor([-0.434, -0.070, -0.202, -0.334, -0.597,  0.445, -0.106, -1.526, -1.112,  0.070])\n",
      "conv2               [2, 32, 96, 96]     tensor([-0.201, -0.217, -0.178, -0.103, -0.235, -0.112, -0.032,  0.107, -0.073, -0.313])\n",
      "add conv_shortcut   [2, 32, 96, 96]     tensor([-0.579, -0.396, -0.193, -0.662, -0.056, -0.110, -0.406,  0.084, -0.649, -1.121])\n",
      "conv1               [2, 32, 96, 96]     tensor([-0.493, -1.457, -1.604, -1.583, -1.943, -1.831, -2.015, -1.617, -1.150, -1.342])\n",
      "add time_emb_proj   [2, 32, 96, 96]     tensor([ 0.781, -0.184, -0.331, -0.310, -0.670, -0.557, -0.742, -0.344,  0.124, -0.068])\n",
      "conv2               [2, 32, 96, 96]     tensor([-0.110, -0.188,  0.008, -0.117,  0.199, -0.032,  0.062,  0.046,  0.088, -0.130])\n",
      "add conv_shortcut   [2, 32, 96, 96]     tensor([-0.587, -0.252,  0.140, -0.243,  0.250, -0.864, -0.547, -0.534, -0.110,  0.091])\n",
      "conv                [2, 32, 48, 48]     tensor([ 1.093,  1.090,  1.386,  3.094, -0.006,  0.524,  0.264,  1.049, -0.191,  0.467])\n",
      "conv1               [2, 64, 48, 48]     tensor([-1.748, -3.139, -2.902, -3.853, -3.844, -3.081, -3.067, -1.979, -3.242, -3.807])\n",
      "add time_emb_proj   [2, 64, 48, 48]     tensor([-7.731, -9.121, -8.885, -9.836, -9.827, -9.064, -9.050, -7.962, -9.224, -9.790])\n",
      "conv2               [2, 64, 48, 48]     tensor([-0.177, -0.091,  0.020,  0.127,  0.179,  0.128,  0.108,  0.046, -0.055, -0.228])\n",
      "add conv_shortcut   [2, 64, 48, 48]     tensor([ 0.528,  1.443,  1.007,  1.156,  0.685,  1.225,  1.173,  1.688,  0.591, -0.254])\n",
      "proj_in             [2, 2304, 64]       tensor([ 0.182, -0.099, -0.638, -0.160, -0.058,  0.172,  0.521,  0.322,  0.082, -0.222])\n",
      "attn1               [2, 2304, 64]       tensor([-0.194, -0.057, -0.303, -0.127,  0.008, -0.210, -0.220, -0.153,  0.252, -0.347])\n",
      "add attn1           [2, 2304, 64]       tensor([-0.012, -0.156, -0.941, -0.286, -0.051, -0.039,  0.300,  0.169,  0.335, -0.569])\n",
      "norm2               [2, 2304, 64]       tensor([ 0.018, -0.315, -1.982, -0.573, -0.070, -0.051,  0.654,  0.411,  0.733, -1.191])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 2304, 64]       tensor([ 5.909, -7.288, -4.924,  3.281, -3.738, -4.070,  3.967,  0.425, -4.209, -7.630])\n",
      "add attn2           [2, 2304, 64]       tensor([ 5.896, -7.444, -5.865,  2.994, -3.788, -4.109,  4.268,  0.593, -3.874, -8.199])\n",
      "ff                  [2, 2304, 64]       tensor([ 0.091,  0.176, -0.020,  0.095, -0.108, -0.446, -0.139, -0.045,  0.317, -0.230])\n",
      "add ff              [2, 2304, 64]       tensor([ 5.987, -7.269, -5.885,  3.089, -3.896, -4.555,  4.128,  0.549, -3.557, -8.428])\n",
      "attn1               [2, 2304, 64]       tensor([-0.114, -0.230, -0.119, -0.175, -0.382,  0.409, -0.060, -0.044,  0.138, -0.267])\n",
      "add attn1           [2, 2304, 64]       tensor([ 5.874, -7.499, -6.004,  2.914, -4.278, -4.146,  4.068,  0.505, -3.420, -8.695])\n",
      "norm2               [2, 2304, 64]       tensor([ 1.306, -1.249, -1.006,  0.777, -0.604, -0.661,  1.002,  0.250, -0.443, -1.499])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 2304, 64]       tensor([-0.295, -0.344,  0.558, -0.655,  1.192,  0.984, -0.046,  1.328, -0.261, -0.079])\n",
      "add attn2           [2, 2304, 64]       tensor([ 5.579, -7.843, -5.446,  2.259, -3.086, -3.162,  4.022,  1.833, -3.681, -8.775])\n",
      "ff                  [2, 2304, 64]       tensor([ 0.224,  0.326, -0.404,  0.515, -0.789,  0.572, -0.625,  0.456,  0.354,  0.657])\n",
      "add ff              [2, 2304, 64]       tensor([ 5.802, -7.517, -5.850,  2.774, -3.875, -2.589,  3.397,  2.289, -3.327, -8.118])\n",
      "proj_out            [2, 64, 48, 48]     tensor([-0.415,  0.100, -0.088,  1.489,  0.236,  0.886,  0.143,  0.703, -0.984, -0.712])\n",
      "conv1               [2, 64, 48, 48]     tensor([-1.592, -3.079, -3.568, -3.291, -3.529, -2.744, -2.083, -1.585, -2.152, -2.558])\n",
      "add time_emb_proj   [2, 64, 48, 48]     tensor([-3.777, -5.264, -5.753, -5.476, -5.714, -4.929, -4.268, -3.770, -4.337, -4.743])\n",
      "conv2               [2, 64, 48, 48]     tensor([-0.460, -0.693, -0.760, -0.730, -0.690, -0.643, -0.626, -0.662, -0.759, -0.787])\n",
      "add conv_shortcut   [2, 64, 48, 48]     tensor([ 0.498, -0.564, -2.045, -1.976, -0.739, -0.240, -2.281,  0.159, -0.836, -1.067])\n",
      "proj_in             [2, 2304, 64]       tensor([ 0.009, -0.688,  0.767, -1.404,  0.092, -0.587,  0.864,  0.626,  0.026,  0.534])\n",
      "attn1               [2, 2304, 64]       tensor([-1.365, -0.155, -0.267, -0.808,  0.813, -1.096, -1.497, -0.301,  0.927, -0.423])\n",
      "add attn1           [2, 2304, 64]       tensor([-1.356, -0.842,  0.499, -2.212,  0.905, -1.682, -0.634,  0.325,  0.953,  0.111])\n",
      "norm2               [2, 2304, 64]       tensor([-1.252, -0.817,  0.462, -2.083,  0.781, -1.587, -0.569,  0.279,  0.831,  0.104])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 2304, 64]       tensor([-3.021,  9.975,  0.982, -7.147,  2.548,  2.667, -5.144, -3.964,  5.444, -9.425])\n",
      "add attn2           [2, 2304, 64]       tensor([-4.377,  9.133,  1.481, -9.359,  3.453,  0.985, -5.778, -3.639,  6.398, -9.315])\n",
      "ff                  [2, 2304, 64]       tensor([ 0.514, -0.261, -0.217, -0.069,  0.251, -0.158,  0.497,  0.631,  0.085,  0.263])\n",
      "add ff              [2, 2304, 64]       tensor([-3.863,  8.872,  1.265, -9.428,  3.704,  0.826, -5.280, -3.008,  6.483, -9.051])\n",
      "attn1               [2, 2304, 64]       tensor([-0.143,  0.054,  0.850, -0.412,  0.693, -0.251,  0.276,  0.363,  0.068, -0.207])\n",
      "add attn1           [2, 2304, 64]       tensor([-4.005,  8.926,  2.115, -9.840,  4.397,  0.575, -5.004, -2.644,  6.552, -9.259])\n",
      "norm2               [2, 2304, 64]       tensor([-0.745,  0.886,  0.070, -1.452,  0.363, -0.132, -0.846, -0.576,  0.624, -1.353])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 2304, 64]       tensor([-0.065, -0.757,  0.456,  0.061,  0.026, -0.261,  0.410, -0.214,  0.560,  0.162])\n",
      "add attn2           [2, 2304, 64]       tensor([-4.071,  8.169,  2.571, -9.779,  4.423,  0.314, -4.594, -2.858,  7.112, -9.096])\n",
      "ff                  [2, 2304, 64]       tensor([ 1.084, -0.829,  0.091, -0.168, -0.138, -0.551,  0.344,  0.784, -0.101,  0.225])\n",
      "add ff              [2, 2304, 64]       tensor([-2.987,  7.340,  2.662, -9.947,  4.285, -0.238, -4.250, -2.074,  7.011, -8.871])\n",
      "proj_out            [2, 64, 48, 48]     tensor([2.742, 1.723, 0.222, 0.241, 1.521, 2.050, 0.031, 2.403, 1.437, 1.234])\n",
      "conv                [2, 64, 24, 24]     tensor([ 8.954, 12.050, 12.247,  9.000,  7.119,  1.103,  7.829,  7.626,  6.827,  4.924])\n",
      "conv1               [2, 128, 24, 24]    tensor([-3.197, -6.468, -7.290, -6.562, -3.850, -3.420, -3.922, -6.120, -5.538, -3.300])\n",
      "add time_emb_proj   [2, 128, 24, 24]    tensor([ -7.023, -10.294, -11.116, -10.388,  -7.676,  -7.246,  -7.748,  -9.946,  -9.364,  -7.126])\n",
      "conv2               [2, 128, 24, 24]    tensor([-0.332, -0.322,  0.040,  0.167,  0.070, -0.146, -0.163, -0.045, -0.135, -0.432])\n",
      "add conv_shortcut   [2, 128, 24, 24]    tensor([-7.188, -6.590, -6.705, -3.726, -1.810, -3.595, -6.303, -7.161, -4.585, -4.253])\n",
      "proj_in             [2, 576, 128]       tensor([ 0.791, -1.260,  0.151,  1.766, -0.304, -3.144, -0.104, -1.546, -2.075, -1.434])\n",
      "attn1               [2, 576, 128]       tensor([ 2.061, -3.171,  2.579, -2.098, -2.209, -3.046, -3.147,  1.073, -1.189, -4.548])\n",
      "add attn1           [2, 576, 128]       tensor([ 2.852, -4.431,  2.730, -0.333, -2.513, -6.190, -3.251, -0.473, -3.264, -5.982])\n",
      "norm2               [2, 576, 128]       tensor([ 0.814, -1.406,  0.803, -0.157, -0.810, -1.953, -1.046, -0.199, -1.051, -1.897])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([ 5.766, -6.976,  7.021, -8.504, -4.664,  3.573,  0.366,  1.629,  1.717, -4.886])\n",
      "add attn2           [2, 576, 128]       tensor([  8.617, -11.407,   9.751,  -8.836,  -7.177,  -2.617,  -2.884,   1.156,  -1.547, -10.869])\n",
      "ff                  [2, 576, 128]       tensor([ 0.099, -0.150,  0.344, -0.273,  0.068,  0.159, -0.438,  0.204, -0.232, -0.108])\n",
      "add ff              [2, 576, 128]       tensor([  8.717, -11.557,  10.095,  -9.109,  -7.109,  -2.458,  -3.322,   1.360,  -1.779, -10.976])\n",
      "attn1               [2, 576, 128]       tensor([ 1.168, -3.679,  3.388,  2.013, -0.191, -3.963, -0.523,  4.096,  0.621, -0.369])\n",
      "add attn1           [2, 576, 128]       tensor([  9.885, -15.236,  13.483,  -7.096,  -7.301,  -6.421,  -3.846,   5.456,  -1.158, -11.345])\n",
      "norm2               [2, 576, 128]       tensor([ 0.613, -1.307,  0.898, -0.691, -0.694, -0.627, -0.440,  0.291, -0.231, -1.029])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([  1.391,   3.065,   1.135,   0.328,  -6.509, -11.494,   5.463,  -4.403,   6.478,  -4.080])\n",
      "add attn2           [2, 576, 128]       tensor([ 11.276, -12.171,  14.618,  -6.768, -13.810, -17.915,   1.618,   1.053,   5.320, -15.425])\n",
      "ff                  [2, 576, 128]       tensor([ 0.105,  0.007, -0.097, -0.114, -0.211,  0.100, -0.021,  0.148, -0.142, -0.116])\n",
      "add ff              [2, 576, 128]       tensor([ 11.381, -12.164,  14.521,  -6.882, -14.021, -17.815,   1.597,   1.201,   5.178, -15.541])\n",
      "attn1               [2, 576, 128]       tensor([ 0.254,  0.125,  0.458,  0.938, -0.578, -2.257,  1.230,  1.260,  0.462,  0.371])\n",
      "add attn1           [2, 576, 128]       tensor([ 11.635, -12.039,  14.979,  -5.944, -14.599, -20.071,   2.827,   2.461,   5.640, -15.171])\n",
      "norm2               [2, 576, 128]       tensor([ 0.552, -0.864,  0.770, -0.466, -0.983, -1.241,  0.045, -0.004,  0.206, -0.964])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([ 0.233,  1.142, -1.504, -1.805, -0.165,  0.383, -0.530, -0.418,  0.037, -0.498])\n",
      "add attn2           [2, 576, 128]       tensor([ 11.868, -10.897,  13.474,  -7.749, -14.764, -19.688,   2.296,   2.043,   5.677, -15.669])\n",
      "ff                  [2, 576, 128]       tensor([-0.067,  0.199, -0.032, -0.015, -0.127,  0.148,  0.130,  0.048, -0.036, -0.047])\n",
      "add ff              [2, 576, 128]       tensor([ 11.802, -10.698,  13.442,  -7.764, -14.891, -19.540,   2.426,   2.091,   5.641, -15.716])\n",
      "attn1               [2, 576, 128]       tensor([-0.223, -0.147,  0.502, -0.095,  0.195, -0.169,  0.250,  0.017,  0.185,  0.384])\n",
      "add attn1           [2, 576, 128]       tensor([ 11.579, -10.845,  13.944,  -7.859, -14.697, -19.709,   2.676,   2.108,   5.826, -15.332])\n",
      "norm2               [2, 576, 128]       tensor([ 0.560, -0.707,  0.709, -0.570, -0.970, -1.240,  0.019,  0.006,  0.238, -0.972])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-2.908,  6.947,  0.333,  2.371,  3.181, -6.047,  3.907, -4.839, -3.541,  2.279])\n",
      "add attn2           [2, 576, 128]       tensor([  8.671,  -3.898,  14.277,  -5.488, -11.516, -25.756,   6.584,  -2.731,   2.284, -13.052])\n",
      "ff                  [2, 576, 128]       tensor([-0.014, -0.051,  0.040,  0.179,  0.107,  0.040,  0.155,  0.019, -0.280, -0.147])\n",
      "add ff              [2, 576, 128]       tensor([  8.657,  -3.949,  14.317,  -5.309, -11.408, -25.717,   6.738,  -2.712,   2.004, -13.199])\n",
      "attn1               [2, 576, 128]       tensor([-0.020,  0.325, -0.186,  0.184,  0.114, -0.206,  0.037,  0.035, -0.381, -0.215])\n",
      "add attn1           [2, 576, 128]       tensor([  8.637,  -3.625,  14.131,  -5.125, -11.294, -25.923,   6.775,  -2.677,   1.624, -13.414])\n",
      "norm2               [2, 576, 128]       tensor([ 0.397, -0.265,  0.701, -0.364, -0.684, -1.520,  0.318, -0.196,  0.002, -0.825])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([ -9.682,   9.670,   3.052,  -8.847, -26.301,   1.261, -12.291,  -0.254,  -2.757, -21.523])\n",
      "add attn2           [2, 576, 128]       tensor([ -1.045,   6.046,  17.183, -13.971, -37.595, -24.661,  -5.516,  -2.932,  -1.133, -34.937])\n",
      "ff                  [2, 576, 128]       tensor([-0.164,  0.200, -0.174, -0.048,  0.185,  0.111, -0.266, -0.064, -0.358, -0.087])\n",
      "add ff              [2, 576, 128]       tensor([ -1.209,   6.246,  17.009, -14.019, -37.410, -24.550,  -5.783,  -2.995,  -1.491, -35.024])\n",
      "attn1               [2, 576, 128]       tensor([-0.616,  0.591,  0.827,  0.231,  1.500,  0.175,  1.082, -0.524,  0.135,  0.362])\n",
      "add attn1           [2, 576, 128]       tensor([ -1.825,   6.836,  17.836, -13.788, -35.910, -24.375,  -4.701,  -3.519,  -1.356, -34.662])\n",
      "norm2               [2, 576, 128]       tensor([-0.094,  0.349,  0.894, -0.637, -1.705, -1.176, -0.212, -0.157, -0.036, -1.675])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([ -8.706,   4.243,   3.779,   1.541,  -0.879, -13.555,  -4.755,  15.682,   4.411,  -1.551])\n",
      "add attn2           [2, 576, 128]       tensor([-10.531,  11.080,  21.615, -12.247, -36.789, -37.931,  -9.456,  12.163,   3.055, -36.213])\n",
      "ff                  [2, 576, 128]       tensor([-2.322e-01,  2.280e-01, -1.027e-01, -8.465e-02,  2.078e-02,  1.414e-01, -6.253e-02, -8.300e-05, -2.800e-01, -1.008e-01])\n",
      "add ff              [2, 576, 128]       tensor([-10.763,  11.308,  21.513, -12.332, -36.769, -37.789,  -9.519,  12.163,   2.775, -36.314])\n",
      "attn1               [2, 576, 128]       tensor([-0.133, -0.245, -0.697,  0.423,  0.234,  0.131,  0.090,  0.314, -0.345, -0.093])\n",
      "add attn1           [2, 576, 128]       tensor([-10.896,  11.063,  20.816, -11.909, -36.534, -37.658,  -9.428,  12.477,   2.430, -36.407])\n",
      "norm2               [2, 576, 128]       tensor([-0.451,  0.526,  0.925, -0.487, -1.547, -1.571, -0.380,  0.556,  0.138, -1.557])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-0.588, -0.736, -0.817,  1.346, -1.851, -0.122, -1.042,  1.608, -0.382,  0.963])\n",
      "add attn2           [2, 576, 128]       tensor([-11.484,  10.327,  19.998, -10.564, -38.386, -37.780, -10.471,  14.085,   2.048, -35.444])\n",
      "ff                  [2, 576, 128]       tensor([-0.161,  0.433, -0.305,  0.146,  0.130,  0.202, -0.008, -0.102, -0.357,  0.177])\n",
      "add ff              [2, 576, 128]       tensor([-11.645,  10.760,  19.693, -10.417, -38.256, -37.578, -10.478,  13.983,   1.691, -35.266])\n",
      "attn1               [2, 576, 128]       tensor([ 0.101,  0.078, -0.114, -0.008,  0.699, -0.005,  0.324, -0.138, -0.874,  0.231])\n",
      "add attn1           [2, 576, 128]       tensor([-11.544,  10.839,  19.579, -10.425, -37.557, -37.583, -10.154,  13.845,   0.817, -35.035])\n",
      "norm2               [2, 576, 128]       tensor([-0.481,  0.502,  0.896, -0.421, -1.561, -1.558, -0.391,  0.637,  0.077, -1.454])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-0.517,  0.546, -0.775, -0.223,  0.059, -0.047,  0.211, -0.015,  1.005, -0.877])\n",
      "add attn2           [2, 576, 128]       tensor([-12.061,  11.385,  18.804, -10.649, -37.498, -37.630,  -9.943,  13.830,   1.822, -35.912])\n",
      "ff                  [2, 576, 128]       tensor([-0.807, -0.286, -1.185,  1.113,  1.200,  0.409, -0.338,  0.073, -0.710,  0.023])\n",
      "add ff              [2, 576, 128]       tensor([-12.867,  11.099,  17.619,  -9.536, -36.298, -37.220, -10.282,  13.903,   1.111, -35.889])\n",
      "attn1               [2, 576, 128]       tensor([ 0.071,  0.227, -1.006,  0.381,  0.092,  0.089,  0.042,  0.063, -0.277, -0.158])\n",
      "add attn1           [2, 576, 128]       tensor([-12.796,  11.326,  16.613,  -9.155, -36.206, -37.132, -10.239,  13.966,   0.834, -36.047])\n",
      "norm2               [2, 576, 128]       tensor([-0.493,  0.509,  0.755, -0.376, -1.564, -1.573, -0.395,  0.644,  0.074, -1.534])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-0.106, -0.144,  0.009,  0.019, -0.010,  0.288, -0.513,  0.426,  0.549, -0.270])\n",
      "add attn2           [2, 576, 128]       tensor([-12.902,  11.182,  16.622,  -9.136, -36.216, -36.844, -10.753,  14.392,   1.383, -36.317])\n",
      "ff                  [2, 576, 128]       tensor([-1.030, -0.159, -0.887,  0.705,  1.164,  0.182, -0.275, -0.176, -0.887,  0.184])\n",
      "add ff              [2, 576, 128]       tensor([-13.932,  11.023,  15.735,  -8.431, -35.051, -36.662, -11.028,  14.216,   0.496, -36.133])\n",
      "attn1               [2, 576, 128]       tensor([-0.117,  0.056, -0.427,  0.231,  0.229, -0.369,  0.632,  0.130, -0.396, -0.140])\n",
      "add attn1           [2, 576, 128]       tensor([-14.048,  11.079,  15.308,  -8.200, -34.822, -37.031, -10.396,  14.346,   0.100, -36.273])\n",
      "norm2               [2, 576, 128]       tensor([-0.566,  0.525,  0.721, -0.310, -1.464, -1.583, -0.408,  0.679,  0.026, -1.551])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-0.126, -0.309, -0.261,  0.149, -0.422, -0.301, -0.133,  0.150,  0.023,  0.019])\n",
      "add attn2           [2, 576, 128]       tensor([-14.174,  10.770,  15.047,  -8.052, -35.244, -37.332, -10.529,  14.496,   0.123, -36.253])\n",
      "ff                  [2, 576, 128]       tensor([-0.944,  0.179, -0.768,  0.361,  0.717,  0.135, -0.108, -0.147, -0.654, -0.106])\n",
      "add ff              [2, 576, 128]       tensor([-15.118,  10.950,  14.279,  -7.691, -34.527, -37.197, -10.637,  14.349,  -0.531, -36.359])\n",
      "proj_out            [2, 128, 24, 24]    tensor([-0.458, -0.167,  0.011,  2.655,  4.616,  3.151,  0.359, -0.297,  2.058,  2.473])\n",
      "conv1               [2, 128, 24, 24]    tensor([ -3.207,  -7.571, -11.475,  -9.400,  -5.747,  -3.730,  -4.722,  -7.260,  -7.010,  -4.508])\n",
      "add time_emb_proj   [2, 128, 24, 24]    tensor([-0.448, -4.812, -8.716, -6.641, -2.988, -0.971, -1.963, -4.501, -4.251, -1.749])\n",
      "conv2               [2, 128, 24, 24]    tensor([0.606, 0.647, 0.513, 0.276, 0.301, 0.495, 0.602, 0.513, 0.346, 0.301])\n",
      "add conv_shortcut   [2, 128, 24, 24]    tensor([17.295, 20.873, 16.366, 21.334, 14.976, 13.867, 19.906, 18.700, 17.321, 15.420])\n",
      "proj_in             [2, 576, 128]       tensor([-1.356,  0.639,  0.201, -0.875, -1.191, -1.044, -1.137,  1.685, -0.221,  1.127])\n",
      "attn1               [2, 576, 128]       tensor([-3.249,  1.294,  0.139, -0.613,  0.138, -2.347, -2.622,  1.670,  0.030,  0.889])\n",
      "add attn1           [2, 576, 128]       tensor([-4.606,  1.933,  0.340, -1.488, -1.052, -3.391, -3.759,  3.355, -0.191,  2.016])\n",
      "norm2               [2, 576, 128]       tensor([-2.146,  0.910,  0.188, -0.649, -0.448, -1.590, -1.734,  1.589, -0.052,  0.947])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-15.064,   1.897,   9.459,  -9.837, -28.547,  11.943,   9.145,   6.496, -17.027, -15.988])\n",
      "add attn2           [2, 576, 128]       tensor([-19.670,   3.830,   9.799, -11.324, -29.599,   8.552,   5.386,   9.851, -17.218, -13.972])\n",
      "ff                  [2, 576, 128]       tensor([-0.020,  0.019, -0.013, -0.068,  0.077, -0.019, -0.111,  0.062, -0.093,  0.040])\n",
      "add ff              [2, 576, 128]       tensor([-19.690,   3.848,   9.786, -11.393, -29.522,   8.533,   5.275,   9.913, -17.310, -13.932])\n",
      "attn1               [2, 576, 128]       tensor([-0.435, -1.312,  0.284,  1.028, -1.142,  0.222,  0.294,  0.949, -0.092, -0.330])\n",
      "add attn1           [2, 576, 128]       tensor([-20.124,   2.536,  10.069, -10.365, -30.664,   8.756,   5.569,  10.862, -17.403, -14.262])\n",
      "norm2               [2, 576, 128]       tensor([-0.902,  0.194,  0.529, -0.450, -1.409,  0.468,  0.340,  0.577, -0.772, -0.639])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-20.651,  -4.118,  -3.671, -10.861, -10.040,  31.204,   0.084,  34.331, -24.646,   5.471])\n",
      "add attn2           [2, 576, 128]       tensor([-40.775,  -1.581,   6.398, -21.226, -40.704,  39.960,   5.653,  45.193, -42.049,  -8.791])\n",
      "ff                  [2, 576, 128]       tensor([-0.055, -0.029,  0.035, -0.055, -0.091, -0.018, -0.033,  0.051, -0.101,  0.027])\n",
      "add ff              [2, 576, 128]       tensor([-40.831,  -1.611,   6.433, -21.281, -40.795,  39.942,   5.620,  45.245, -42.150,  -8.764])\n",
      "attn1               [2, 576, 128]       tensor([-0.603, -0.366, -0.511,  0.074,  0.021, -0.691,  0.387, -0.299,  0.512, -0.468])\n",
      "add attn1           [2, 576, 128]       tensor([-41.434,  -1.976,   5.922, -21.207, -40.774,  39.251,   6.007,  44.946, -41.638,  -9.232])\n",
      "norm2               [2, 576, 128]       tensor([-1.124,  0.038,  0.263, -0.525, -1.134,  1.192,  0.248,  1.360, -1.123, -0.193])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-0.305,  1.215,  1.910, -0.454,  2.005,  7.733,  6.010,  7.872, -1.452, -0.178])\n",
      "add attn2           [2, 576, 128]       tensor([-41.738,  -0.762,   7.832, -21.661, -38.769,  46.984,  12.017,  52.818, -43.090,  -9.410])\n",
      "ff                  [2, 576, 128]       tensor([-0.056, -0.052,  0.025, -0.032,  0.004, -0.046, -0.107,  0.020, -0.070, -0.053])\n",
      "add ff              [2, 576, 128]       tensor([-41.795,  -0.813,   7.857, -21.693, -38.765,  46.938,  11.910,  52.838, -43.160,  -9.463])\n",
      "attn1               [2, 576, 128]       tensor([-0.466, -0.013,  0.010, -0.759, -0.301,  0.071, -0.545, -0.176,  0.535,  0.030])\n",
      "add attn1           [2, 576, 128]       tensor([-42.260,  -0.826,   7.867, -22.452, -39.066,  47.009,  11.365,  52.662, -42.625,  -9.432])\n",
      "norm2               [2, 576, 128]       tensor([-1.140,  0.022,  0.275, -0.614, -1.070,  1.410,  0.384,  1.542, -1.153, -0.189])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([  4.767,  -0.795,   0.984,   1.504,   2.036,   0.373,  -3.661,   2.065, -10.515,  -1.279])\n",
      "add attn2           [2, 576, 128]       tensor([-37.493,  -1.621,   8.851, -20.948, -37.030,  47.382,   7.704,  54.727, -53.140, -10.711])\n",
      "ff                  [2, 576, 128]       tensor([-0.062, -0.028,  0.032, -0.126, -0.087,  0.099, -0.227,  0.121, -0.213, -0.031])\n",
      "add ff              [2, 576, 128]       tensor([-37.555,  -1.649,   8.883, -21.074, -37.117,  47.481,   7.478,  54.848, -53.353, -10.741])\n",
      "attn1               [2, 576, 128]       tensor([-2.896e-01,  4.763e-01, -2.876e-04, -7.842e-01, -3.608e-01, -5.767e-01, -2.807e-01, -7.045e-01,  7.578e-01, -4.440e-01])\n",
      "add attn1           [2, 576, 128]       tensor([-37.845,  -1.172,   8.883, -21.858, -37.478,  46.904,   7.197,  54.143, -52.595, -11.185])\n",
      "norm2               [2, 576, 128]       tensor([-0.956,  0.042,  0.288, -0.541, -0.955,  1.326,  0.265,  1.526, -1.377, -0.243])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-4.324, -1.944,  2.650,  0.770, -0.299,  1.363,  1.609, -0.537, -0.859, -1.083])\n",
      "add attn2           [2, 576, 128]       tensor([-42.169,  -3.117,  11.532, -21.089, -37.777,  48.267,   8.806,  53.606, -53.454, -12.268])\n",
      "ff                  [2, 576, 128]       tensor([-0.098, -0.070, -0.110, -0.106, -0.053,  0.047, -0.190,  0.026, -0.182,  0.023])\n",
      "add ff              [2, 576, 128]       tensor([-42.266,  -3.186,  11.423, -21.195, -37.830,  48.314,   8.617,  53.632, -53.635, -12.245])\n",
      "attn1               [2, 576, 128]       tensor([-0.149, -0.180,  0.135, -0.649, -0.295, -0.720, -0.154,  0.018,  0.098, -0.411])\n",
      "add attn1           [2, 576, 128]       tensor([-42.415,  -3.367,  11.557, -21.844, -38.124,  47.594,   8.463,  53.650, -53.537, -12.656])\n",
      "norm2               [2, 576, 128]       tensor([-1.077, -0.029,  0.374, -0.523, -0.981,  1.363,  0.307,  1.542, -1.411, -0.290])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-0.610,  1.741,  1.497,  6.069,  0.732,  0.162, -7.128,  1.524,  0.475,  3.827])\n",
      "add attn2           [2, 576, 128]       tensor([-43.025,  -1.626,  13.054, -15.775, -37.393,  47.756,   1.334,  55.174, -53.062,  -8.829])\n",
      "ff                  [2, 576, 128]       tensor([ 0.019, -0.094, -0.155,  0.085, -0.052, -0.003, -0.237,  0.115, -0.132, -0.019])\n",
      "add ff              [2, 576, 128]       tensor([-43.007,  -1.720,  12.900, -15.689, -37.444,  47.753,   1.097,  55.289, -53.194,  -8.848])\n",
      "attn1               [2, 576, 128]       tensor([-0.409, -0.640,  0.072,  0.151,  0.191, -0.084,  0.167,  0.065,  0.227, -0.500])\n",
      "add attn1           [2, 576, 128]       tensor([-43.416,  -2.360,  12.972, -15.539, -37.254,  47.669,   1.264,  55.353, -52.967,  -9.348])\n",
      "norm2               [2, 576, 128]       tensor([-1.099, -0.016,  0.408, -0.361, -0.932,  1.362,  0.095,  1.570, -1.389, -0.188])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-0.254,  0.094, -0.268, -0.067,  0.180, -0.356,  0.143,  0.039, -0.096,  0.525])\n",
      "add attn2           [2, 576, 128]       tensor([-43.670,  -2.266,  12.704, -15.605, -37.073,  47.313,   1.407,  55.393, -53.063,  -8.823])\n",
      "ff                  [2, 576, 128]       tensor([-0.006, -0.133, -0.160,  0.070, -0.017,  0.010, -0.235,  0.081, -0.272, -0.049])\n",
      "add ff              [2, 576, 128]       tensor([-43.675,  -2.399,  12.544, -15.535, -37.090,  47.323,   1.172,  55.474, -53.335,  -8.872])\n",
      "attn1               [2, 576, 128]       tensor([-0.543, -0.345,  0.414,  0.360, -0.165, -0.369,  0.374,  0.221,  0.459, -0.447])\n",
      "add attn1           [2, 576, 128]       tensor([-44.218,  -2.744,  12.957, -15.175, -37.255,  46.954,   1.546,  55.695, -52.876,  -9.319])\n",
      "norm2               [2, 576, 128]       tensor([-1.135, -0.020,  0.412, -0.360, -0.922,  1.315,  0.097,  1.570, -1.364, -0.192])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([  4.482,  -0.264,  -3.809,   0.240,  10.687,   4.066, -15.631,   4.242, -24.080,   1.344])\n",
      "add attn2           [2, 576, 128]       tensor([-39.736,  -3.009,   9.148, -14.935, -26.568,  51.020, -14.085,  59.937, -76.956,  -7.975])\n",
      "ff                  [2, 576, 128]       tensor([ 0.004, -0.151, -0.129,  0.176,  0.044, -0.115, -0.382,  0.181, -0.345,  0.193])\n",
      "add ff              [2, 576, 128]       tensor([-39.733,  -3.159,   9.019, -14.759, -26.524,  50.904, -14.467,  60.118, -77.300,  -7.782])\n",
      "attn1               [2, 576, 128]       tensor([-0.453,  0.037,  0.144,  0.266,  0.286, -0.250, -0.030,  0.321,  0.111, -0.620])\n",
      "add attn1           [2, 576, 128]       tensor([-40.185,  -3.122,   9.164, -14.493, -26.238,  50.655, -14.497,  60.439, -77.189,  -8.402])\n",
      "norm2               [2, 576, 128]       tensor([-1.048, -0.036,  0.299, -0.360, -0.655,  1.465, -0.348,  1.700, -2.105, -0.201])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([ 0.426, -0.321, -0.101,  0.428,  0.680, -0.546, -0.387, -0.219, -0.293,  0.380])\n",
      "add attn2           [2, 576, 128]       tensor([-39.759,  -3.443,   9.063, -14.065, -25.557,  50.108, -14.884,  60.220, -77.482,  -8.022])\n",
      "ff                  [2, 576, 128]       tensor([ 0.267, -0.469, -0.320, -0.208, -0.099, -0.494, -0.473,  0.024, -0.400,  0.441])\n",
      "add ff              [2, 576, 128]       tensor([-39.493,  -3.912,   8.742, -14.273, -25.656,  49.614, -15.357,  60.244, -77.882,  -7.581])\n",
      "attn1               [2, 576, 128]       tensor([-0.457, -0.850,  0.663,  0.184,  0.265,  0.147, -0.480,  0.514,  0.695,  0.223])\n",
      "add attn1           [2, 576, 128]       tensor([-39.950,  -4.762,   9.406, -14.089, -25.391,  49.762, -15.837,  60.758, -77.187,  -7.358])\n",
      "norm2               [2, 576, 128]       tensor([-1.041, -0.075,  0.293, -0.339, -0.651,  1.377, -0.369,  1.705, -2.075, -0.156])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([ 26.950,   0.286,   2.597,  33.402,  18.435,  -7.599,   2.560, -19.596,  -7.115,  -0.505])\n",
      "add attn2           [2, 576, 128]       tensor([-13.000,  -4.476,  12.003,  19.313,  -6.956,  42.163, -13.277,  41.162, -84.302,  -7.863])\n",
      "ff                  [2, 576, 128]       tensor([ 0.090, -0.549, -0.110,  0.060,  0.325, -0.351, -0.731, -0.083, -0.192,  0.487])\n",
      "add ff              [2, 576, 128]       tensor([-12.909,  -5.025,  11.894,  19.373,  -6.632,  41.811, -14.008,  41.079, -84.494,  -7.376])\n",
      "proj_out            [2, 128, 24, 24]    tensor([-6.341, -2.833, -7.272, -2.356, -8.634, -9.726, -3.774, -4.970, -6.341, -8.187])\n",
      "conv1               [2, 128, 24, 24]    tensor([1.490, 1.299, 1.562, 1.779, 1.988, 1.465, 0.953, 0.788, 1.032, 1.395])\n",
      "add time_emb_proj   [2, 128, 24, 24]    tensor([1.413, 1.222, 1.485, 1.702, 1.911, 1.388, 0.876, 0.711, 0.955, 1.317])\n",
      "conv2               [2, 128, 24, 24]    tensor([0.213, 0.420, 0.472, 0.490, 0.466, 0.454, 0.422, 0.416, 0.415, 0.432])\n",
      "add conv_shortcut   [2, 128, 24, 24]    tensor([ 0.587,  2.002,  1.647,  1.874,  2.106,  1.483, -0.425,  1.152,  2.360,  0.578])\n",
      "proj_in             [2, 576, 128]       tensor([-0.732,  0.896, -0.236,  0.983, -1.176,  0.469, -0.995, -0.374,  0.809, -0.841])\n",
      "attn1               [2, 576, 128]       tensor([-0.423,  0.394,  0.012, -0.223, -0.602,  1.545,  0.167, -0.868, -1.846, -0.081])\n",
      "add attn1           [2, 576, 128]       tensor([-1.155,  1.290, -0.224,  0.760, -1.778,  2.015, -0.828, -1.241, -1.037, -0.922])\n",
      "norm2               [2, 576, 128]       tensor([-1.002,  1.000, -0.265,  0.533, -1.511,  1.583, -0.727, -1.092, -0.897, -0.806])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([ 2.635,  0.207, -3.320,  8.042,  4.300, -2.385,  4.470, -1.934,  0.192,  2.509])\n",
      "add attn2           [2, 576, 128]       tensor([ 1.479,  1.497, -3.545,  8.801,  2.521, -0.370,  3.642, -3.175, -0.844,  1.588])\n",
      "ff                  [2, 576, 128]       tensor([-0.145, -0.229,  0.308,  0.069, -0.197,  0.076,  0.254,  0.148,  0.225,  0.240])\n",
      "add ff              [2, 576, 128]       tensor([ 1.335,  1.268, -3.236,  8.871,  2.324, -0.294,  3.897, -3.027, -0.619,  1.827])\n",
      "attn1               [2, 576, 128]       tensor([-2.531,  2.889, -9.955,  7.056, -2.493,  0.339,  4.416,  0.586, -3.634, -0.532])\n",
      "add attn1           [2, 576, 128]       tensor([ -1.196,   4.157, -13.191,  15.927,  -0.168,   0.045,   8.312,  -2.441,  -4.253,   1.295])\n",
      "norm2               [2, 576, 128]       tensor([-0.280,  0.324, -1.651,  1.664, -0.160, -0.123,  0.801, -0.411, -0.601,  0.022])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-1.309, -0.587, -9.355, 10.957,  5.374, -4.022,  3.214, -0.715,  0.446,  4.371])\n",
      "add attn2           [2, 576, 128]       tensor([ -2.505,   3.570, -22.546,  26.883,   5.206,  -3.977,  11.526,  -3.156,  -3.807,   5.667])\n",
      "ff                  [2, 576, 128]       tensor([ 0.306, -0.545,  0.283,  0.041,  0.319,  0.007,  0.060,  0.058, -0.124, -0.134])\n",
      "add ff              [2, 576, 128]       tensor([ -2.199,   3.026, -22.263,  26.924,   5.525,  -3.969,  11.586,  -3.098,  -3.931,   5.533])\n",
      "attn1               [2, 576, 128]       tensor([ 0.049,  0.147,  0.069,  1.090, -0.125, -0.168,  0.314,  0.511,  0.147, -0.152])\n",
      "add attn1           [2, 576, 128]       tensor([ -2.150,   3.173, -22.194,  28.015,   5.400,  -4.137,  11.900,  -2.587,  -3.784,   5.381])\n",
      "norm2               [2, 576, 128]       tensor([-0.306,  0.166, -2.045,  2.350,  0.361, -0.479,  0.959, -0.342, -0.448,  0.358])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([ 0.286, -0.325, -0.269,  0.370, -0.344,  0.017,  0.023,  0.317,  0.253, -0.042])\n",
      "add attn2           [2, 576, 128]       tensor([ -1.864,   2.848, -22.463,  28.385,   5.056,  -4.121,  11.923,  -2.269,  -3.531,   5.339])\n",
      "ff                  [2, 576, 128]       tensor([ 0.061, -0.104, -0.119,  0.395, -0.019,  0.178, -0.083,  0.047, -0.195,  0.094])\n",
      "add ff              [2, 576, 128]       tensor([ -1.803,   2.744, -22.582,  28.780,   5.037,  -3.943,  11.840,  -2.223,  -3.726,   5.433])\n",
      "attn1               [2, 576, 128]       tensor([ 0.633,  0.006,  0.817, -1.501,  0.158, -0.286, -0.970, -0.404,  0.621,  0.481])\n",
      "add attn1           [2, 576, 128]       tensor([ -1.171,   2.750, -21.765,  27.279,   5.194,  -4.229,  10.870,  -2.627,  -3.106,   5.915])\n",
      "norm2               [2, 576, 128]       tensor([-0.213,  0.152, -2.143,  2.427,  0.382, -0.495,  0.912, -0.351, -0.397,  0.430])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-1.950,  1.734, -1.575,  4.262,  0.630, -0.318, -0.086,  3.898,  2.752, -1.466])\n",
      "add attn2           [2, 576, 128]       tensor([ -3.120,   4.484, -23.340,  31.541,   5.824,  -4.547,  10.784,   1.271,  -0.354,   4.449])\n",
      "ff                  [2, 576, 128]       tensor([ 0.035, -0.129,  0.273, -0.064,  0.265,  0.114,  0.110,  0.243, -0.143, -0.171])\n",
      "add ff              [2, 576, 128]       tensor([ -3.085,   4.355, -23.067,  31.477,   6.089,  -4.433,  10.894,   1.514,  -0.497,   4.278])\n",
      "attn1               [2, 576, 128]       tensor([-0.700,  0.482, -1.278,  2.253,  0.273, -0.555,  1.019,  0.143, -0.996,  0.722])\n",
      "add attn1           [2, 576, 128]       tensor([ -3.785,   4.837, -24.345,  33.730,   6.362,  -4.988,  11.913,   1.657,  -1.493,   5.000])\n",
      "norm2               [2, 576, 128]       tensor([-0.421,  0.279, -2.117,  2.667,  0.406, -0.519,  0.866,  0.025, -0.239,  0.293])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-3.463,  1.775, -2.600,  2.098, -4.736,  2.701,  0.296,  5.548,  1.373, -0.409])\n",
      "add attn2           [2, 576, 128]       tensor([ -7.249,   6.611, -26.945,  35.827,   1.626,  -2.288,  12.209,   7.205,  -0.120,   4.591])\n",
      "ff                  [2, 576, 128]       tensor([-0.035,  0.055,  0.069, -0.016,  0.228,  0.002, -0.174,  0.375,  0.093, -0.207])\n",
      "add ff              [2, 576, 128]       tensor([-7.284e+00,  6.667e+00, -2.688e+01,  3.581e+01,  1.854e+00, -2.286e+00,  1.204e+01,  7.580e+00, -2.662e-02,  4.383e+00])\n",
      "attn1               [2, 576, 128]       tensor([-0.130, -0.300, -0.229,  1.244, -0.575, -0.308,  0.301,  0.320,  0.241, -0.518])\n",
      "add attn1           [2, 576, 128]       tensor([ -7.413,   6.367, -27.104,  37.055,   1.279,  -2.594,  12.336,   7.900,   0.214,   3.866])\n",
      "norm2               [2, 576, 128]       tensor([-6.394e-01,  3.738e-01, -2.138e+00,  2.712e+00,  1.963e-03, -2.833e-01,  8.248e-01,  4.838e-01, -7.671e-02,  2.095e-01])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-0.242,  0.018,  0.378,  0.143, -0.513,  0.078, -0.029,  0.133, -0.152,  0.404])\n",
      "add attn2           [2, 576, 128]       tensor([ -7.655,   6.385, -26.726,  37.198,   0.766,  -2.516,  12.307,   8.033,   0.062,   4.270])\n",
      "ff                  [2, 576, 128]       tensor([-0.062, -0.027, -0.254,  0.097,  0.040,  0.187, -0.160,  0.051,  0.181, -0.063])\n",
      "add ff              [2, 576, 128]       tensor([ -7.718,   6.358, -26.980,  37.294,   0.807,  -2.329,  12.147,   8.084,   0.244,   4.207])\n",
      "attn1               [2, 576, 128]       tensor([-4.630e-01, -3.100e-01, -7.196e-01,  8.279e-01, -8.603e-01, -7.270e-01,  6.115e-01, -6.797e-04, -6.355e-02, -4.855e-01])\n",
      "add attn1           [2, 576, 128]       tensor([ -8.181,   6.048, -27.700,  38.122,  -0.054,  -3.056,  12.758,   8.083,   0.180,   3.721])\n",
      "norm2               [2, 576, 128]       tensor([-0.686,  0.355, -2.129,  2.672, -0.099, -0.312,  0.837,  0.495, -0.079,  0.182])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([ 2.998, -0.153,  1.652, -2.852,  1.487,  3.625, -3.065,  1.816,  0.049,  0.613])\n",
      "add attn2           [2, 576, 128]       tensor([ -5.182,   5.896, -26.048,  35.270,   1.433,   0.568,   9.693,   9.899,   0.229,   4.335])\n",
      "ff                  [2, 576, 128]       tensor([ 0.140,  0.222, -0.063,  0.076,  0.139,  0.023, -0.019,  0.347,  0.112, -0.030])\n",
      "add ff              [2, 576, 128]       tensor([ -5.042,   6.117, -26.111,  35.346,   1.572,   0.592,   9.673,  10.246,   0.341,   4.304])\n",
      "attn1               [2, 576, 128]       tensor([ 1.060,  0.312, -0.006,  1.504,  0.221, -0.281,  0.279,  0.183,  0.172, -0.233])\n",
      "add attn1           [2, 576, 128]       tensor([ -3.981,   6.429, -26.117,  36.850,   1.793,   0.311,   9.952,  10.429,   0.513,   4.071])\n",
      "norm2               [2, 576, 128]       tensor([-0.381,  0.363, -1.948,  2.507,  0.028, -0.075,  0.601,  0.636, -0.065,  0.195])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([ 2.055,  0.555,  0.539,  0.061, -0.308,  0.596, -1.493,  0.777, -1.612, -1.174])\n",
      "add attn2           [2, 576, 128]       tensor([ -1.927,   6.984, -25.578,  36.912,   1.486,   0.906,   8.459,  11.206,  -1.099,   2.897])\n",
      "ff                  [2, 576, 128]       tensor([ 0.117,  0.048, -0.112,  0.230,  0.240,  0.225, -0.025,  0.298,  0.111,  0.018])\n",
      "add ff              [2, 576, 128]       tensor([ -1.809,   7.032, -25.690,  37.142,   1.726,   1.131,   8.435,  11.504,  -0.988,   2.915])\n",
      "attn1               [2, 576, 128]       tensor([ 0.041, -0.385, -0.167,  0.602,  0.151, -0.193,  0.170, -0.243,  0.062, -0.019])\n",
      "add attn1           [2, 576, 128]       tensor([ -1.769,   6.647, -25.857,  37.743,   1.877,   0.939,   8.604,  11.260,  -0.926,   2.896])\n",
      "norm2               [2, 576, 128]       tensor([-0.208,  0.378, -1.817,  2.478,  0.046, -0.012,  0.501,  0.698, -0.128,  0.133])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-1.817,  1.410, -4.010,  0.053,  2.189,  0.470, -3.225,  2.751,  0.576, -3.838])\n",
      "add attn2           [2, 576, 128]       tensor([ -3.586,   8.057, -29.867,  37.796,   4.066,   1.409,   5.379,  14.011,  -0.350,  -0.942])\n",
      "ff                  [2, 576, 128]       tensor([ 0.151, -0.106,  0.022, -0.017,  0.095, -0.038, -0.036,  0.220, -0.005,  0.024])\n",
      "add ff              [2, 576, 128]       tensor([ -3.435,   7.952, -29.845,  37.779,   4.161,   1.372,   5.343,  14.231,  -0.355,  -0.919])\n",
      "attn1               [2, 576, 128]       tensor([ 0.042, -0.331, -0.308,  0.675,  0.358, -0.125,  0.356, -0.070,  0.297, -0.173])\n",
      "add attn1           [2, 576, 128]       tensor([ -3.392,   7.621, -30.152,  38.454,   4.519,   1.247,   5.699,  14.161,  -0.059,  -1.092])\n",
      "norm2               [2, 576, 128]       tensor([-0.271,  0.447, -2.009,  2.473,  0.237,  0.035,  0.319,  0.900, -0.049, -0.132])\n",
      "context             [2, 77, 2048]       tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])\n",
      "attn2               [2, 576, 128]       tensor([-0.143,  0.105, -0.192,  0.077, -0.083, -0.085, -0.222,  0.241, -0.088, -0.009])\n",
      "add attn2           [2, 576, 128]       tensor([ -3.535,   7.726, -30.344,  38.531,   4.435,   1.162,   5.478,  14.403,  -0.147,  -1.101])\n",
      "ff                  [2, 576, 128]       tensor([ 0.125,  0.216,  0.060,  0.196,  0.297,  0.221, -0.048,  0.169, -0.023,  0.124])\n",
      "add ff              [2, 576, 128]       tensor([ -3.410,   7.943, -30.284,  38.728,   4.732,   1.383,   5.429,  14.572,  -0.170,  -0.977])\n",
      "proj_out            [2, 128, 24, 24]    tensor([16.475, 24.096, 20.511, 23.489,  5.639,  5.428, 20.923, 21.836, 19.620, 13.229])\n",
      "conv1               [2, 128, 24, 24]    tensor([0.612, 0.919, 0.961, 1.029, 0.822, 0.822, 1.036, 1.060, 1.055, 0.958])\n",
      "add time_emb_proj   [2, 128, 24, 24]    tensor([-8.704, -8.396, -8.355, -8.286, -8.494, -8.494, -8.280, -8.256, -8.261, -8.358])\n",
      "conv2               [2, 128, 24, 24]    tensor([3.287, 4.324, 4.089, 4.136, 4.220, 4.234, 4.161, 4.076, 4.092, 4.213])\n",
      "add conv_shortcut   [2, 128, 24, 24]    tensor([19.763, 28.419, 24.600, 27.625,  9.859,  9.663, 25.084, 25.912, 23.712, 17.442])\n"
     ]
    }
   ],
   "source": [
    "for name, t in dlog_l:\n",
    "    print(f'{name:<20}{str(list(t.shape)):<20}{t.flatten()[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf7aae-7c29-4430-ab1a-4a5ab7513e4a",
   "metadata": {},
   "source": [
    "Local intermediate results are not empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "216adfba-9675-493b-bcf6-1cb41d20b9ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1               [2, 32, 96, 96]     tensor([-0.828, -0.465, -0.597, -0.728, -0.992,  0.050, -0.500, -1.920, -1.507, -0.325])\n",
      "add time_emb_proj   [2, 32, 96, 96]     tensor([-0.418, -0.055, -0.187, -0.318, -0.582,  0.460, -0.090, -1.510, -1.097,  0.085])\n",
      "conv2               [2, 32, 96, 96]     tensor([-0.201, -0.217, -0.178, -0.103, -0.235, -0.112, -0.033,  0.107, -0.073, -0.313])\n",
      "add conv_shortcut   [2, 32, 96, 96]     tensor([-0.579, -0.396, -0.193, -0.662, -0.056, -0.110, -0.406,  0.084, -0.649, -1.122])\n",
      "conv1               [2, 32, 96, 96]     tensor([-0.489, -1.452, -1.598, -1.578, -1.935, -1.825, -2.010, -1.613, -1.147, -1.336])\n",
      "add time_emb_proj   [2, 32, 96, 96]     tensor([ 0.798, -0.165, -0.311, -0.291, -0.648, -0.538, -0.723, -0.326,  0.140, -0.049])\n",
      "conv2               [2, 32, 96, 96]     tensor([-0.109, -0.187,  0.009, -0.117,  0.200, -0.033,  0.062,  0.047,  0.089, -0.130])\n",
      "add conv_shortcut   [2, 32, 96, 96]     tensor([-0.586, -0.251,  0.140, -0.243,  0.251, -0.865, -0.546, -0.534, -0.110,  0.091])\n",
      "conv                [2, 32, 48, 48]     tensor([ 1.091,  1.078,  1.375,  3.085, -0.018,  0.515,  0.255,  1.035, -0.204,  0.458])\n",
      "conv1               [2, 64, 48, 48]     tensor([-1.760, -3.156, -2.930, -3.878, -3.873, -3.110, -3.097, -2.015, -3.273, -3.834])\n",
      "add time_emb_proj   [2, 64, 48, 48]     tensor([-7.804, -9.201, -8.975, -9.922, -9.918, -9.154, -9.142, -8.060, -9.318, -9.878])\n",
      "conv2               [2, 64, 48, 48]     tensor([-0.183, -0.101,  0.010,  0.118,  0.171,  0.120,  0.101,  0.040, -0.061, -0.234])\n",
      "add conv_shortcut   [2, 64, 48, 48]     tensor([ 0.534,  1.446,  1.009,  1.159,  0.691,  1.236,  1.186,  1.694,  0.599, -0.247])\n",
      "proj_in             [2, 2304, 64]       tensor([ 0.184, -0.104, -0.635, -0.163, -0.055,  0.177,  0.522,  0.324,  0.085, -0.225])\n",
      "attn1               [2, 2304, 64]       tensor([-0.184, -0.093, -0.251, -0.156, -0.122, -0.209, -0.203, -0.180,  0.195, -0.330])\n",
      "add attn1           [2, 2304, 64]       tensor([ 1.040e-04, -1.968e-01, -8.864e-01, -3.189e-01, -1.775e-01, -3.267e-02,  3.188e-01,  1.439e-01,  2.797e-01, -5.551e-01])\n",
      "attn2               [2, 2304, 64]       tensor([  6.565,  -5.352,  -6.271,   5.966,  -2.299,  -4.301,   6.378,   1.230,  -8.356, -15.714])\n",
      "add attn2           [2, 2304, 64]       tensor([  6.565,  -5.549,  -7.157,   5.647,  -2.477,  -4.333,   6.697,   1.373,  -8.077, -16.269])\n",
      "ff                  [2, 2304, 64]       tensor([ 0.051,  0.183, -0.051,  0.073, -0.070, -0.405, -0.195, -0.075,  0.364, -0.181])\n",
      "add ff              [2, 2304, 64]       tensor([  6.616,  -5.366,  -7.208,   5.720,  -2.547,  -4.738,   6.502,   1.298,  -7.712, -16.450])\n",
      "attn1               [2, 2304, 64]       tensor([ 0.083,  0.070, -0.237, -0.087, -0.362,  0.379, -0.128, -0.052,  0.115, -0.226])\n",
      "add attn1           [2, 2304, 64]       tensor([  6.699,  -5.297,  -7.445,   5.633,  -2.909,  -4.359,   6.374,   1.247,  -7.597, -16.677])\n",
      "attn2               [2, 2304, 64]       tensor([ 0.113, -0.994, -0.217,  0.074,  0.306,  0.243, -0.690,  0.442,  0.359,  0.363])\n",
      "add attn2           [2, 2304, 64]       tensor([  6.812,  -6.291,  -7.662,   5.707,  -2.603,  -4.116,   5.684,   1.689,  -7.238, -16.314])\n",
      "ff                  [2, 2304, 64]       tensor([ 0.279,  0.344, -0.486,  0.622, -0.799,  0.682, -0.471,  0.623,  0.372,  0.724])\n",
      "add ff              [2, 2304, 64]       tensor([  7.091,  -5.946,  -8.148,   6.329,  -3.402,  -3.433,   5.212,   2.311,  -6.866, -15.590])\n",
      "proj_out            [2, 64, 48, 48]     tensor([-0.942,  0.018, -0.463,  1.219,  1.307,  1.843, -0.258,  0.280, -0.888,  0.371])\n",
      "conv1               [2, 64, 48, 48]     tensor([-1.577, -2.929, -3.515, -3.289, -3.392, -2.503, -1.916, -1.491, -2.098, -2.387])\n",
      "add time_emb_proj   [2, 64, 48, 48]     tensor([-3.798, -5.150, -5.736, -5.509, -5.612, -4.724, -4.137, -3.712, -4.319, -4.608])\n",
      "conv2               [2, 64, 48, 48]     tensor([-0.474, -0.712, -0.773, -0.724, -0.665, -0.620, -0.622, -0.668, -0.751, -0.756])\n",
      "add conv_shortcut   [2, 64, 48, 48]     tensor([ 0.389, -0.660, -2.126, -1.864, -0.649, -0.216, -2.387,  0.052, -0.884, -0.964])\n",
      "proj_in             [2, 2304, 64]       tensor([-0.050, -0.514,  0.680, -1.355,  0.077, -0.614,  0.716,  0.620,  0.102,  0.478])\n",
      "attn1               [2, 2304, 64]       tensor([-1.590, -0.159, -0.307, -0.860,  0.963, -1.169, -1.570, -0.341,  1.038, -0.485])\n",
      "add attn1           [2, 2304, 64]       tensor([-1.640, -0.673,  0.374, -2.215,  1.040, -1.783, -0.854,  0.279,  1.140, -0.007])\n",
      "attn2               [2, 2304, 64]       tensor([-3.020,  9.976,  0.982, -7.148,  2.548,  2.667, -5.143, -3.962,  5.446, -9.426])\n",
      "add attn2           [2, 2304, 64]       tensor([-4.660,  9.304,  1.356, -9.363,  3.588,  0.884, -5.997, -3.683,  6.586, -9.433])\n",
      "ff                  [2, 2304, 64]       tensor([ 0.522, -0.273, -0.225, -0.074,  0.242, -0.165,  0.507,  0.636,  0.080,  0.249])\n",
      "add ff              [2, 2304, 64]       tensor([-4.139,  9.031,  1.131, -9.437,  3.830,  0.719, -5.490, -3.048,  6.666, -9.184])\n",
      "attn1               [2, 2304, 64]       tensor([-0.148,  0.054,  0.858, -0.416,  0.697, -0.254,  0.269,  0.363,  0.071, -0.205])\n",
      "add attn1           [2, 2304, 64]       tensor([-4.287,  9.085,  1.989, -9.853,  4.528,  0.465, -5.221, -2.685,  6.737, -9.389])\n",
      "attn2               [2, 2304, 64]       tensor([-0.205, -0.168,  0.304, -0.035,  0.398, -0.094,  0.244, -0.032,  0.101,  0.560])\n",
      "add attn2           [2, 2304, 64]       tensor([-4.492,  8.917,  2.293, -9.888,  4.926,  0.371, -4.977, -2.716,  6.838, -8.829])\n",
      "ff                  [2, 2304, 64]       tensor([ 1.088, -0.858,  0.066, -0.171, -0.136, -0.544,  0.358,  0.796, -0.090,  0.211])\n",
      "add ff              [2, 2304, 64]       tensor([ -3.404,   8.059,   2.359, -10.059,   4.790,  -0.172,  -4.619,  -1.921,   6.747,  -8.619])\n",
      "proj_out            [2, 64, 48, 48]     tensor([ 2.693,  1.682,  0.191,  0.408,  1.673,  2.134, -0.022,  2.353,  1.444,  1.400])\n",
      "conv                [2, 64, 24, 24]     tensor([ 8.804, 12.071, 12.340,  9.305,  7.026,  1.711,  7.633,  7.422,  7.197,  4.811])\n",
      "conv1               [2, 128, 24, 24]    tensor([-3.281, -6.434, -7.338, -6.608, -3.926, -3.468, -3.939, -6.156, -5.563, -3.337])\n",
      "add time_emb_proj   [2, 128, 24, 24]    tensor([ -7.124, -10.277, -11.180, -10.451,  -7.768,  -7.311,  -7.782,  -9.999,  -9.405,  -7.180])\n",
      "conv2               [2, 128, 24, 24]    tensor([-0.296, -0.283,  0.065,  0.185,  0.090, -0.127, -0.149, -0.038, -0.129, -0.405])\n",
      "add conv_shortcut   [2, 128, 24, 24]    tensor([-7.042, -6.520, -6.733, -3.690, -1.833, -3.608, -6.263, -7.237, -4.634, -4.301])\n",
      "proj_in             [2, 576, 128]       tensor([ 0.763, -1.177,  0.114,  1.675, -0.286, -3.023, -0.103, -1.488, -1.978, -1.395])\n",
      "attn1               [2, 576, 128]       tensor([ 2.139, -3.245,  2.655, -2.119, -2.258, -3.109, -3.244,  1.133, -1.179, -4.706])\n",
      "add attn1           [2, 576, 128]       tensor([ 2.901, -4.422,  2.769, -0.444, -2.544, -6.132, -3.347, -0.355, -3.157, -6.101])\n",
      "attn2               [2, 576, 128]       tensor([ 6.427, -5.716,  5.981, -8.151, -5.220,  3.756,  0.298,  2.613,  1.814, -4.174])\n",
      "add attn2           [2, 576, 128]       tensor([  9.329, -10.137,   8.749,  -8.595,  -7.764,  -2.376,  -3.049,   2.258,  -1.343, -10.274])\n",
      "ff                  [2, 576, 128]       tensor([ 0.089, -0.158,  0.347, -0.273,  0.074,  0.190, -0.470,  0.199, -0.259, -0.118])\n",
      "add ff              [2, 576, 128]       tensor([  9.418, -10.296,   9.096,  -8.868,  -7.690,  -2.186,  -3.520,   2.457,  -1.602, -10.392])\n",
      "attn1               [2, 576, 128]       tensor([ 1.665, -4.155,  3.985,  2.256, -0.094, -5.058, -0.668,  4.951,  0.664, -0.574])\n",
      "add attn1           [2, 576, 128]       tensor([ 11.083, -14.451,  13.081,  -6.612,  -7.784,  -7.243,  -4.188,   7.408,  -0.938, -10.966])\n",
      "attn2               [2, 576, 128]       tensor([  1.360,   3.137,   1.093,   0.325,  -6.508, -11.446,   5.496,  -4.454,   6.445,  -4.110])\n",
      "add attn2           [2, 576, 128]       tensor([ 12.444, -11.313,  14.175,  -6.287, -14.291, -18.690,   1.308,   2.954,   5.507, -15.077])\n",
      "ff                  [2, 576, 128]       tensor([ 0.108,  0.005, -0.111, -0.117, -0.228,  0.115, -0.036,  0.151, -0.147, -0.123])\n",
      "add ff              [2, 576, 128]       tensor([ 12.552, -11.308,  14.063,  -6.404, -14.519, -18.575,   1.272,   3.105,   5.360, -15.200])\n",
      "attn1               [2, 576, 128]       tensor([ 0.309,  0.157,  0.691,  1.254, -0.693, -2.450,  1.720,  1.418,  0.630,  0.612])\n",
      "add attn1           [2, 576, 128]       tensor([ 12.861, -11.151,  14.754,  -5.150, -15.213, -21.025,   2.991,   4.522,   5.990, -14.588])\n",
      "attn2               [2, 576, 128]       tensor([ 0.180,  1.182, -1.704, -1.884, -0.069,  0.448, -0.546, -0.490,  0.003, -0.416])\n",
      "add attn2           [2, 576, 128]       tensor([ 13.041,  -9.969,  13.050,  -7.034, -15.282, -20.577,   2.446,   4.033,   5.993, -15.004])\n",
      "ff                  [2, 576, 128]       tensor([-0.068,  0.210, -0.041, -0.021, -0.150,  0.166,  0.116,  0.044, -0.038, -0.064])\n",
      "add ff              [2, 576, 128]       tensor([ 12.973,  -9.759,  13.009,  -7.055, -15.432, -20.411,   2.562,   4.077,   5.955, -15.068])\n",
      "attn1               [2, 576, 128]       tensor([-0.200,  0.013,  0.359, -0.168,  0.424, -0.351,  0.287,  0.013,  0.178,  0.526])\n",
      "add attn1           [2, 576, 128]       tensor([ 12.773,  -9.746,  13.369,  -7.223, -15.008, -20.761,   2.849,   4.090,   6.133, -14.542])\n",
      "attn2               [2, 576, 128]       tensor([-2.768,  6.812, -0.039,  2.556,  2.977, -5.944,  4.140, -4.444, -3.699,  2.254])\n",
      "add attn2           [2, 576, 128]       tensor([ 10.006,  -2.934,  13.329,  -4.667, -12.031, -26.705,   6.989,  -0.354,   2.434, -12.288])\n",
      "ff                  [2, 576, 128]       tensor([-0.001, -0.045,  0.035,  0.165,  0.085,  0.047,  0.137,  0.006, -0.278, -0.155])\n",
      "add ff              [2, 576, 128]       tensor([ 10.005,  -2.979,  13.365,  -4.502, -11.946, -26.659,   7.126,  -0.348,   2.156, -12.443])\n",
      "attn1               [2, 576, 128]       tensor([-0.686,  0.562, -0.195, -0.036,  0.248,  0.254, -0.418, -0.591, -0.687, -0.128])\n",
      "add attn1           [2, 576, 128]       tensor([  9.319,  -2.417,  13.170,  -4.538, -11.698, -26.405,   6.708,  -0.939,   1.469, -12.571])\n",
      "attn2               [2, 576, 128]       tensor([ -9.682,   9.670,   3.053,  -8.846, -26.305,   1.260, -12.291,  -0.255,  -2.758, -21.526])\n",
      "add attn2           [2, 576, 128]       tensor([ -0.363,   7.253,  16.223, -13.384, -38.002, -25.145,  -5.583,  -1.194,  -1.289, -34.097])\n",
      "ff                  [2, 576, 128]       tensor([-0.177,  0.210, -0.181, -0.060,  0.175,  0.121, -0.278, -0.063, -0.391, -0.098])\n",
      "add ff              [2, 576, 128]       tensor([ -0.540,   7.463,  16.042, -13.444, -37.827, -25.024,  -5.861,  -1.257,  -1.680, -34.195])\n",
      "attn1               [2, 576, 128]       tensor([-0.706,  0.619,  0.866,  0.175,  1.558,  0.129,  1.069, -0.620,  0.130,  0.421])\n",
      "add attn1           [2, 576, 128]       tensor([ -1.246,   8.082,  16.908, -13.269, -36.269, -24.895,  -4.792,  -1.877,  -1.550, -33.774])\n",
      "attn2               [2, 576, 128]       tensor([ -9.077,   4.139,   3.783,   2.038,  -0.861, -14.059,  -5.081,  16.279,   4.735,  -2.135])\n",
      "add attn2           [2, 576, 128]       tensor([-10.323,  12.221,  20.691, -11.231, -37.130, -38.954,  -9.873,  14.402,   3.185, -35.909])\n",
      "ff                  [2, 576, 128]       tensor([-0.241,  0.231, -0.099, -0.094, -0.001,  0.159, -0.063, -0.007, -0.289, -0.110])\n",
      "add ff              [2, 576, 128]       tensor([-10.564,  12.452,  20.591, -11.325, -37.131, -38.794,  -9.936,  14.394,   2.895, -36.019])\n",
      "attn1               [2, 576, 128]       tensor([-0.095, -0.307, -0.792,  0.469,  0.297,  0.044,  0.146,  0.293, -0.353, -0.107])\n",
      "add attn1           [2, 576, 128]       tensor([-10.659,  12.145,  19.799, -10.856, -36.835, -38.750,  -9.789,  14.687,   2.543, -36.126])\n",
      "attn2               [2, 576, 128]       tensor([-0.617, -0.776, -0.867,  1.427, -1.909, -0.066, -1.133,  1.585, -0.335,  1.066])\n",
      "add attn2           [2, 576, 128]       tensor([-11.277,  11.369,  18.932,  -9.429, -38.744, -38.816, -10.922,  16.272,   2.208, -35.060])\n",
      "ff                  [2, 576, 128]       tensor([-0.147,  0.437, -0.291,  0.123,  0.117,  0.214, -0.014, -0.089, -0.381,  0.162])\n",
      "add ff              [2, 576, 128]       tensor([-11.424,  11.806,  18.641,  -9.306, -38.627, -38.602, -10.936,  16.183,   1.827, -34.898])\n",
      "attn1               [2, 576, 128]       tensor([ 0.045,  0.004, -0.187, -0.038,  0.786,  0.021,  0.282, -0.147, -0.958,  0.266])\n",
      "add attn1           [2, 576, 128]       tensor([-11.378,  11.810,  18.454,  -9.344, -37.841, -38.580, -10.654,  16.036,   0.868, -34.633])\n",
      "attn2               [2, 576, 128]       tensor([-0.572,  0.860, -1.043, -0.225, -0.127, -0.097,  0.316,  0.107,  1.130, -0.967])\n",
      "add attn2           [2, 576, 128]       tensor([-11.951,  12.670,  17.410,  -9.569, -37.968, -38.677, -10.337,  16.143,   1.999, -35.600])\n",
      "ff                  [2, 576, 128]       tensor([-0.784, -0.270, -1.183,  1.087,  1.178,  0.409, -0.347,  0.062, -0.720, -0.025])\n",
      "add ff              [2, 576, 128]       tensor([-12.735,  12.400,  16.228,  -8.483, -36.790, -38.268, -10.685,  16.205,   1.278, -35.626])\n",
      "attn1               [2, 576, 128]       tensor([ 0.163,  0.192, -1.098,  0.376,  0.071,  0.072, -0.010,  0.124, -0.241, -0.243])\n",
      "add attn1           [2, 576, 128]       tensor([-12.572,  12.592,  15.130,  -8.107, -36.719, -38.196, -10.695,  16.329,   1.038, -35.868])\n",
      "attn2               [2, 576, 128]       tensor([-0.116,  0.137, -0.173,  0.105,  0.049,  0.247, -0.038,  0.113, -0.029, -0.329])\n",
      "add attn2           [2, 576, 128]       tensor([-12.688,  12.729,  14.957,  -8.001, -36.670, -37.948, -10.733,  16.442,   1.009, -36.197])\n",
      "ff                  [2, 576, 128]       tensor([-0.992, -0.154, -0.875,  0.674,  1.137,  0.204, -0.283, -0.175, -0.889,  0.174])\n",
      "add ff              [2, 576, 128]       tensor([-13.680,  12.575,  14.082,  -7.327, -35.533, -37.744, -11.016,  16.267,   0.119, -36.023])\n",
      "attn1               [2, 576, 128]       tensor([-0.181,  0.037, -0.435,  0.200,  0.271, -0.311,  0.599,  0.124, -0.391, -0.137])\n",
      "add attn1           [2, 576, 128]       tensor([-13.862,  12.612,  13.647,  -7.127, -35.262, -38.055, -10.417,  16.392,  -0.272, -36.160])\n",
      "attn2               [2, 576, 128]       tensor([-0.199, -0.290, -0.430,  0.276, -0.076, -0.246, -0.257,  0.164, -0.014,  0.163])\n",
      "add attn2           [2, 576, 128]       tensor([-14.061,  12.322,  13.217,  -6.850, -35.338, -38.301, -10.674,  16.556,  -0.285, -35.996])\n",
      "ff                  [2, 576, 128]       tensor([-0.916,  0.178, -0.745,  0.326,  0.703,  0.136, -0.115, -0.152, -0.640, -0.116])\n",
      "add ff              [2, 576, 128]       tensor([-14.977,  12.500,  12.472,  -6.524, -34.635, -38.165, -10.789,  16.404,  -0.925, -36.113])\n",
      "proj_out            [2, 128, 24, 24]    tensor([0.174, 0.419, 0.474, 3.199, 5.117, 3.618, 0.915, 0.119, 2.507, 2.940])\n",
      "conv1               [2, 128, 24, 24]    tensor([ -3.098,  -7.419, -11.507,  -9.520,  -5.673,  -3.870,  -4.401,  -6.961,  -6.957,  -4.653])\n",
      "add time_emb_proj   [2, 128, 24, 24]    tensor([-0.308, -4.629, -8.717, -6.730, -2.883, -1.080, -1.612, -4.171, -4.167, -1.863])\n",
      "conv2               [2, 128, 24, 24]    tensor([0.604, 0.632, 0.492, 0.266, 0.292, 0.477, 0.575, 0.502, 0.334, 0.281])\n",
      "add conv_shortcut   [2, 128, 24, 24]    tensor([17.868, 21.283, 16.251, 21.448, 15.256, 13.922, 20.336, 18.711, 17.556, 15.910])\n",
      "proj_in             [2, 576, 128]       tensor([-1.361,  0.635,  0.222, -0.870, -1.169, -1.020, -1.125,  1.669, -0.206,  1.119])\n",
      "attn1               [2, 576, 128]       tensor([-3.342,  1.304,  0.167, -0.603,  0.124, -2.377, -2.702,  1.779,  0.054,  0.933])\n",
      "add attn1           [2, 576, 128]       tensor([-4.703,  1.939,  0.388, -1.473, -1.045, -3.396, -3.827,  3.449, -0.152,  2.052])\n",
      "attn2               [2, 576, 128]       tensor([-15.126,   1.921,   9.406,  -9.743, -28.575,  11.805,   9.301,   6.362, -17.111, -15.940])\n",
      "add attn2           [2, 576, 128]       tensor([-19.830,   3.860,   9.795, -11.215, -29.620,   8.409,   5.474,   9.811, -17.263, -13.888])\n",
      "ff                  [2, 576, 128]       tensor([-0.021,  0.018, -0.012, -0.066,  0.077, -0.019, -0.109,  0.060, -0.092,  0.041])\n",
      "add ff              [2, 576, 128]       tensor([-19.850,   3.878,   9.782, -11.281, -29.543,   8.389,   5.366,   9.871, -17.354, -13.847])\n",
      "attn1               [2, 576, 128]       tensor([-0.429, -1.304,  0.281,  1.021, -1.134,  0.215,  0.288,  0.945, -0.092, -0.331])\n",
      "add attn1           [2, 576, 128]       tensor([-20.280,   2.574,  10.063, -10.261, -30.676,   8.604,   5.653,  10.816, -17.446, -14.178])\n",
      "attn2               [2, 576, 128]       tensor([-20.654,  -4.117,  -3.671, -10.861, -10.042,  31.207,   0.084,  34.335, -24.649,   5.472])\n",
      "add attn2           [2, 576, 128]       tensor([-40.934,  -1.543,   6.392, -21.122, -40.718,  39.811,   5.737,  45.152, -42.095,  -8.706])\n",
      "ff                  [2, 576, 128]       tensor([-0.056, -0.029,  0.035, -0.055, -0.090, -0.017, -0.033,  0.052, -0.101,  0.027])\n",
      "add ff              [2, 576, 128]       tensor([-40.990,  -1.572,   6.427, -21.177, -40.808,  39.794,   5.704,  45.204, -42.195,  -8.679])\n",
      "attn1               [2, 576, 128]       tensor([-0.311, -0.424, -0.630, -0.290,  0.262, -0.472,  0.298, -0.613,  0.317, -0.143])\n",
      "add attn1           [2, 576, 128]       tensor([-41.301,  -1.997,   5.798, -21.468, -40.546,  39.322,   6.002,  44.590, -41.879,  -8.823])\n",
      "attn2               [2, 576, 128]       tensor([-2.468,  1.333, -3.116, -2.594,  4.938,  3.778,  6.644,  5.286, -3.760,  0.842])\n",
      "add attn2           [2, 576, 128]       tensor([-43.769,  -0.663,   2.682, -24.062, -35.608,  43.100,  12.646,  49.876, -45.639,  -7.981])\n",
      "ff                  [2, 576, 128]       tensor([-0.039, -0.069,  0.021, -0.035,  0.012, -0.044, -0.108,  0.023, -0.059, -0.041])\n",
      "add ff              [2, 576, 128]       tensor([-43.808,  -0.732,   2.703, -24.096, -35.596,  43.056,  12.538,  49.899, -45.698,  -8.022])\n",
      "attn1               [2, 576, 128]       tensor([ 0.348,  0.440, -0.281, -1.318,  0.787, -0.436, -0.146, -0.611, -0.020,  0.269])\n",
      "add attn1           [2, 576, 128]       tensor([-43.460,  -0.293,   2.422, -25.414, -34.809,  42.620,  12.392,  49.288, -45.717,  -7.753])\n",
      "attn2               [2, 576, 128]       tensor([  4.474,  -0.774,   1.054,   1.444,   1.737,   0.489,  -3.569,   1.913, -10.552,  -1.453])\n",
      "add attn2           [2, 576, 128]       tensor([-38.986,  -1.067,   3.476, -23.970, -33.072,  43.109,   8.822,  51.201, -56.269,  -9.207])\n",
      "ff                  [2, 576, 128]       tensor([-0.056, -0.043,  0.027, -0.136, -0.097,  0.088, -0.250,  0.124, -0.208, -0.015])\n",
      "add ff              [2, 576, 128]       tensor([-39.042,  -1.110,   3.504, -24.106, -33.168,  43.197,   8.572,  51.326, -56.477,  -9.221])\n",
      "attn1               [2, 576, 128]       tensor([ 0.339,  0.398, -0.120, -0.516,  0.392, -1.322, -0.629, -0.665,  0.608, -0.326])\n",
      "add attn1           [2, 576, 128]       tensor([-38.703,  -0.711,   3.384, -24.622, -32.776,  41.875,   7.943,  50.660, -55.869,  -9.548])\n",
      "attn2               [2, 576, 128]       tensor([-5.098, -0.725,  0.882, -0.789, -0.486,  0.885,  4.633,  0.281, -1.120, -1.798])\n",
      "add attn2           [2, 576, 128]       tensor([-43.802,  -1.436,   4.266, -25.410, -33.262,  42.760,  12.576,  50.942, -56.990, -11.346])\n",
      "ff                  [2, 576, 128]       tensor([-0.099, -0.085, -0.112, -0.099, -0.039,  0.052, -0.192,  0.043, -0.183,  0.023])\n",
      "add ff              [2, 576, 128]       tensor([-43.901,  -1.521,   4.154, -25.509, -33.300,  42.812,  12.385,  50.984, -57.173, -11.323])\n",
      "attn1               [2, 576, 128]       tensor([-0.129, -0.129, -0.043, -0.521,  0.044, -0.589, -0.075, -0.082,  0.118, -0.359])\n",
      "add attn1           [2, 576, 128]       tensor([-44.030,  -1.650,   4.111, -26.030, -33.257,  42.224,  12.309,  50.902, -57.055, -11.682])\n",
      "attn2               [2, 576, 128]       tensor([-0.578,  1.630,  1.372,  5.982,  0.692,  0.205, -7.054,  1.461,  0.534,  3.754])\n",
      "add attn2           [2, 576, 128]       tensor([-4.461e+01, -1.947e-02,  5.483e+00, -2.005e+01, -3.256e+01,  4.243e+01,  5.256e+00,  5.236e+01, -5.652e+01, -7.928e+00])\n",
      "ff                  [2, 576, 128]       tensor([ 0.007, -0.130, -0.154,  0.086, -0.042, -0.001, -0.222,  0.102, -0.146, -0.021])\n",
      "add ff              [2, 576, 128]       tensor([-44.600,  -0.150,   5.329, -19.962, -32.607,  42.428,   5.034,  52.466, -56.667,  -7.950])\n",
      "attn1               [2, 576, 128]       tensor([-0.399, -0.615,  0.069,  0.082,  0.212, -0.137,  0.138,  0.018,  0.261, -0.474])\n",
      "add attn1           [2, 576, 128]       tensor([-44.999,  -0.765,   5.398, -19.880, -32.394,  42.291,   5.172,  52.484, -56.406,  -8.424])\n",
      "attn2               [2, 576, 128]       tensor([-0.347, -0.029, -0.075, -0.213, -0.076, -0.282,  0.046, -0.083, -0.136,  0.404])\n",
      "add attn2           [2, 576, 128]       tensor([-45.346,  -0.794,   5.323, -20.093, -32.471,  42.009,   5.217,  52.401, -56.542,  -8.019])\n",
      "ff                  [2, 576, 128]       tensor([ 0.008, -0.128, -0.173,  0.049, -0.027,  0.022, -0.243,  0.098, -0.270, -0.024])\n",
      "add ff              [2, 576, 128]       tensor([-45.338,  -0.923,   5.150, -20.044, -32.497,  42.031,   4.974,  52.499, -56.812,  -8.044])\n",
      "attn1               [2, 576, 128]       tensor([-0.568, -0.294,  0.219,  0.244,  0.021, -0.215,  0.216,  0.401,  0.399, -0.098])\n",
      "add attn1           [2, 576, 128]       tensor([-45.906,  -1.217,   5.369, -19.800, -32.476,  41.817,   5.190,  52.900, -56.414,  -8.142])\n",
      "attn2               [2, 576, 128]       tensor([  4.483,  -0.264,  -3.810,   0.240,  10.688,   4.067, -15.633,   4.242, -24.084,   1.343])\n",
      "add attn2           [2, 576, 128]       tensor([-41.423,  -1.481,   1.559, -19.560, -21.789,  45.884, -10.443,  57.142, -80.497,  -6.799])\n",
      "ff                  [2, 576, 128]       tensor([ 0.013, -0.165, -0.114,  0.188,  0.065, -0.146, -0.387,  0.190, -0.348,  0.186])\n",
      "add ff              [2, 576, 128]       tensor([-41.410,  -1.646,   1.446, -19.372, -21.723,  45.738, -10.830,  57.332, -80.846,  -6.613])\n",
      "attn1               [2, 576, 128]       tensor([-0.124,  0.078, -0.297,  0.351,  0.268,  0.245, -0.405,  0.195, -0.023, -0.008])\n",
      "add attn1           [2, 576, 128]       tensor([-41.535,  -1.568,   1.149, -19.021, -21.456,  45.983, -11.235,  57.527, -80.868,  -6.621])\n",
      "attn2               [2, 576, 128]       tensor([ 0.009,  0.021, -0.135,  0.196,  0.288, -0.204, -0.282,  0.008, -0.133, -0.059])\n",
      "add attn2           [2, 576, 128]       tensor([-41.525,  -1.547,   1.014, -18.825, -21.168,  45.778, -11.517,  57.535, -81.001,  -6.680])\n",
      "ff                  [2, 576, 128]       tensor([ 0.238, -0.484, -0.339, -0.184, -0.105, -0.486, -0.497,  0.024, -0.429,  0.432])\n",
      "add ff              [2, 576, 128]       tensor([-41.287,  -2.031,   0.675, -19.008, -21.273,  45.293, -12.014,  57.559, -81.430,  -6.248])\n",
      "attn1               [2, 576, 128]       tensor([-0.502, -0.858,  0.612,  0.156,  0.296,  0.086, -0.469,  0.493,  0.630,  0.151])\n",
      "add attn1           [2, 576, 128]       tensor([-41.789,  -2.889,   1.287, -18.852, -20.977,  45.379, -12.483,  58.052, -80.801,  -6.097])\n",
      "attn2               [2, 576, 128]       tensor([ 25.201,  -1.096,   5.346,  31.989,  17.284,  -9.292,   0.860, -18.893,  -9.915,   1.553])\n",
      "add attn2           [2, 576, 128]       tensor([-16.588,  -3.986,   6.633,  13.137,  -3.693,  36.087, -11.623,  39.159, -90.716,  -4.544])\n",
      "ff                  [2, 576, 128]       tensor([ 0.142, -0.609, -0.158,  0.024,  0.369, -0.417, -0.754, -0.119, -0.191,  0.504])\n",
      "add ff              [2, 576, 128]       tensor([-16.446,  -4.595,   6.475,  13.161,  -3.324,  35.670, -12.377,  39.040, -90.907,  -4.039])\n",
      "proj_out            [2, 128, 24, 24]    tensor([ -7.500,  -4.174,  -9.125,  -3.993, -10.088, -11.391,  -5.079,  -6.688,  -7.837,  -9.424])\n",
      "conv1               [2, 128, 24, 24]    tensor([ 7.131, 14.556, 14.844, 13.950,  9.481,  8.588,  7.777,  8.167,  8.230,  7.436])\n",
      "add time_emb_proj   [2, 128, 24, 24]    tensor([ 7.052, 14.477, 14.765, 13.871,  9.402,  8.509,  7.698,  8.088,  8.151,  7.357])\n",
      "conv2               [2, 128, 24, 24]    tensor([ 0.080,  0.067,  0.100,  0.188,  0.247,  0.175,  0.054, -0.016,  0.121,  0.335])\n",
      "add conv_shortcut   [2, 128, 24, 24]    tensor([ 0.869, 11.159,  5.967,  9.732,  2.597, -6.451, -1.426, -0.509,  2.550, -2.760])\n",
      "proj_in             [2, 576, 128]       tensor([ 1.549,  1.607,  1.283,  0.861, -1.218,  2.978, -1.683,  2.208,  2.338, -2.643])\n",
      "attn1               [2, 576, 128]       tensor([-0.584,  1.793, -2.156,  0.079, -2.453,  1.487, -0.420, -0.814, -0.745, -0.425])\n",
      "add attn1           [2, 576, 128]       tensor([ 0.965,  3.399, -0.873,  0.940, -3.670,  4.466, -2.102,  1.394,  1.593, -3.068])\n",
      "attn2               [2, 576, 128]       tensor([ 4.885,  0.071, -2.864,  6.192,  4.724, -4.082,  4.738, -3.296, -0.290,  4.100])\n",
      "add attn2           [2, 576, 128]       tensor([ 5.851,  3.471, -3.737,  7.132,  1.053,  0.384,  2.636, -1.901,  1.303,  1.033])\n",
      "ff                  [2, 576, 128]       tensor([ 0.035,  1.112, -0.711,  2.087, -1.478,  0.798,  0.600,  1.032,  0.385, -0.246])\n",
      "add ff              [2, 576, 128]       tensor([ 5.885,  4.583, -4.447,  9.219, -0.425,  1.182,  3.236, -0.870,  1.688,  0.787])\n",
      "attn1               [2, 576, 128]       tensor([ -2.569,   2.906, -10.039,   7.123,  -2.478,   0.355,   4.498,   0.538,  -3.741,  -0.541])\n",
      "add attn1           [2, 576, 128]       tensor([  3.316,   7.488, -14.487,  16.342,  -2.902,   1.537,   7.734,  -0.331,  -2.053,   0.245])\n",
      "attn2               [2, 576, 128]       tensor([-1.308, -0.588, -9.356, 10.958,  5.374, -4.021,  3.213, -0.715,  0.445,  4.371])\n",
      "add attn2           [2, 576, 128]       tensor([  2.009,   6.900, -23.842,  27.300,   2.472,  -2.484,  10.947,  -1.046,  -1.608,   4.616])\n",
      "ff                  [2, 576, 128]       tensor([ 0.295, -0.057, -0.612,  1.194, -0.214, -0.161,  0.650, -0.025, -0.885, -0.548])\n",
      "add ff              [2, 576, 128]       tensor([  2.303,   6.843, -24.454,  28.495,   2.258,  -2.645,  11.597,  -1.071,  -2.493,   4.068])\n",
      "attn1               [2, 576, 128]       tensor([ 0.163,  1.228, -0.695,  1.812, -1.237,  0.174,  1.765,  0.045, -0.392,  0.451])\n",
      "add attn1           [2, 576, 128]       tensor([  2.466,   8.071, -25.149,  30.306,   1.021,  -2.471,  13.362,  -1.027,  -2.885,   4.519])\n",
      "attn2               [2, 576, 128]       tensor([ 0.248, -0.338, -0.242,  0.312, -0.327, -0.007,  0.005,  0.296,  0.208, -0.048])\n",
      "add attn2           [2, 576, 128]       tensor([  2.714,   7.733, -25.391,  30.618,   0.694,  -2.478,  13.367,  -0.730,  -2.677,   4.471])\n",
      "ff                  [2, 576, 128]       tensor([ 0.133,  0.444, -0.814,  1.344, -0.230,  0.528, -0.096,  0.242, -0.411, -0.157])\n",
      "add ff              [2, 576, 128]       tensor([  2.847,   8.177, -26.205,  31.962,   0.464,  -1.949,  13.272,  -0.489,  -3.089,   4.315])\n",
      "attn1               [2, 576, 128]       tensor([ 0.916, -0.236,  1.404, -2.175,  0.688,  0.271, -1.252,  0.065,  1.060,  0.585])\n",
      "add attn1           [2, 576, 128]       tensor([  3.763,   7.941, -24.802,  29.787,   1.152,  -1.679,  12.020,  -0.424,  -2.029,   4.899])\n",
      "attn2               [2, 576, 128]       tensor([-1.951,  1.734, -1.576,  4.261,  0.630, -0.318, -0.086,  3.898,  2.755, -1.465])\n",
      "add attn2           [2, 576, 128]       tensor([  1.812,   9.675, -26.378,  34.048,   1.782,  -1.997,  11.934,   3.474,   0.726,   3.434])\n",
      "ff                  [2, 576, 128]       tensor([ 0.187,  0.082, -0.114,  0.443,  0.056,  0.203,  0.263,  0.137, -0.313, -0.348])\n",
      "add ff              [2, 576, 128]       tensor([  1.999,   9.757, -26.491,  34.491,   1.838,  -1.794,  12.198,   3.611,   0.412,   3.086])\n",
      "attn1               [2, 576, 128]       tensor([-0.800,  0.610, -1.508,  2.231,  0.175, -0.492,  1.059,  0.090, -0.863,  0.712])\n",
      "add attn1           [2, 576, 128]       tensor([  1.199,  10.367, -28.000,  36.721,   2.013,  -2.286,  13.257,   3.701,  -0.451,   3.798])\n",
      "attn2               [2, 576, 128]       tensor([-3.464,  1.775, -2.601,  2.098, -4.737,  2.701,  0.297,  5.550,  1.373, -0.408])\n",
      "add attn2           [2, 576, 128]       tensor([ -2.265,  12.142, -30.600,  38.819,  -2.724,   0.415,  13.553,   9.251,   0.923,   3.390])\n",
      "ff                  [2, 576, 128]       tensor([ 0.047,  0.212, -0.151,  0.223,  0.102,  0.015, -0.068,  0.221, -0.040, -0.208])\n",
      "add ff              [2, 576, 128]       tensor([ -2.218,  12.354, -30.752,  39.042,  -2.622,   0.429,  13.485,   9.472,   0.883,   3.182])\n",
      "attn1               [2, 576, 128]       tensor([-0.635, -0.423, -0.160,  0.406, -0.561,  0.293,  0.034,  0.311,  0.103, -0.260])\n",
      "add attn1           [2, 576, 128]       tensor([ -2.853,  11.931, -30.911,  39.448,  -3.184,   0.723,  13.519,   9.783,   0.986,   2.922])\n",
      "attn2               [2, 576, 128]       tensor([-0.111,  0.062,  0.261,  0.144, -0.439,  0.167,  0.039,  0.069, -0.114,  0.446])\n",
      "add attn2           [2, 576, 128]       tensor([ -2.964,  11.993, -30.650,  39.592,  -3.623,   0.890,  13.558,   9.852,   0.872,   3.368])\n",
      "ff                  [2, 576, 128]       tensor([-0.074,  0.085, -0.559,  0.345, -0.085,  0.131,  0.117, -0.113,  0.098, -0.201])\n",
      "add ff              [2, 576, 128]       tensor([ -3.038,  12.078, -31.209,  39.937,  -3.708,   1.021,  13.674,   9.738,   0.970,   3.167])\n",
      "attn1               [2, 576, 128]       tensor([ 0.431,  0.083,  0.541, -0.919,  0.336,  0.315, -0.664,  0.052,  0.325, -0.178])\n",
      "add attn1           [2, 576, 128]       tensor([ -2.608,  12.161, -30.668,  39.018,  -3.372,   1.335,  13.011,   9.791,   1.294,   2.989])\n",
      "attn2               [2, 576, 128]       tensor([ 3.035, -0.175,  1.599, -2.597,  1.470,  3.821, -2.912,  1.783,  0.193,  0.610])\n",
      "add attn2           [2, 576, 128]       tensor([  0.428,  11.987, -29.069,  36.421,  -1.902,   5.156,  10.098,  11.574,   1.487,   3.599])\n",
      "ff                  [2, 576, 128]       tensor([ 0.092,  0.471, -0.456,  0.385, -0.064, -0.019,  0.143,  0.389,  0.017, -0.044])\n",
      "add ff              [2, 576, 128]       tensor([  0.520,  12.458, -29.524,  36.806,  -1.966,   5.137,  10.242,  11.963,   1.505,   3.555])\n",
      "attn1               [2, 576, 128]       tensor([ 0.423,  0.065,  0.180,  0.614,  0.211, -0.358,  0.095,  0.108,  0.024,  0.072])\n",
      "add attn1           [2, 576, 128]       tensor([  0.943,  12.523, -29.344,  37.420,  -1.755,   4.779,  10.337,  12.071,   1.529,   3.627])\n",
      "attn2               [2, 576, 128]       tensor([ 2.752,  0.224, -0.199,  0.931, -0.297,  0.425, -1.231, -0.008, -1.932, -0.966])\n",
      "add attn2           [2, 576, 128]       tensor([  3.695,  12.747, -29.544,  38.351,  -2.052,   5.205,   9.106,  12.063,  -0.402,   2.662])\n",
      "ff                  [2, 576, 128]       tensor([ 0.016,  0.137, -0.360,  0.445,  0.154,  0.342, -0.059,  0.313,  0.067, -0.014])\n",
      "add ff              [2, 576, 128]       tensor([  3.711,  12.884, -29.903,  38.797,  -1.898,   5.547,   9.047,  12.376,  -0.335,   2.648])\n",
      "attn1               [2, 576, 128]       tensor([-0.118, -0.318, -0.173,  0.417, -0.198, -0.098,  0.369, -0.085, -0.187,  0.120])\n",
      "add attn1           [2, 576, 128]       tensor([  3.594,  12.566, -30.077,  39.214,  -2.096,   5.449,   9.416,  12.292,  -0.522,   2.768])\n",
      "attn2               [2, 576, 128]       tensor([-1.822,  1.409, -4.020,  0.055,  2.168,  0.475, -3.242,  2.737,  0.567, -3.860])\n",
      "add attn2           [2, 576, 128]       tensor([  1.772,  13.975, -34.097,  39.269,   0.072,   5.924,   6.174,  15.029,   0.045,  -1.092])\n",
      "ff                  [2, 576, 128]       tensor([ 0.115, -0.025, -0.049,  0.041,  0.124, -0.070,  0.079,  0.187, -0.051, -0.045])\n",
      "add ff              [2, 576, 128]       tensor([ 1.886e+00,  1.395e+01, -3.415e+01,  3.931e+01,  1.957e-01,  5.854e+00,  6.253e+00,  1.522e+01, -5.351e-03, -1.136e+00])\n",
      "attn1               [2, 576, 128]       tensor([-0.072, -0.211,  0.101,  0.034,  0.000,  0.077, -0.383,  0.308, -0.220,  0.008])\n",
      "add attn1           [2, 576, 128]       tensor([  1.815,  13.739, -34.045,  39.344,   0.196,   5.930,   5.870,  15.524,  -0.226,  -1.129])\n",
      "attn2               [2, 576, 128]       tensor([-0.138,  0.077, -0.193,  0.131, -0.108, -0.059, -0.188,  0.188, -0.072, -0.031])\n",
      "add attn2           [2, 576, 128]       tensor([  1.676,  13.816, -34.238,  39.475,   0.089,   5.871,   5.682,  15.712,  -0.297,  -1.160])\n",
      "ff                  [2, 576, 128]       tensor([ 0.159,  0.261, -0.084,  0.426,  0.364,  0.266,  0.089,  0.049, -0.093,  0.029])\n",
      "add ff              [2, 576, 128]       tensor([  1.835,  14.077, -34.322,  39.901,   0.452,   6.137,   5.771,  15.761,  -0.390,  -1.131])\n",
      "proj_out            [2, 128, 24, 24]    tensor([21.499,  5.677, 16.770,  4.253, 19.617, 14.935, 10.512, 10.458, 13.137, 14.557])\n",
      "conv1               [2, 128, 24, 24]    tensor([1.903, 2.215, 2.396, 2.080, 1.948, 2.220, 2.026, 1.654, 1.701, 2.020])\n",
      "add time_emb_proj   [2, 128, 24, 24]    tensor([-7.547, -7.236, -7.055, -7.371, -7.502, -7.230, -7.424, -7.796, -7.750, -7.430])\n",
      "conv2               [2, 128, 24, 24]    tensor([2.097, 3.128, 3.534, 3.501, 2.834, 2.253, 2.291, 2.644, 2.705, 2.132])\n",
      "add conv_shortcut   [2, 128, 24, 24]    tensor([23.596,  8.805, 20.304,  7.754, 22.451, 17.189, 12.802, 13.102, 15.841, 16.689])\n"
     ]
    }
   ],
   "source": [
    "for name, t in dlog_c:\n",
    "    print(f'{name:<20}{str(list(t.shape)):<20}{t.flatten()[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486c79bf-2889-4f60-bad3-412182132b80",
   "metadata": {},
   "source": [
    "Cloud intermediate results are also not empty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b1082c-4937-463f-b779-dbd1c02b11ca",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e912e1b4-9d93-4680-a9e1-ac68a1ec9f05",
   "metadata": {},
   "source": [
    "Okay, now let's compare local and cloud intermediate outputs (at level subblock minus 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e8caab89-aba7-45f5-b283-f2c83b40632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from util_inspect import fmt_bool\n",
    "\n",
    "def compare_intermediate_results(n=None,n_start=0,prec=5, compare_prec=2):\n",
    "    if n is None: n=max(len(dlog_c),len(dlog_l))\n",
    "    i,lv,b,c,l,en,es,ev,d,stats = '-','level','block','cloud','local','equal name?','equal shape?','equal values?','mean abs Î”','mean Â± std'\n",
    "    print(f'{i:<3} | {lv:<5} | {b:<5} | {c:<19} | {l:<19} | {en:<11} | {es:<12} | {ev:<13} | ' + ('{:>'+str(prec+5)+'}').format(d) + f' | {stats:>12}')\n",
    "    i,lv,b,c,l,en,es,ev,d,stats = '','','','','','','','prec='+str(compare_prec),'prec='+str(prec),''\n",
    "    print(f'{i:<3} | {lv:<5} | {b:<5} | {c:<19} | {l:<19} | {en:<11} | {es:<12} | {ev:^13} | ' + ('{:>'+str(prec+5)+'}').format(d) + f' | {stats:>12}')\n",
    "    total_len = 3+3+5+3+5+3+19+3+19+3+11+3+12+3+13+3+(prec+5)+3+12\n",
    "\n",
    "    line = partial(\n",
    "        lambda txt, width: print(txt * (width//len(txt))),\n",
    "        width=total_len\n",
    "    )\n",
    "    \n",
    "    line('=')\n",
    "\n",
    "    lv,block=1,1\n",
    "    for i in range(n_start,n):\n",
    "        (cn,ct),(ln,lt)=dlog_c[i],dlog_l[i]\n",
    "        eq_name = cn==ln\n",
    "        eq_shape = ct.shape==lt.shape\n",
    "        eq_vals = torch.allclose(ct,lt,atol=10**-compare_prec)\n",
    "        #ct,lt = broadcast(c.t,l.t)\n",
    "        mae = (ct-lt).abs().mean()\n",
    "\n",
    "        mean,std = ct.mean(),ct.std()\n",
    "        \n",
    "        print(f'{i:<3} | {lv:^5} | {block:^5} | {cn:<19} | {ln:<19} | ', end='')\n",
    "        print(fmt_bool(eq_name, '^11')+' | '+fmt_bool(eq_shape, '^12')+' | '+fmt_bool(eq_vals, '^13')+' | ', end='')\n",
    "        print(('{:>'+str(prec+5)+'.'+str(prec)+'f}').format(mae)+' | ', end='')\n",
    "        print(f'{ct.mean():>5.2f} Â± {ct.std():>3.2f}')\n",
    "\n",
    "        if cn=='conv':\n",
    "            line('=')\n",
    "            lv += 1\n",
    "            block = 1\n",
    "        if cn in ('add conv_shortcut','proj_out'):\n",
    "            line('-')\n",
    "            block += 1\n",
    "        if cn in ('proj_in', 'add ff'): line('-   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "56892953-74b2-4103-ba00-eb0ed4249553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-   | level | block | cloud               | local               | equal name? | equal shape? | equal values? | mean abs Î” |   mean Â± std\n",
      "    |       |       |                     |                     |             |              |    prec=2     |     prec=5 |             \n",
      "========================================================================================================================================\n",
      "0   |   1   |   1   | conv1               | conv1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[92m      y      \u001b[0m |    0.00023 | -0.39 Â± 1.27\n",
      "1   |   1   |   1   | add time_emb_proj   | add time_emb_proj   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00685 | -0.26 Â± 1.49\n",
      "2   |   1   |   1   | conv2               | conv2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[92m      y      \u001b[0m |    0.00008 | -0.03 Â± 0.41\n",
      "3   |   1   |   1   | add conv_shortcut   | add conv_shortcut   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[92m      y      \u001b[0m |    0.00019 |  0.00 Â± 0.99\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "4   |   1   |   2   | conv1               | conv1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00312 | -0.07 Â± 1.10\n",
      "5   |   1   |   2   | add time_emb_proj   | add time_emb_proj   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00836 |  0.08 Â± 1.12\n",
      "6   |   1   |   2   | conv2               | conv2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00102 |  0.04 Â± 0.74\n",
      "7   |   1   |   2   | add conv_shortcut   | add conv_shortcut   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00201 |  0.19 Â± 1.64\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "8   |   1   |   3   | conv                | conv                | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.01570 |  0.57 Â± 3.33\n",
      "========================================================================================================================================\n",
      "9   |   2   |   1   | conv1               | conv1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.02232 | -0.33 Â± 4.89\n",
      "10  |   2   |   1   | add time_emb_proj   | add time_emb_proj   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.05976 | -0.26 Â± 7.57\n",
      "11  |   2   |   1   | conv2               | conv2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00420 |  0.08 Â± 0.90\n",
      "12  |   2   |   1   | add conv_shortcut   | add conv_shortcut   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.01575 |  0.29 Â± 2.55\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "13  |   2   |   2   | proj_in             | proj_in             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00273 |  0.03 Â± 0.71\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "14  |   2   |   2   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.09741 | -0.03 Â± 0.29\n",
      "15  |   2   |   2   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.09742 |  0.00 Â± 0.82\n",
      "16  |   2   |   2   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.15383 |  0.00 Â± 0.97\n",
      "17  |   2   |   2   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "18  |   2   |   2   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.73908 | -0.51 Â± 5.13\n",
      "19  |   2   |   2   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.78791 | -0.51 Â± 5.27\n",
      "20  |   2   |   2   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.06974 |  0.01 Â± 0.28\n",
      "21  |   2   |   2   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.79937 | -0.50 Â± 5.29\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "22  |   2   |   2   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.08315 |  0.01 Â± 0.27\n",
      "23  |   2   |   2   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.81192 | -0.49 Â± 5.32\n",
      "24  |   2   |   2   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.25515 |  0.00 Â± 0.97\n",
      "25  |   2   |   2   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "26  |   2   |   2   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.64773 |  0.03 Â± 0.41\n",
      "27  |   2   |   2   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.15857 | -0.46 Â± 5.33\n",
      "28  |   2   |   2   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.16631 |  0.12 Â± 0.57\n",
      "29  |   2   |   2   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.21253 | -0.34 Â± 5.29\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "30  |   2   |   2   | proj_out            | proj_out            | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.20753 |  0.45 Â± 2.58\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "31  |   2   |   3   | conv1               | conv1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.36899 |  0.22 Â± 11.80\n",
      "32  |   2   |   3   | add time_emb_proj   | add time_emb_proj   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.36862 |  0.15 Â± 13.35\n",
      "33  |   2   |   3   | conv2               | conv2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.04369 |  0.21 Â± 1.92\n",
      "34  |   2   |   3   | add conv_shortcut   | add conv_shortcut   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.15546 |  0.15 Â± 5.21\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "35  |   2   |   4   | proj_in             | proj_in             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.03179 |  0.06 Â± 0.80\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "36  |   2   |   4   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.08382 |  0.03 Â± 0.92\n",
      "37  |   2   |   4   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.09295 |  0.09 Â± 1.43\n",
      "38  |   2   |   4   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.04766 | -0.00 Â± 0.97\n",
      "39  |   2   |   4   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "40  |   2   |   4   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.09375 |  1.56 Â± 6.92\n",
      "41  |   2   |   4   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.17724 |  1.65 Â± 7.40\n",
      "42  |   2   |   4   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00932 |  0.03 Â± 0.35\n",
      "43  |   2   |   4   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.17949 |  1.69 Â± 7.46\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "44  |   2   |   4   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00431 |  0.06 Â± 0.49\n",
      "45  |   2   |   4   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.17998 |  1.75 Â± 7.68\n",
      "46  |   2   |   4   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.02230 |  0.00 Â± 0.97\n",
      "47  |   2   |   4   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "48  |   2   |   4   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.27600 |  0.01 Â± 0.37\n",
      "49  |   2   |   4   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.37445 |  1.76 Â± 7.61\n",
      "50  |   2   |   4   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.01380 |  0.01 Â± 0.47\n",
      "51  |   2   |   4   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.37420 |  1.77 Â± 7.50\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "52  |   2   |   4   | proj_out            | proj_out            | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.16134 |  0.22 Â± 4.69\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "53  |   2   |   5   | conv                | conv                | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.34387 | -1.27 Â± 10.61\n",
      "========================================================================================================================================\n",
      "54  |   3   |   1   | conv1               | conv1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.19830 | -3.30 Â± 8.67\n",
      "55  |   3   |   1   | add time_emb_proj   | add time_emb_proj   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.21551 | -2.90 Â± 10.80\n",
      "56  |   3   |   1   | conv2               | conv2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.02676 | -0.37 Â± 1.71\n",
      "57  |   3   |   1   | add conv_shortcut   | add conv_shortcut   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.14997 | -0.87 Â± 5.80\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "58  |   3   |   2   | proj_in             | proj_in             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.02864 | -0.06 Â± 0.96\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "59  |   3   |   2   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.21937 |  0.02 Â± 1.97\n",
      "60  |   3   |   2   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.22398 | -0.04 Â± 2.43\n",
      "61  |   3   |   2   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.07479 |  0.00 Â± 0.97\n",
      "62  |   3   |   2   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "63  |   3   |   2   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.17801 |  0.06 Â± 7.67\n",
      "64  |   3   |   2   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.24026 |  0.02 Â± 8.57\n",
      "65  |   3   |   2   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.04659 |  0.00 Â± 0.23\n",
      "66  |   3   |   2   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.24610 |  0.02 Â± 8.62\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "67  |   3   |   2   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.57275 |  0.12 Â± 2.35\n",
      "68  |   3   |   2   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.43663 |  0.14 Â± 9.84\n",
      "69  |   3   |   2   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.20086 |  0.00 Â± 0.97\n",
      "70  |   3   |   2   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "71  |   3   |   2   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.52309 | -0.63 Â± 15.62\n",
      "72  |   3   |   2   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.18643 | -0.49 Â± 20.47\n",
      "73  |   3   |   2   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.02297 | -0.01 Â± 0.17\n",
      "74  |   3   |   2   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.18252 | -0.50 Â± 20.53\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "75  |   3   |   2   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.35911 | -0.01 Â± 1.53\n",
      "76  |   3   |   2   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.32369 | -0.51 Â± 21.32\n",
      "77  |   3   |   2   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.14596 | -0.00 Â± 0.97\n",
      "78  |   3   |   2   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "79  |   3   |   2   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.15542 | -0.18 Â± 12.22\n",
      "80  |   3   |   2   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.09797 | -0.69 Â± 27.89\n",
      "81  |   3   |   2   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.02451 | -0.01 Â± 0.15\n",
      "82  |   3   |   2   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.09866 | -0.70 Â± 27.96\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "83  |   3   |   2   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.09155 | -0.03 Â± 0.42\n",
      "84  |   3   |   2   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.07823 | -0.73 Â± 28.06\n",
      "85  |   3   |   2   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.14390 | -0.00 Â± 0.97\n",
      "86  |   3   |   2   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "87  |   3   |   2   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.16268 | -0.28 Â± 2.12\n",
      "88  |   3   |   2   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.08410 | -1.01 Â± 28.27\n",
      "89  |   3   |   2   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.02595 | -0.02 Â± 0.13\n",
      "90  |   3   |   2   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.08334 | -1.03 Â± 28.32\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "91  |   3   |   2   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.25510 |  0.05 Â± 0.66\n",
      "92  |   3   |   2   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.00428 | -0.97 Â± 27.99\n",
      "93  |   3   |   2   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.14229 |  0.00 Â± 0.97\n",
      "94  |   3   |   2   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "95  |   3   |   2   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.58632 | -0.75 Â± 7.74\n",
      "96  |   3   |   2   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.08705 | -1.73 Â± 29.28\n",
      "97  |   3   |   2   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.03433 | -0.02 Â± 0.18\n",
      "98  |   3   |   2   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.08337 | -1.74 Â± 29.28\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "99  |   3   |   2   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.08970 | -0.03 Â± 0.55\n",
      "100 |   3   |   2   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.09786 | -1.77 Â± 29.40\n",
      "101 |   3   |   2   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.13890 | -0.00 Â± 0.97\n",
      "102 |   3   |   2   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "103 |   3   |   2   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.02363 |  0.24 Â± 15.63\n",
      "104 |   3   |   2   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.55832 | -1.53 Â± 30.66\n",
      "105 |   3   |   2   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.04906 | -0.01 Â± 0.20\n",
      "106 |   3   |   2   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.56131 | -1.55 Â± 30.66\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "107 |   3   |   2   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.07518 |  0.02 Â± 0.33\n",
      "108 |   3   |   2   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.54985 | -1.53 Â± 30.64\n",
      "109 |   3   |   2   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.15839 |  0.00 Â± 0.97\n",
      "110 |   3   |   2   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "111 |   3   |   2   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.16250 |  0.52 Â± 8.62\n",
      "112 |   3   |   2   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.52296 | -1.01 Â± 31.80\n",
      "113 |   3   |   2   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.05015 |  0.06 Â± 0.53\n",
      "114 |   3   |   2   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.51625 | -0.95 Â± 31.65\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "115 |   3   |   2   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.05272 |  0.01 Â± 0.31\n",
      "116 |   3   |   2   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.50601 | -0.94 Â± 31.61\n",
      "117 |   3   |   2   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.15037 | -0.00 Â± 0.97\n",
      "118 |   3   |   2   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "119 |   3   |   2   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.46445 |  0.81 Â± 14.32\n",
      "120 |   3   |   2   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.70773 | -0.12 Â± 30.45\n",
      "121 |   3   |   2   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.05673 | -0.01 Â± 0.58\n",
      "122 |   3   |   2   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.69316 | -0.13 Â± 30.39\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "123 |   3   |   2   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.04679 | -0.02 Â± 0.34\n",
      "124 |   3   |   2   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.68853 | -0.15 Â± 30.41\n",
      "125 |   3   |   2   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.16349 | -0.00 Â± 0.98\n",
      "126 |   3   |   2   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "127 |   3   |   2   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.22171 | -0.03 Â± 0.53\n",
      "128 |   3   |   2   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.69388 | -0.18 Â± 30.38\n",
      "129 |   3   |   2   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.05516 | -0.03 Â± 0.39\n",
      "130 |   3   |   2   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.68160 | -0.20 Â± 30.33\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "131 |   3   |   2   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.03833 | -0.01 Â± 0.26\n",
      "132 |   3   |   2   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    5.67993 | -0.22 Â± 30.36\n",
      "133 |   3   |   2   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.16314 |  0.00 Â± 0.98\n",
      "134 |   3   |   2   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "135 |   3   |   2   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.25813 | -0.04 Â± 4.87\n",
      "136 |   3   |   2   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    7.01228 | -0.25 Â± 30.45\n",
      "137 |   3   |   2   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.07865 | -0.01 Â± 0.44\n",
      "138 |   3   |   2   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    6.99067 | -0.26 Â± 30.36\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "139 |   3   |   2   | proj_out            | proj_out            | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.34045 | -0.65 Â± 10.47\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "140 |   3   |   3   | conv1               | conv1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.47251 | -2.57 Â± 16.82\n",
      "141 |   3   |   3   | add time_emb_proj   | add time_emb_proj   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.47271 | -2.49 Â± 19.27\n",
      "142 |   3   |   3   | conv2               | conv2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.03938 |  0.01 Â± 1.29\n",
      "143 |   3   |   3   | add conv_shortcut   | add conv_shortcut   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.22851 |  0.34 Â± 24.44\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "144 |   3   |   4   | proj_in             | proj_in             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.06940 | -0.02 Â± 1.50\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "145 |   3   |   4   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.03951 | -0.06 Â± 1.47\n",
      "146 |   3   |   4   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.08284 | -0.07 Â± 2.62\n",
      "147 |   3   |   4   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.02136 | -0.00 Â± 0.97\n",
      "148 |   3   |   4   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "149 |   3   |   4   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.17499 | -1.15 Â± 19.31\n",
      "150 |   3   |   4   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.19964 | -1.22 Â± 20.11\n",
      "151 |   3   |   4   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00097 | -0.00 Â± 0.07\n",
      "152 |   3   |   4   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.19980 | -1.23 Â± 20.14\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "153 |   3   |   4   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00283 | -0.01 Â± 0.66\n",
      "154 |   3   |   4   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.19984 | -1.24 Â± 20.48\n",
      "155 |   3   |   4   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00929 |  0.00 Â± 0.97\n",
      "156 |   3   |   4   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "157 |   3   |   4   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.02840 | -1.41 Â± 18.96\n",
      "158 |   3   |   4   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.21876 | -2.64 Â± 33.56\n",
      "159 |   3   |   4   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00065 | -0.00 Â± 0.07\n",
      "160 |   3   |   4   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.21887 | -2.64 Â± 33.59\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "161 |   3   |   4   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.20532 | -0.04 Â± 0.31\n",
      "162 |   3   |   4   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.33727 | -2.68 Â± 33.54\n",
      "163 |   3   |   4   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00908 | -0.00 Â± 0.97\n",
      "164 |   3   |   4   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "165 |   3   |   4   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.81046 |  0.53 Â± 3.69\n",
      "166 |   3   |   4   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.83967 | -2.14 Â± 34.59\n",
      "167 |   3   |   4   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00633 | -0.01 Â± 0.07\n",
      "168 |   3   |   4   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.83950 | -2.16 Â± 34.62\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "169 |   3   |   4   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.43456 | -0.00 Â± 0.42\n",
      "170 |   3   |   4   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.85582 | -2.16 Â± 34.52\n",
      "171 |   3   |   4   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.07921 |  0.00 Â± 0.97\n",
      "172 |   3   |   4   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "173 |   3   |   4   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.14102 | -0.13 Â± 4.41\n",
      "174 |   3   |   4   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.83036 | -2.28 Â± 36.35\n",
      "175 |   3   |   4   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00906 | -0.00 Â± 0.19\n",
      "176 |   3   |   4   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.83126 | -2.28 Â± 36.44\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "177 |   3   |   4   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.32070 |  0.01 Â± 0.44\n",
      "178 |   3   |   4   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.88373 | -2.28 Â± 36.34\n",
      "179 |   3   |   4   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.07655 | -0.00 Â± 0.97\n",
      "180 |   3   |   4   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "181 |   3   |   4   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.91258 |  0.07 Â± 2.06\n",
      "182 |   3   |   4   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.95295 | -2.21 Â± 36.23\n",
      "183 |   3   |   4   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00767 | -0.01 Â± 0.09\n",
      "184 |   3   |   4   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.95133 | -2.22 Â± 36.28\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "185 |   3   |   4   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.11324 |  0.03 Â± 0.36\n",
      "186 |   3   |   4   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.95046 | -2.19 Â± 36.32\n",
      "187 |   3   |   4   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.07765 |  0.00 Â± 0.97\n",
      "188 |   3   |   4   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "189 |   3   |   4   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.10680 | -0.09 Â± 3.36\n",
      "190 |   3   |   4   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.95887 | -2.27 Â± 36.62\n",
      "191 |   3   |   4   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00996 | -0.01 Â± 0.12\n",
      "192 |   3   |   4   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.95882 | -2.28 Â± 36.68\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "193 |   3   |   4   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.03355 |  0.03 Â± 0.28\n",
      "194 |   3   |   4   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.96371 | -2.25 Â± 36.62\n",
      "195 |   3   |   4   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.07728 | -0.00 Â± 0.97\n",
      "196 |   3   |   4   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "197 |   3   |   4   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.18850 |  0.03 Â± 0.50\n",
      "198 |   3   |   4   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.98250 | -2.22 Â± 36.62\n",
      "199 |   3   |   4   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.01000 | -0.02 Â± 0.17\n",
      "200 |   3   |   4   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.98293 | -2.24 Â± 36.71\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "201 |   3   |   4   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.13228 |  0.03 Â± 0.29\n",
      "202 |   3   |   4   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.00501 | -2.21 Â± 36.71\n",
      "203 |   3   |   4   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.07834 |  0.00 Â± 0.97\n",
      "204 |   3   |   4   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "205 |   3   |   4   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.01572 |  0.47 Â± 9.05\n",
      "206 |   3   |   4   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.00312 | -1.73 Â± 36.34\n",
      "207 |   3   |   4   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.01394 | -0.00 Â± 0.19\n",
      "208 |   3   |   4   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.00547 | -1.74 Â± 36.44\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "209 |   3   |   4   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.24159 |  0.01 Â± 0.24\n",
      "210 |   3   |   4   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.03444 | -1.72 Â± 36.45\n",
      "211 |   3   |   4   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.07985 |  0.00 Â± 0.98\n",
      "212 |   3   |   4   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "213 |   3   |   4   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.31637 | -0.02 Â± 0.28\n",
      "214 |   3   |   4   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.05491 | -1.74 Â± 36.51\n",
      "215 |   3   |   4   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.01481 | -0.01 Â± 0.36\n",
      "216 |   3   |   4   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.05622 | -1.75 Â± 36.61\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "217 |   3   |   4   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.02854 |  0.03 Â± 0.45\n",
      "218 |   3   |   4   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.05749 | -1.71 Â± 36.59\n",
      "219 |   3   |   4   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.07957 | -0.00 Â± 0.97\n",
      "220 |   3   |   4   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "221 |   3   |   4   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.05575 |  0.94 Â± 13.00\n",
      "222 |   3   |   4   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.69794 | -0.77 Â± 32.30\n",
      "223 |   3   |   4   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.03782 | -0.01 Â± 0.37\n",
      "224 |   3   |   4   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.69320 | -0.78 Â± 32.36\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "225 |   3   |   4   | proj_out            | proj_out            | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.28962 | -0.16 Â± 13.14\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "226 |   3   |   5   | conv1               | conv1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    8.41563 | -2.75 Â± 11.88\n",
      "227 |   3   |   5   | add time_emb_proj   | add time_emb_proj   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    8.43531 | -2.54 Â± 13.50\n",
      "228 |   3   |   5   | conv2               | conv2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.11361 | -0.06 Â± 2.40\n",
      "229 |   3   |   5   | add conv_shortcut   | add conv_shortcut   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   11.26654 | -0.18 Â± 15.15\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "230 |   3   |   6   | proj_in             | proj_in             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.30093 | -0.02 Â± 1.58\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "231 |   3   |   6   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.00836 |  0.00 Â± 1.59\n",
      "232 |   3   |   6   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.86512 | -0.02 Â± 2.46\n",
      "233 |   3   |   6   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.74791 |  0.00 Â± 0.97\n",
      "234 |   3   |   6   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "235 |   3   |   6   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.54641 |  0.23 Â± 4.15\n",
      "236 |   3   |   6   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.74839 |  0.21 Â± 5.31\n",
      "237 |   3   |   6   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.77041 | -0.15 Â± 3.60\n",
      "238 |   3   |   6   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    4.24090 |  0.06 Â± 7.20\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "239 |   3   |   6   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.68337 |  0.26 Â± 4.94\n",
      "240 |   3   |   6   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    6.56630 |  0.32 Â± 11.14\n",
      "241 |   3   |   6   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.55787 |  0.00 Â± 0.97\n",
      "242 |   3   |   6   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "243 |   3   |   6   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.99888 | -0.03 Â± 3.16\n",
      "244 |   3   |   6   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    6.85780 |  0.29 Â± 12.50\n",
      "245 |   3   |   6   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.34958 |  0.06 Â± 0.51\n",
      "246 |   3   |   6   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    7.12900 |  0.35 Â± 12.82\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "247 |   3   |   6   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    2.39318 | -0.03 Â± 1.76\n",
      "248 |   3   |   6   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    9.00988 |  0.32 Â± 13.53\n",
      "249 |   3   |   6   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.58498 | -0.00 Â± 0.97\n",
      "250 |   3   |   6   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "251 |   3   |   6   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.76487 |  0.03 Â± 1.64\n",
      "252 |   3   |   6   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    8.90856 |  0.35 Â± 13.54\n",
      "253 |   3   |   6   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.27900 |  0.04 Â± 0.37\n",
      "254 |   3   |   6   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    9.14479 |  0.39 Â± 13.78\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "255 |   3   |   6   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.12802 | -0.04 Â± 1.47\n",
      "256 |   3   |   6   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    9.23369 |  0.35 Â± 12.73\n",
      "257 |   3   |   6   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.60938 |  0.00 Â± 0.97\n",
      "258 |   3   |   6   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "259 |   3   |   6   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.69672 |  0.08 Â± 2.05\n",
      "260 |   3   |   6   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    9.31041 |  0.43 Â± 13.15\n",
      "261 |   3   |   6   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.19394 |  0.01 Â± 0.24\n",
      "262 |   3   |   6   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    9.46322 |  0.44 Â± 13.26\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "263 |   3   |   6   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.21161 |  0.00 Â± 1.05\n",
      "264 |   3   |   6   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.42627 |  0.44 Â± 13.85\n",
      "265 |   3   |   6   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.62648 | -0.00 Â± 0.97\n",
      "266 |   3   |   6   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "267 |   3   |   6   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.69746 | -0.10 Â± 2.36\n",
      "268 |   3   |   6   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.55771 |  0.34 Â± 14.44\n",
      "269 |   3   |   6   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.11496 |  0.01 Â± 0.16\n",
      "270 |   3   |   6   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.63595 |  0.35 Â± 14.48\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "271 |   3   |   6   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.53866 |  0.01 Â± 0.36\n",
      "272 |   3   |   6   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.94390 |  0.36 Â± 14.57\n",
      "273 |   3   |   6   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.62245 | -0.00 Â± 0.97\n",
      "274 |   3   |   6   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "275 |   3   |   6   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.71864 |  0.25 Â± 3.68\n",
      "276 |   3   |   6   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.18641 |  0.61 Â± 14.13\n",
      "277 |   3   |   6   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.15837 |  0.01 Â± 0.22\n",
      "278 |   3   |   6   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.29455 |  0.62 Â± 14.25\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "279 |   3   |   6   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.60555 |  0.01 Â± 0.54\n",
      "280 |   3   |   6   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.58433 |  0.63 Â± 13.98\n",
      "281 |   3   |   6   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.60348 | -0.00 Â± 0.97\n",
      "282 |   3   |   6   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "283 |   3   |   6   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.20082 |  0.13 Â± 2.96\n",
      "284 |   3   |   6   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.41863 |  0.76 Â± 14.10\n",
      "285 |   3   |   6   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.14536 |  0.02 Â± 0.20\n",
      "286 |   3   |   6   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.51587 |  0.78 Â± 14.22\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "287 |   3   |   6   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.25793 | -0.02 Â± 0.38\n",
      "288 |   3   |   6   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.62158 |  0.76 Â± 14.22\n",
      "289 |   3   |   6   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.59486 | -0.00 Â± 0.97\n",
      "290 |   3   |   6   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "291 |   3   |   6   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.69607 | -0.12 Â± 1.50\n",
      "292 |   3   |   6   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.64513 |  0.64 Â± 14.50\n",
      "293 |   3   |   6   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.09366 |  0.02 Â± 0.16\n",
      "294 |   3   |   6   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.68629 |  0.66 Â± 14.58\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "295 |   3   |   6   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.11470 | -0.03 Â± 0.24\n",
      "296 |   3   |   6   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.68377 |  0.63 Â± 14.60\n",
      "297 |   3   |   6   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.58391 |  0.00 Â± 0.97\n",
      "298 |   3   |   6   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "299 |   3   |   6   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.57314 | -0.23 Â± 2.05\n",
      "300 |   3   |   6   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.68253 |  0.40 Â± 14.87\n",
      "301 |   3   |   6   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.06584 |  0.01 Â± 0.12\n",
      "302 |   3   |   6   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.70261 |  0.40 Â± 14.92\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "303 |   3   |   6   | attn1               | attn1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.28117 |  0.01 Â± 0.31\n",
      "304 |   3   |   6   | add attn1           | add attn1           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.78535 |  0.41 Â± 14.85\n",
      "305 |   3   |   6   | norm2               | norm2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.57655 |  0.00 Â± 0.97\n",
      "306 |   3   |   6   | context             | context             | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.00053 |  0.02 Â± 3.07\n",
      "307 |   3   |   6   | attn2               | attn2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.85789 |  0.08 Â± 1.84\n",
      "308 |   3   |   6   | add attn2           | add attn2           | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.48515 |  0.49 Â± 14.82\n",
      "309 |   3   |   6   | ff                  | ff                  | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    0.11847 |  0.02 Â± 0.18\n",
      "310 |   3   |   6   | add ff              | add ff              | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   10.54437 |  0.51 Â± 14.93\n",
      "-   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   -   \n",
      "311 |   3   |   6   | proj_out            | proj_out            | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   17.28852 | -0.27 Â± 11.51\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n",
      "312 |   3   |   7   | conv1               | conv1               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.52791 |  0.21 Â± 1.53\n",
      "313 |   3   |   7   | add time_emb_proj   | add time_emb_proj   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    1.52122 |  0.20 Â± 3.89\n",
      "314 |   3   |   7   | conv2               | conv2               | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |    3.99515 | -1.11 Â± 10.26\n",
      "315 |   3   |   7   | add conv_shortcut   | add conv_shortcut   | \u001b[92m     y     \u001b[0m | \u001b[92m     y      \u001b[0m | \u001b[91m      n      \u001b[0m |   15.22173 | -1.37 Â± 16.57\n",
      "----------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "compare_intermediate_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e76d2-75e3-4c1f-a25d-1bca89c12ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d0cd396c-f22e-4b18-a507-2c92a8871e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 34)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts_l = [t for n,t in dlog_l if n=='context']\n",
    "contexts_c = [t for n,t in dlog_c if n=='context']\n",
    "len(contexts_l), len(contexts_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4a09c80e-65ce-4549-b0a0-8e8de07974f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr | local equal to next? | equal across local/cloud? | cloud equal to next?\n",
      "0  |         True         |           False           |         True        \n",
      "1  |         True         |           False           |         True        \n",
      "2  |         True         |           False           |         True        \n",
      "3  |         True         |           False           |         True        \n",
      "4  |         True         |           False           |         True        \n",
      "5  |         True         |           False           |         True        \n",
      "6  |         True         |           False           |         True        \n",
      "7  |         True         |           False           |         True        \n",
      "8  |         True         |           False           |         True        \n",
      "9  |         True         |           False           |         True        \n",
      "10 |         True         |           False           |         True        \n",
      "11 |         True         |           False           |         True        \n",
      "12 |         True         |           False           |         True        \n",
      "13 |         True         |           False           |         True        \n",
      "14 |         True         |           False           |         True        \n",
      "15 |         True         |           False           |         True        \n",
      "16 |         True         |           False           |         True        \n",
      "17 |         True         |           False           |         True        \n",
      "18 |         True         |           False           |         True        \n",
      "19 |         True         |           False           |         True        \n",
      "20 |         True         |           False           |         True        \n",
      "21 |         True         |           False           |         True        \n",
      "22 |         True         |           False           |         True        \n",
      "23 |         True         |           False           |         True        \n",
      "24 |         True         |           False           |         True        \n",
      "25 |         True         |           False           |         True        \n",
      "26 |         True         |           False           |         True        \n",
      "27 |         True         |           False           |         True        \n",
      "28 |         True         |           False           |         True        \n",
      "29 |         True         |           False           |         True        \n",
      "30 |         True         |           False           |         True        \n",
      "31 |         True         |           False           |         True        \n",
      "32 |         True         |           False           |         True        \n"
     ]
    }
   ],
   "source": [
    "header = ('nr','local equal to next?','equal across local/cloud?','cloud equal to next?')\n",
    "print(' | '.join(header))\n",
    "for i in range(len(contexts_l)-1):\n",
    "    eq_next_l = (contexts_l[i]==contexts_l[i+1]).all().item()\n",
    "    eq_next_c = (contexts_c[i]==contexts_c[i+1]).all().item()\n",
    "    eq_across = torch.allclose(contexts_l[i],contexts_c[i], atol=1e-2)\n",
    "\n",
    "    vals = (i,eq_next_l,eq_across,eq_next_c)\n",
    "    \n",
    "    print(' | '.join(f'{str(v):^{len(h)}}' for v, h in zip(vals, header)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6bc9545b-f7a4-4bc4-bad1-524580ac4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "cxt_l = contexts_l[0]\n",
    "cxt_c = contexts_c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e32a45e1-3a3f-423d-ab62-03c3d0b31878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.892, -2.511,  4.717,  1.092, -1.341, -4.957, -2.133, -2.664,  3.387,  0.525])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cxt_l.flatten()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "512d1051-5fb5-45b5-98b3-eae723fbe52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.892, -2.511,  4.718,  1.092, -1.341, -4.955, -2.133, -2.663,  3.388,  0.525])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cxt_c.flatten()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "097a4800-76bd-4c78-bff9-95ae2ec40372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(cxt_l, cxt_c, atol=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5040a1-3c28-4369-8205-350a15d038da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
